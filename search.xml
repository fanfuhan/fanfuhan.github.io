<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[linux下python创建虚拟环境]]></title>
    <url>%2F2019%2F04%2F17%2Flinux_python_env%2F</url>
    <content type="text"><![CDATA[安装 virtualenv1pip install virtualenv 创建工作目录12mkdir myprojectcd myproject 创建一个独立的python运行环境，命名为 venc123# --no-site-packages 得到了一个不带任何第三方包的“干净”的Python运行环境# 若要继承已有的环境包，不加此参数virtualenv --no-site-packages venv --python=python2.7 进入创建的环境1source venv/bin/activate 自动生成和安装 requirements.txt 依赖12345# 生成requirements.txt文件pip freeze &gt; requirements.txt# 安装requirements.txt依赖pip install -r requirements.txt 退出虚拟环境1deactivate 删除虚拟环境1rm -r venv]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>linux</tag>
        <tag>virtualenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-055-二值图像分析(凸包检测)]]></title>
    <url>%2F2019%2F04%2F17%2Fopencv-055%2F</url>
    <content type="text"><![CDATA[知识点对二值图像进行轮廓分析之后，对获取到的每个轮廓数据，可以构建每个轮廓的凸包，构建完成之后会返回该凸包包含的点集。根据返回的凸包点集可以绘制该轮廓对应的凸包。OpenCV对轮廓提取凸包的API函数如下： 12345678910void cv::convexHull( InputArray points, OutputArray hull, bool clockwise = false, bool returnPoints = true )points参数是输入的轮廓点集hull凸包检测的输出结果，当参数returnPoints为ture的时候返回凸包的顶点坐标是个点集、returnPoints为false的是返回的是一个integer的vector里面是凸包各个顶点在轮廓点集对应的indexclockwise 表示顺时针方向或者逆时针方向returnPoints表示是否返回点集 OpenCV中的凸包寻找算法是基于Graham’s扫描法。OpenCV中还提供了另外一个API函数用来判断一个轮廓是否为凸包，该方法如下： 1234bool cv::isContourConvex( InputArray contour)该方法只有一个输入参数就是轮廓点集。 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 二值图像分析(凸包检测) */int main() &#123; Mat src = imread("../images/hand.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 二值化 Mat gray, binary; cvtColor(src, gray, COLOR_BGR2GRAY); threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); // 删除干扰块 Mat k = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1)); morphologyEx(binary, binary, MORPH_OPEN, k); imshow("binary", binary); // 轮廓发现与绘制 vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(binary, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point()); for (size_t t = 0; t &lt; contours.size(); t++) &#123; vector&lt;Point&gt; hull; convexHull(contours[t], hull); bool isHull = isContourConvex(contours[t]); printf("test convex of the contours %s", isHull?"y":"n"); int len = hull.size(); for (int i = 0; i &lt; len; ++i) &#123; circle(src, hull[i], 4, Scalar(255,0,0), 2); line(src, hull[i%len], hull[(i+1)%len], Scalar(0,0,255),2); &#125; &#125; imshow("contours", src); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829303132import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/hand.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)k = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))binary = cv.morphologyEx(binary, cv.MORPH_OPEN, k)cv.imshow("binary", binary)# 轮廓发现out, contours, hierarchy = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)for c in range(len(contours)): ret = cv.isContourConvex(contours[c]) points = cv.convexHull(contours[c]) total = len(points) for i in range(len(points)): x1, y1 = points[i%total][0] x2, y2 = points[(i+1)%total][0] cv.circle(src, (x1, y1), 4, (255, 0, 0), 2, 8, 0) cv.line(src, (x1, y1), (x2, y2), (0, 0, 255), 2, 8, 0) print(points) print("convex : ", ret)# 显示cv.imshow("contours_analysis", src)cv.imwrite("D:/contours_analysis.png", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>二值图像分析(凸包检测)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-056-二值图像分析(直线拟合与极值点寻找)]]></title>
    <url>%2F2019%2F04%2F17%2Fopencv-056%2F</url>
    <content type="text"><![CDATA[知识点对轮廓进行分析，除了可以对轮廓进行椭圆或者圆的拟合之外，还可以对轮廓点集进行直线拟合，直线拟合的算法有很多，最常见的就是最小二乘法，对于多约束线性方程，最小二乘可以找好直线方程的两个参数、实现直线拟合，OpenCV中直线拟合正是基于最小二乘法实现的。 OpenCV实现直线拟合的API如下: 12345678910111213141516171819void cv::fitLine( InputArray points, OutputArray line, int distType, double param, double reps, double aeps )points表示待拟合的输入点集合line在二维拟合时候输出的是vec4f类型的数据，在三维拟合的时候输出是vec6f的vectordistType表示在拟合时候使用距离计算公式是哪一种，OpenCV支持如下六种方式： DIST_L1 = 1 DIST_L2 = 2 DIST_L12 = 4 DIST_FAIR = 5 DIST_WELSCH = 6 DIST_HUBER = 7param对模型拟合距离计算公式需要参数C，5~7 distType需要参数Creps与aeps是指对拟合结果的精度要求，一般取0.01 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 二值图像分析(直线拟合与极值点寻找) */int main() &#123; Mat src = imread("../images/twolines.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 去噪声与二值化 Mat binary; Canny(src, binary, 80, 160, 3, false); imshow("binary", binary); Mat k = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1)); dilate(binary, binary, k); // 轮廓发现于绘制 vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(binary, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point()); for (size_t t = 0; t &lt; contours.size(); ++t) &#123; // 最大外接轮廓 Rect rect = boundingRect(contours[t]); int m = max(rect.width, rect.height); if (m &lt; 30) continue; // 直线拟合 Vec4f oneline; fitLine(contours[t], oneline, DIST_L1, 0, 0.01, 0.01); float dx = oneline[0]; float dy = oneline[1]; float x0 = oneline[2]; float y0 = oneline[3]; // 直线参数斜率k 和 截距b float k = dy / dx; float b = y0 - k * x0; // 寻找轮廓极值点 int minx = 0, miny = 10000; int maxx = 0, maxy = 0; for (int i = 0; i &lt; contours[t].size(); ++i) &#123; Point pt = contours[t][i]; if (miny &gt; pt.y) &#123; miny = pt.y; &#125; if (maxy &lt; pt.y) &#123; maxy = pt.y; &#125; maxx = (maxy - b) / k; minx = (miny - b) / k; line(src, Point(maxx, maxy), Point(minx, miny), Scalar(0,0,255), 2); &#125; &#125; imshow("contours", src); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import cv2 as cvimport numpy as npdef canny_demo(image): t = 80 canny_output = cv.Canny(image, t, t * 2) cv.imwrite("D:/canny_output.png", canny_output) return canny_outputsrc = cv.imread("D:/images/twolines.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)binary = canny_demo(src)k = np.ones((3, 3), dtype=np.uint8)binary = cv.morphologyEx(binary, cv.MORPH_DILATE, k)cv.imshow("binary", binary)# 轮廓发现out, contours, hierarchy = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)# 直线拟合与极值点寻找for c in range(len(contours)): x, y, w, h = cv.boundingRect(contours[c]) m = max(w, h) if m &lt; 30: continue vx, vy, x0, y0 = cv.fitLine(contours[c], cv.DIST_L1, 0, 0.01, 0.01) k = vy/vx b = y0 - k*x0 maxx = 0 maxy = 0 miny = 100000 minx = 0 for pt in contours[c]: px, py = pt[0] if maxy &lt; py: maxy = py if miny &gt; py: miny = py maxx = (maxy - b) / k minx = (miny - b) / k cv.line(src, (np.int32(maxx), np.int32(maxy)), (np.int32(minx), np.int32(miny)), (0, 0, 255), 2, 8, 0)# 显示cv.imshow("contours_analysis", src)cv.imwrite("D:/contours_analysis.png", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>二值图像分析(直线拟合与极值点寻找)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-054-二值图像分析(对轮廓圆与椭圆拟合)]]></title>
    <url>%2F2019%2F04%2F17%2Fopencv-054%2F</url>
    <content type="text"><![CDATA[知识点有时候我们需要对找到的轮廓点进行拟合，生成一个拟合的圆形或者椭圆，以便我们对轮廓进行更进一步的处理，满足我们对最终轮廓形状的判断，OpenCV对轮廓进行圆形或者椭圆拟合的API函数如下： 123456789RotatedRect cv::fitEllipse( InputArray points)参数points是轮廓点，输出RotatedRect包含下面三个信息- 拟合之后圆或者椭圆的中心位置、- 长轴与短轴的直径- 角度然后我们就可以根据得到拟合信息绘制椭圆、当长轴与短轴相等的时候就是圆。 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 二值图像分析(对轮廓圆与椭圆拟合) */int main() &#123; Mat src = imread("../images/stuff.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 去噪声与二值化 Mat dst, gray, binary; Canny(src, binary, 80, 160); Mat k = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1)); dilate(binary, binary, k); // 轮廓发现与绘制 vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(binary, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point()); for (size_t t = 0; t &lt; contours.size(); t++) &#123; // 寻找适配圆 RotatedRect rrt = fitEllipse(contours[t]); ellipse(src, rrt, Scalar(0,0,255), 2); &#125; imshow("contours", src); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425262728293031323334import cv2 as cvimport numpy as npdef canny_demo(image): t = 80 canny_output = cv.Canny(image, t, t * 2) cv.imshow("canny_output", canny_output) cv.imwrite("D:/canny_output.png", canny_output) return canny_outputsrc = cv.imread("D:/images/stuff.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)binary = canny_demo(src)k = np.ones((3, 3), dtype=np.uint8)binary = cv.morphologyEx(binary, cv.MORPH_DILATE, k)# 轮廓发现out, contours, hierarchy = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)for c in range(len(contours)): # 椭圆拟合 (cx, cy), (a, b), angle = cv.fitEllipse(contours[c]) # 绘制椭圆 cv.ellipse(src, (np.int32(cx), np.int32(cy)), (np.int32(a/2), np.int32(b/2)), angle, 0, 360, (0, 0, 255), 2, 8, 0)# 显示cv.imshow("contours_analysis", src)cv.imwrite("D:/contours_analysis.png", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>二值图像分析(对轮廓圆与椭圆拟合)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-052-二值图像分析(使用几何矩计算轮廓中心与横纵比过滤)]]></title>
    <url>%2F2019%2F04%2F16%2Fopencv-052%2F</url>
    <content type="text"><![CDATA[知识点对图像二值图像的每个轮廓，可以计算轮廓几何矩，根据几何矩可以计算图像的中心位置，估计得到中心位置可以计算中心矩、然后再根据中心矩可以计算胡矩。 几何矩 API 123456Moments cv::moments( InputArray array, bool binaryImage = false)array是输入的图像轮廓点集合输出图像的几何矩。 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;int main() &#123; Mat src = imread("../images/stuff.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 去噪声与二值化 Mat dst, gray, binary; Canny(src, binary, 80, 160); Mat k = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1)); dilate(binary, binary, k); // 轮廓发现与绘制 vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(binary, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point()); for (size_t t = 0; t &lt; contours.size(); t++) &#123; // 最小外接轮廓 RotatedRect rrt = minAreaRect(contours[t]); float w = rrt.size.width; float h = rrt.size.height; Point2f pts[4]; rrt.points(pts); // 计算横纵比 float ratio = min(w,h) / max(w,h); Point2f cpt = rrt.center; circle(src, cpt, 2, Scalar(255,0,0), 2); if(ratio &gt; 0.9)&#123; circle(src, cpt, 2, Scalar(255,0,0), 2); // 绘制旋转矩形 for (int i = 0; i &lt; 4; i++) &#123; line(src, pts[i % 4], pts[(i + 1) % 4], Scalar(0, 0, 255), 2); &#125; &#125; if(ratio &lt; 0.5)&#123; circle(src, cpt, 2, Scalar(255,0,0), 2); // 绘制旋转矩形 for (int i = 0; i &lt; 4; i++) &#123; line(src, pts[i % 4], pts[(i + 1) % 4], Scalar(0, 255, 0), 2); &#125; &#125; &#125; imshow("contours", src); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import cv2 as cvimport numpy as npdef canny_demo(image): t = 80 canny_output = cv.Canny(image, t, t * 2) cv.imshow("canny_output", canny_output) cv.imwrite("D:/canny_output.png", canny_output) return canny_outputsrc = cv.imread("D:/images/stuff.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)binary = canny_demo(src)k = np.ones((3, 3), dtype=np.uint8)binary = cv.morphologyEx(binary, cv.MORPH_DILATE, k)# 轮廓发现out, contours, hierarchy = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)for c in range(len(contours)): rect = cv.minAreaRect(contours[c]) cx, cy = rect[0] ww, hh = rect[1] ratio = np.minimum(ww, hh) / np.maximum(ww, hh) print(ratio) mm = cv.moments(contours[c]) m00 = mm['m00'] m10 = mm['m10'] m01 = mm['m01'] cx = np.int(m10 / m00) cy = np.int(m01 / m00) box = cv.boxPoints(rect) box = np.int0(box) if ratio &gt; 0.9: cv.drawContours(src, [box], 0, (0, 0, 255), 2) cv.circle(src, (np.int32(cx), np.int32(cy)), 2, (255, 0, 0), 2, 8, 0) if ratio &lt; 0.5: cv.drawContours(src, [box], 0, (255, 0, 255), 2) cv.circle(src, (np.int32(cx), np.int32(cy)), 2, (0, 0, 255), 2, 8, 0)# 显示cv.imshow("contours_analysis", src)cv.imwrite("D:/contours_analysis.png", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>使用几何矩计算轮廓中心</tag>
        <tag>横纵比过滤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-053-二值图像分析(使用Hu矩实现轮廓匹配)]]></title>
    <url>%2F2019%2F04%2F16%2Fopencv-053%2F</url>
    <content type="text"><![CDATA[知识点对图像二值图像的每个轮廓，可以计算轮廓几何矩，根据几何矩可以计算图像的中心位置，估计得到中心位置可以计算中心矩、然后再根据中心矩可以计算胡矩。 OpenCV中可以通过如下的API一次计算出上述三种矩，API如下： 123456Moments cv::moments( InputArray array, bool binaryImage = false)array是输入的图像轮廓点集合输出的图像几何矩 根据几何矩输出结果可以计算胡矩，胡矩计算的API如下： 123456void cv::HuMoments( const Moments &amp; moments, double hu[7] )moments参数表示输入的图像矩hu[7]表示输出的胡矩七个值 然后我们可以使用hu矩作为输入，对轮廓进行匹配，进行轮廓外形匹配的API如下： 123456789101112double cv::matchShapes( InputArray contour1, InputArray contour2, int method, double parameter)contour1第一个轮廓点集合，或者灰度图像contour2第二个轮廓点集合，或者灰度图像method表示比较方法，最常见有CONTOURS_MATCH_I1CONTOURS_MATCH_I2CONTOURS_MATCH_I3 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;void contours_info(Mat &amp;image, vector&lt;vector&lt;Point&gt;&gt; &amp;pts);int main() &#123; Mat src = imread("../images/abc.png"); Mat src2 = imread("../images/a5.png"); if (src.empty() || src2.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); imshow("input1", src2); // 轮廓发现 vector&lt;vector&lt;Point&gt;&gt; contours1; vector&lt;vector&lt;Point&gt;&gt; contours2; contours_info(src, contours1); contours_info(src2, contours2); // 几何矩计算与hu矩计算 Moments mm2 = moments(contours2[0]); Mat hu2; HuMoments(mm2, hu2); // 轮廓匹配 for (size_t t = 0; t &lt; contours1.size(); ++t) &#123; Moments mm = moments(contours1[t]); Mat hu; HuMoments(mm, hu); double dist = matchShapes(hu, hu2, CONTOURS_MATCH_I1, 0); if (dist &lt; 1) &#123; drawContours(src, contours1, t, Scalar(0,0,255), 2); &#125; &#125; imshow("match_result", src); waitKey(0); return 0;&#125;void contours_info(Mat &amp;image, vector&lt;vector&lt;Point&gt;&gt; &amp;pts) &#123; Mat gray, binary; vector&lt;Vec4i&gt; hierarchy; cvtColor(image, gray, COLOR_BGR2GRAY); threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); findContours(binary, pts, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE);&#125; 123456789101112131415161718192021222324252627282930313233343536373839import cv2 as cvimport numpy as npdef contours_info(image): gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY) ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU) out, contours, hierarchy = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE) return contourssrc = cv.imread("D:/images/abc.png")cv.namedWindow("input1", cv.WINDOW_AUTOSIZE)cv.imshow("input1", src)src2 = cv.imread("D:/images/a5.png")cv.imshow("input2", src2)# 轮廓发现contours1 = contours_info(src)contours2 = contours_info(src2)# 几何矩计算与hu矩计算mm2 = cv.moments(contours2[0])hum2 = cv.HuMoments(mm2)# 轮廓匹配for c in range(len(contours1)): mm = cv.moments(contours1[c]) hum = cv.HuMoments(mm) dist = cv.matchShapes(hum, hum2, cv.CONTOURS_MATCH_I1, 0) if dist &lt; 1: cv.drawContours(src, contours1, c, (0, 0, 255), 2, 8) print("dist %f"%(dist))# 显示cv.imshow("contours_analysis", src)cv.imwrite("D:/contours_analysis.png", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>使用Hu矩实现轮廓匹配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-051-二值图像分析(使用轮廓逼近)]]></title>
    <url>%2F2019%2F04%2F16%2Fopencv-051%2F</url>
    <content type="text"><![CDATA[知识点对图像二值图像的每个轮廓，可以使用轮廓逼近，逼近每个轮廓的真实几何形状，从而通过轮廓逼近的输出结果判断一个对象是什么形状。 API 1234567891011void cv::approxPolyDP( InputArray curve, OutputArray approxCurve, double epsilon, bool closed )其中Curve表示轮廓曲线approxCurve 表示轮廓逼近输出的顶点数目epsilon 轮廓逼近的顶点距离真实轮廓曲线的最大距离，该值越小表示越逼近真实轮廓close 表示是否为闭合区域 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;int main() &#123; Mat src = imread("../images/contours.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 去噪声与二值化 Mat gray, binary; cvtColor(src, gray, COLOR_BGR2GRAY); threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); // 轮廓发现与绘制 vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(binary, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point()); Scalar color = Scalar(255, 0, 0); for (size_t t = 0; t &lt; contours.size(); ++t) &#123; RotatedRect rrt = minAreaRect(contours[t]); Point2f cpt = rrt.center; circle(src, cpt, 2, Scalar(0, 255, 0), 2); Mat result; approxPolyDP(contours[t], result, 4, true); if (result.rows == 6) &#123; putText(src, "poly", cpt, FONT_HERSHEY_SIMPLEX, .7, color); &#125; if (result.rows == 3) &#123; putText(src, "triangle", cpt, FONT_HERSHEY_SIMPLEX, .7, color); &#125; if (result.rows == 4) &#123; putText(src, "rectangle", cpt, FONT_HERSHEY_SIMPLEX, .7, color); &#125; if(result.rows &gt; 10) &#123; putText(src, "circle", cpt, FONT_HERSHEY_SIMPLEX, .7, color); &#125; &#125; imshow("contours", src); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/contours.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)# 轮廓发现out, contours, hierarchy = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)for c in range(len(contours)): rect = cv.minAreaRect(contours[c]) cx, cy = rect[0] result = cv.approxPolyDP(contours[c], 4, True) vertexes = result.shape[0] if vertexes == 3: cv.putText(src, "triangle", (np.int32(cx), np.int32(cy)), cv.FONT_HERSHEY_SIMPLEX, .7, (0, 0, 255), 2, 8); if vertexes == 4: cv.putText(src, "rectangle", (np.int32(cx), np.int32(cy)), cv.FONT_HERSHEY_SIMPLEX, .7, (0, 0, 255), 2, 8); if vertexes == 6: cv.putText(src, "poly", (np.int32(cx), np.int32(cy)), cv.FONT_HERSHEY_SIMPLEX, .7, (0, 0, 255), 2, 8); if vertexes &gt; 10: cv.putText(src, "circle", (np.int32(cx), np.int32(cy)), cv.FONT_HERSHEY_SIMPLEX, .7, (0, 0, 255), 2, 8); print(vertexes)# 显示cv.imshow("contours_analysis", src)cv.imwrite("D:/contours_analysis.png", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>二值图像分析(使用轮廓逼近)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用keras实现一个多输入多输出的网络]]></title>
    <url>%2F2019%2F04%2F16%2Fkeras_multiple_input_output%2F</url>
    <content type="text"><![CDATA[结构图 代码12345678910111213141516171819import kerasfrom keras.layers import Input, Densefrom keras.models import Modelinput1 = Input(shape=(784,), name="input1")input2 = Input(shape=(10,), name="input2")hidden = Dense(1, activation='relu')(input1)output1 = Dense(10, activation='relu', name="output1")(hidden)hidden_input2 = keras.layers.concatenate([hidden, input2])output2 = Dense(10, activation='relu', name="output2")(hidden_input2)model = Model(inputs=[input1, input2], outputs=[output1, output2])model.compile(loss=&#123;'output1': ... , 'output2': ...&#125;, optimizer=..., loss_weights= [1, 0.4], metrics=['accuracy'])model.fit([train_X1, train_X2], [train_y1, train_y2], batch_size=None, epochs=1, validation_data=([test_X1, test_X2], [test_y1, test_y2]))]]></content>
      <categories>
        <category>ML/DL</category>
      </categories>
      <tags>
        <tag>keras</tag>
        <tag>多输入多输出的网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用keras实现Inception结构]]></title>
    <url>%2F2019%2F04%2F16%2Fkeras_inception%2F</url>
    <content type="text"><![CDATA[Inception结构 代码12345678910111213141516171819202122232425262728import kerasfrom keras.layers import Input, Conv2D, MaxPooling2Dfrom keras.models import Model# 定义输入图像尺寸inputs = Input(shape=(256, 256, 3))# 定义第一个分支tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)# 定义第二个分支tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)tower_2 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_2)# 定义第三个分支tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)tower_3 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_3)# 定义第四个分支tower_4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(inputs)tower_4 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_4)output = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4], axis=1)model = Model(inputs=inputs, outputs=output)model.compile(...)model.fit(...)]]></content>
      <categories>
        <category>ML/DL</category>
      </categories>
      <tags>
        <tag>keras</tag>
        <tag>Inception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-048-二值图像分析之轮廓发现]]></title>
    <url>%2F2019%2F04%2F15%2Fopencv-048%2F</url>
    <content type="text"><![CDATA[知识点图像连通组件分析，可以得到二值图像的每个连通组件，但是我们还无法得知各个组件之间的层次关系与几何拓扑关系，如果我们需要进一步分析图像轮廓拓扑信息就可以通过OpenCV的轮廓发现API获取二值图像的轮廓拓扑信息. 轮廓发现API 1234567891011121314151617void cv::findContours( InputOutputArray image, OutputArrayOfArrays contours, OutputArray hierarchy, int mode, int method, Point offset = Point() )各个参数详解如下：Image表示输入图像，必须是二值图像，二值图像可以threshold输出、Canny输出、inRange输出、自适应阈值输出等。Contours获取的轮廓，每个轮廓是一系列的点集合Hierarchy轮廓的层次信息，每个轮廓有四个相关信息，分别是同层下一个、前一个、第一个子节点、父节点mode 表示轮廓寻找时候的拓扑结构返回-RETR_EXTERNAL表示只返回最外层轮廓-RETR_TREE表示返回轮廓树结构Method表示轮廓点集合取得是基于什么算法，常见的是基于CHAIN_APPROX_SIMPLE链式编码方法 绘制轮廓API 12345678910111213void cv::drawContours( InputOutputArray image, InputArrayOfArrays contours, int contourIdx, const Scalar &amp; color, int thickness = 1, int lineType = LINE_8, InputArray hierarchy = noArray(), int maxLevel = INT_MAX, Point offset = Point() )当thickness为正数的时候表示绘制该轮廓当thickness为-1表示填充该轮廓 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 二值图像分析之轮廓发现 */int main() &#123; Mat src1 = imread("../images/master.jpg"); Mat src2 = imread("../images/coins.jpg"); if (src1.empty() || src2.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; //imshow("input_1", src1); imshow("input_2", src2); // 去噪声与二值化 Mat dst, gray, binary; GaussianBlur(src2, dst, Size(3, 3), 0, 0); cvtColor(dst, gray, COLOR_BGR2GRAY); threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); imshow("binary", binary); // 轮廓发现与绘制 vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(binary, contours, hierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE, Point()); for (auto t = 0; t &lt; contours.size(); ++t) &#123; drawContours(src2, contours, t, Scalar(0,0,255), 2, 8); &#125; imshow("contours", src2); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435import cv2 as cvimport numpy as npdef threshold_demo(image): # 去噪声+二值化 dst = cv.GaussianBlur(image,(3, 3), 0) gray = cv.cvtColor(dst, cv.COLOR_BGR2GRAY) ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_OTSU | cv.THRESH_BINARY) cv.imshow("binary", binary) return binarydef canny_demo(image): t = 100 canny_output = cv.Canny(image, t, t * 2) cv.imshow("canny_output", canny_output) return canny_outputsrc = cv.imread("D:/images/yuan_test.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)binary = threshold_demo(src)# 轮廓发现out, contours, hierarchy = cv.findContours(binary, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)for c in range(len(contours)): cv.drawContours(src, contours, c, (0, 0, 255), 2, 8)# 显示cv.imshow("contours-demo", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>二值图像分析之轮廓发现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-050-二值图像分析(矩形面积与弧长)]]></title>
    <url>%2F2019%2F04%2F15%2Fopencv-050%2F</url>
    <content type="text"><![CDATA[知识点对图像二值图像的每个轮廓，我们可以计算轮廓的弧长与面积，根据轮廓的面积与弧长可以实现对不同大小对象的过滤，寻找到我们感兴趣的roi区域，这个也是图像二值分析的任务之一。 OpenCV对轮廓点集计算面积的API函数如下: 12345678double cv::contourArea( InputArray contour, bool oriented = false)计算轮廓的面积，其原理是基于格林公式。参数contour表示输入的轮廓点集参数oriented默认是false返回的面积是正数，如果方向参数为true表示会根据是顺时针或者逆时针方向返回正值或者负值面积。 OpenCV对轮廓点集计算弧长的API函数如下: 1234567double cv::arcLength( InputArray curve, bool closed )参数curve表示输入的轮廓点集参数closed默认表示是否闭合区域 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 二值图像分析(矩形面积与弧长) */int main() &#123; Mat src = imread("../images/zhifang_ball.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 提取边缘 Mat binary; Canny(src, binary, 80, 160); imshow("binary", binary); // 膨胀 Mat k = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1)); dilate(binary, binary, k); // 轮廓发现于绘制 vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(binary, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point()); for (size_t t = 0; t &lt; contours.size(); ++t) &#123; // 最大外接矩形 // Rect rect = boundingRect(contours[t]); // rectangle(src, rect, Scalar(0, 0, 255)); // 面积与弧长过滤 double area = contourArea(contours[t]); double curvelen = arcLength(contours[t], true); if (area &lt; 100 || curvelen &lt; 100)&#123; continue; &#125; // 最小外接矩形 RotatedRect rrt = minAreaRect(contours[t]); Point2f pts[4]; rrt.points(pts); // 绘制旋转矩形与中心位置 for (int i = 0; i &lt; 4; ++i) &#123; line(src, pts[i % 4], pts[(i + 1) % 4], Scalar(0, 255, 0), 2); &#125; Point2f cpt = rrt.center; circle(src, cpt, 2, Scalar(255, 0, 0), 2); &#125; imshow("contours", src); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142import cv2 as cvimport numpy as npdef canny_demo(image): t = 80 canny_output = cv.Canny(image, t, t * 2) cv.imshow("canny_output", canny_output) cv.imwrite("D:/canny_output.png", canny_output) return canny_outputsrc = cv.imread("D:/images/zhifang_ball.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)binary = canny_demo(src)k = np.ones((3, 3), dtype=np.uint8)binary = cv.morphologyEx(binary, cv.MORPH_DILATE, k)# 轮廓发现out, contours, hierarchy = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)for c in range(len(contours)): # x, y, w, h = cv.boundingRect(contours[c]); # cv.drawContours(src, contours, c, (0, 0, 255), 2, 8) # cv.rectangle(src, (x, y), (x+w, y+h), (0, 0, 255), 1, 8, 0); area = cv.contourArea(contours[c]) arclen = cv.arcLength(contours[c], True) if area &lt; 100 or arclen &lt; 100: continue rect = cv.minAreaRect(contours[c]) cx, cy = rect[0] box = cv.boxPoints(rect) box = np.int0(box) cv.drawContours(src,[box],0,(0,0,255),2) cv.circle(src, (np.int32(cx), np.int32(cy)), 2, (255, 0, 0), 2, 8, 0)# 显示cv.imshow("contours_analysis", src)cv.imwrite("D:/contours_analysis.png", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>二值图像分析(矩形面积与弧长)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-049-二值图像分析(轮廓外接矩形)]]></title>
    <url>%2F2019%2F04%2F15%2Fopencv-049%2F</url>
    <content type="text"><![CDATA[知识点对图像二值图像的每个轮廓，OpenCV都提供了API可以求取轮廓的外接矩形. 求取轮廓外接矩形有两种方式，一种是可以基于像素的最大外接轮廓矩形，API解释如下： 123456Rect cv::boundingRect( InputArray points)输入参数points可以一系列点的集合，对轮廓来说就是该轮廓的点集返回结果是一个矩形，x, y, w, h 另一种是可以基于像素的最大外接轮廓矩形，API解释如下： 123456789RotatedRect cv::minAreaRect( InputArray points)输入参数points可以一系列点的集合，对轮廓来说就是该轮廓的点集返回结果是一个旋转矩形，包含下面的信息：-矩形中心位置-矩形的宽高-旋转角度 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;int main() &#123; Mat src = imread("../images/stuff.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 提取边缘 Mat binary; Canny(src, binary, 80, 160); imshow("binary", binary); // 膨胀 Mat k = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1)); dilate(binary, binary, k); // 轮廓发现于绘制 vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(binary, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point()); for (size_t t = 0; t &lt; contours.size(); ++t) &#123; // 最大外接矩形 Rect rect = boundingRect(contours[t]); rectangle(src, rect, Scalar(0, 0, 255)); // 最小外接矩形 RotatedRect rrt = minAreaRect(contours[t]); Point2f pts[4]; rrt.points(pts); // 绘制旋转矩形与中心位置 for (int i = 0; i &lt; 4; ++i) &#123; line(src, pts[i % 4], pts[(i + 1) % 4], Scalar(0, 255, 0), 2); &#125; Point2f cpt = rrt.center; circle(src, cpt, 2, Scalar(255, 0, 0), 2); &#125; imshow("contours", src); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738import cv2 as cvimport numpy as npdef canny_demo(image): t = 80 canny_output = cv.Canny(image, t, t * 2) cv.imshow("canny_output", canny_output) cv.imwrite("D:/canny_output.png", canny_output) return canny_outputsrc = cv.imread("D:/images/stuff.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)binary = canny_demo(src)k = np.ones((3, 3), dtype=np.uint8)binary = cv.morphologyEx(binary, cv.MORPH_DILATE, k)# 轮廓发现out, contours, hierarchy = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)for c in range(len(contours)): x, y, w, h = cv.boundingRect(contours[c]); cv.drawContours(src, contours, c, (0, 0, 255), 2, 8) cv.rectangle(src, (x, y), (x+w, y+h), (0, 0, 255), 1, 8, 0); rect = cv.minAreaRect(contours[c]) cx, cy = rect[0] box = cv.boxPoints(rect) box = np.int0(box) cv.drawContours(src,[box],0,(0,0,255),2) cv.circle(src, (np.int32(cx), np.int32(cy)), 2, (255, 0, 0), 2, 8, 0)# 显示cv.imshow("contours_analysis", src)cv.imwrite("D:/contours_analysis.png", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>二值图像分析(轮廓外接矩形)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-047-二值图像连通组件状态统计]]></title>
    <url>%2F2019%2F04%2F15%2Fopencv-047%2F</url>
    <content type="text"><![CDATA[知识点OpenCV中的连通组件标记算法有两个相关的API： 123456789101112131415161718192021222324252627282930313233343536373839一个是不带统计信息的API int cv::connectedComponents( InputArray image, // 输入二值图像，黑色背景 OutputArray labels, // 输出的标记图像，背景index=0 int connectivity = 8, // 连通域，默认是8连通 int ltype = CV_32S // 输出的labels类型，默认是CV_32S)另外一个是会输出连通组件统计信息的相关API，int cv::connectedComponentsWithStats( InputArray image, OutputArray labels, OutputArray stats, OutputArray centroids, int connectivity, int ltype, int ccltype )相关的统计信息包括在输出stats的对象中，每个连通组件有一个这样的输出结构体。CC_STAT_LEFT Python: cv.CC_STAT_LEFT连通组件外接矩形左上角坐标的X位置信息CC_STAT_TOP Python: cv.CC_STAT_TOP连通组件外接左上角坐标的Y位置信息CC_STAT_WIDTH Python: cv.CC_STAT_WIDTH连通组件外接矩形宽度CC_STAT_HEIGHT Python: cv.CC_STAT_HEIGHT连通组件外接矩形高度CC_STAT_AREA Python: cv.CC_STAT_AREA连通组件的面积大小，基于像素多少统计。Centroids输出的是每个连通组件的中心位置坐标(x, y) 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;RNG rng(12345);void componentwithstats_demo(Mat &amp;image);/* * 二值图像连通组件状态统计 */int main() &#123; Mat src = imread("../images/rice.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); componentwithstats_demo(src); waitKey(0); return 0;&#125;void componentwithstats_demo(Mat &amp;image) &#123; // extract labels Mat gray, binary; GaussianBlur(image, image, Size(3, 3), 0); cvtColor(image, gray, COLOR_BGR2GRAY); threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); Mat labels = Mat::zeros(image.size(), CV_32S); Mat stats, centroids; int num_labels = connectedComponentsWithStats(binary, labels, stats, centroids, 8, 4); cout &lt;&lt; "total labels : " &lt;&lt; num_labels - 1 &lt;&lt; endl; vector&lt;Vec3b&gt; colors(num_labels); // 背景颜色 colors[0] = Vec3b(0, 0, 0); // 目标颜色 for (int i = 1; i &lt; num_labels; ++i) &#123; colors[i] = Vec3b(rng.uniform(0, 256), rng.uniform(0, 256), rng.uniform(0, 256)); &#125; // 抽取统计信息 Mat dst = image.clone(); for (int i = 1; i &lt; num_labels; ++i) &#123; // 中心位置 int cx = centroids.at&lt;double&gt;(i, 0); int cy = centroids.at&lt;double&gt;(i, 1); // 统计信息 int x = stats.at&lt;int&gt;(i, CC_STAT_LEFT); int y = stats.at&lt;int&gt;(i, CC_STAT_TOP); int w = stats.at&lt;int&gt;(i, CC_STAT_WIDTH); int h = stats.at&lt;int&gt;(i, CC_STAT_HEIGHT); int area = stats.at&lt;int&gt;(i, CC_STAT_AREA); // 中心位置绘制 circle(dst, Point(cx, cy), 2, Scalar(0, 255, 0), 2); // 外接矩形 Rect rect(x, y, w, h); rectangle(dst, rect, colors[i]); putText(dst, format("num:%d", i), Point(x, y), FONT_HERSHEY_SIMPLEX, .5, Scalar(0, 0, 255), 1); printf("num : %d, rice area : %d\n", i, area); &#125; imshow("result", dst);&#125; 12345678910111213141516171819202122232425262728293031323334353637import cv2 as cvimport numpy as npdef connected_components_stats_demo(src): src = cv.GaussianBlur(src, (3, 3), 0) gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY) ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU) cv.imshow("binary", binary) num_labels, labels, stats, centers = cv.connectedComponentsWithStats(binary, connectivity=8, ltype=cv.CV_32S) colors = [] for i in range(num_labels): b = np.random.randint(0, 256) g = np.random.randint(0, 256) r = np.random.randint(0, 256) colors.append((b, g, r)) colors[0] = (0, 0, 0) image = np.copy(src) for t in range(1, num_labels, 1): x, y, w, h, area = stats[t] cx, cy = centers[t] cv.circle(image, (np.int32(cx), np.int32(cy)), 2, (0, 255, 0), 2, 8, 0) cv.rectangle(image, (x, y), (x+w, y+h), colors[t], 1, 8, 0) cv.putText(image, "num:" + str(t), (x, y), cv.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255), 1); print("label index %d, area of the label : %d"%(t, area)) cv.imshow("colored labels", image) cv.imwrite("D:/labels.png", image) print("total rice : ", num_labels - 1)input = cv.imread("D:/images/rice.png")connected_components_stats_demo(input)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>二值图像连通组件状态统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-046-二值图像的联通组件寻找]]></title>
    <url>%2F2019%2F04%2F14%2Fopencv-046%2F</url>
    <content type="text"><![CDATA[知识点 连通组件标记算法介绍连接组件标记算法(connected component labeling algorithm)是图像分析中最常用的算法之一，算法的实质是扫描二值图像的每个像素点，对于像素值相同的而且相互连通分为相同的组(group),最终得到图像中所有的像素连通组件。扫描的方式可以是从上到下，从左到右，对于一幅有N个像素的图像来说，最大连通组件个数为N/2。扫描是基于每个像素单位，OpenCV中进行连通组件扫码调用的时候必须保证背景像素是黑色、前景像素是白色。最常见的连通组件扫码有如下两类算法： 一步法，基于图的搜索算法 两步法、基于扫描与等价类合并算法 API 123456int cv::connectedComponents( InputArray image, // 输入二值图像，黑色背景 OutputArray labels, // 输出的标记图像，背景index=0 int connectivity = 8, // 连通域，默认是8连通 int ltype = CV_32S // 输出的labels类型，默认是CV_32S) 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;RNG rng(12345);void connected_component_demo(Mat &amp;image);/* * 二值图像的连通组件标记 */int main() &#123; Mat src = imread("../images/rice.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); connected_component_demo(src); waitKey(0); return 0;&#125;void connected_component_demo(Mat &amp;image) &#123; // extract labels Mat gray, binary; GaussianBlur(image, image, Size(3, 3), 0); cvtColor(image, gray, COLOR_BGR2GRAY); threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); Mat labels = Mat::zeros(image.size(), CV_32S); int num_labels = connectedComponents(binary, labels, 8, CV_32S); cout &lt;&lt; "total labels : " &lt;&lt; num_labels - 1 &lt;&lt; endl; vector&lt;Vec3b&gt; colors(num_labels); // 背景颜色 colors[0] = Vec3b(0, 0, 0); // 目标颜色 for (int i = 1; i &lt; num_labels; ++i) &#123; colors[i] = Vec3b(rng.uniform(0, 256), rng.uniform(0, 256), rng.uniform(0, 256)); &#125; // 给结果着色 Mat dst = Mat::zeros(image.size(), image.type()); for (int row = 0; row &lt; image.rows; ++row) &#123; for (int col = 0; col &lt; image.cols; ++col) &#123; int label = labels.at&lt;int&gt;(row, col); if (label == 0) continue; dst.at&lt;Vec3b&gt;(row, col) = colors[label]; &#125; &#125; imshow("result", dst);&#125; 12345678910111213141516171819202122232425262728293031323334353637import cv2 as cvimport numpy as npdef connected_components_demo(src): src = cv.GaussianBlur(src, (3, 3), 0) gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY) ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU) cv.imshow("binary", binary) output = cv.connectedComponents(binary, connectivity=8, ltype=cv.CV_32S) num_labels = output[0] labels = output[1] colors = [] for i in range(num_labels): b = np.random.randint(0, 256) g = np.random.randint(0, 256) r = np.random.randint(0, 256) colors.append((b, g, r)) colors[0] = (0, 0, 0) h, w = gray.shape image = np.zeros((h, w, 3), dtype=np.uint8) for row in range(h): for col in range(w): image[row, col] = colors[labels[row, col]] cv.imshow("colored labels", image) cv.imwrite("D:/labels.png", image) print("total rice : ", num_labels - 1)src = cv.imread("D:/images/rice.png")h, w = src.shape[:2]connected_components_demo(src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>连通组件标记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-045-图像二值化与去噪]]></title>
    <url>%2F2019%2F04%2F14%2Fopencv-045%2F</url>
    <content type="text"><![CDATA[知识点对于一张需要二值化的图像，我们有两种选择：选择一直接对输入图像转换为灰度图像，然后二值化选择二首先对输入图像进行降噪，去除噪声干扰，然后再二值化 在进行去噪声的时候，可以选择的有： 均值模糊去噪声 高斯模糊去噪声 双边/均值迁移模糊去噪声 非局部均值去噪声 下面以三种方式进行实验， 第一张图是输入图像直接转换为二值图像 第二张图是输入图像先高斯模糊去噪声，然后二值化图像 第三张图是输入图像先均值迁移去噪声，然后二值化的图像 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像二值化与去噪 */int main() &#123; Mat src = imread("../images/coins.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat gray, blurred, binary; // 直接二值化 cvtColor(src, gray, COLOR_BGR2GRAY); threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); imshow("binary_direct", binary); // 先高斯模糊，再二值化 GaussianBlur(src, blurred, Size(3,3), 0, 0); cvtColor(blurred, gray, COLOR_BGR2GRAY); threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); imshow("binary_gaussian", binary); // 先均值迁移模糊，再二值化 pyrMeanShiftFiltering(src, blurred, 10, 100); cvtColor(blurred, gray, COLOR_BGR2GRAY); threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); imshow("binary_pyrmean", binary); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738import cv2 as cvimport numpy as npdef method_1(image): gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY) t, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU) return binarydef method_2(image): blurred = cv.GaussianBlur(image, (3, 3), 0) gray = cv.cvtColor(blurred, cv.COLOR_BGR2GRAY) t, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU) return binarydef method_3(image): blurred = cv.pyrMeanShiftFiltering(image, 10, 100) gray = cv.cvtColor(blurred, cv.COLOR_BGR2GRAY) t, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU) return binarysrc = cv.imread("D:/images/coins.jpg")h, w = src.shape[:2]ret = method_3(src)result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = cv.cvtColor(ret, cv.COLOR_GRAY2BGR)cv.putText(result, "input", (10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.putText(result, "binary", (w+10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.imshow("result", result)cv.imwrite("D:/binary_result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像二值化与去噪</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-044-图像二化自适应阈值算法]]></title>
    <url>%2F2019%2F04%2F14%2Fopencv-044%2F</url>
    <content type="text"><![CDATA[知识点OpenCV中的自适应阈值算法主要是基于均值实现，根据计算均值的方法不同分为盒子模糊均值与高斯模糊均值，然后使用原图减去均值图像，得到的差值图像进行自适应分割. 1234567891011121314151617181920void cv::adaptiveThreshold( InputArray src, OutputArray dst, double maxValue, int adaptiveMethod, int thresholdType, int blockSize, double C)其中blockSize取值必须是奇数，C取值在10左右自适应方法类型：ADAPTIVE_THRESH_GAUSSIAN_C = 1ADAPTIVE_THRESH_MEAN_C = 0当阈值操作类型thresholdType为：THRESH_BINARY二值图像 = 原图 – 均值图像 &gt; -C ? 255 : 0当阈值操作类型thresholdType为：THRESH_BINARY_INV二值图像 = 原图 – 均s值图像 &gt; -C ? 0 : 255 代码（c++,python）1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 自动阈值寻找与二值化 */int main() &#123; Mat src = imread("../images/text1.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 自动阈值寻找与二值化 Mat gray, binary1, binary2; cvtColor(src, gray, COLOR_BGR2GRAY); // int T = mean(src)[0]; // threshold(gray, binary1, T, 255, THRESH_BINARY); adaptiveThreshold(gray, binary2, 255, ADAPTIVE_THRESH_GAUSSIAN_C, THRESH_BINARY, 25, 10); // imshow("binary_T=mean", binary1); imshow("binary_adaptive", binary2); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425262728293031import cv2 as cvimport numpy as np## THRESH_BINARY = 0# THRESH_BINARY_INV = 1# THRESH_TRUNC = 2# THRESH_TOZERO = 3# THRESH_TOZERO_INV = 4#src = cv.imread("D:/images/text1.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w = src.shape[:2]# 自动阈值分割 TRIANGLEgray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)binary = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 25, 10)cv.imshow("binary", binary)result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = cv.cvtColor(binary, cv.COLOR_GRAY2BGR)cv.putText(result, "input", (10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.putText(result, "adaptive threshold", (w+10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.imshow("result", result)cv.imwrite("D:/binary_result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像二化自适应阈值算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-043-图像二值寻找算法(TRIANGLE)]]></title>
    <url>%2F2019%2F04%2F14%2Fopencv-043%2F</url>
    <content type="text"><![CDATA[知识点OpenCV中支持的有OTSU与Triangle两种直方图阈值寻找算法。OTSU基于类内最小方差实现阈值寻找, 它对有两个波峰之间有一个波谷的直方图特别好,但是有时候图像的直方图只有一个波峰,这个时候使用TRIANGLE方法寻找阈值是比较好的一个选择。 注意：两个波峰 –&gt; OTSU ， 一个波峰 –&gt; TRANGLE OpenCV中TRIANGLE算法使用只需要在threshold函数的type类型声明THRESH_TRIANGLE即可 代码（c++,python）1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像二值寻找算法 – TRIANGLE */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 自动阈值寻找与二值化 Mat gray, binary; cvtColor(src, gray, COLOR_BGR2GRAY); double T = threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_TRIANGLE); cout &lt;&lt; "threshold : " &lt;&lt; T &lt;&lt; endl; imshow("binary", binary); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425262728293031323334import cv2 as cvimport numpy as npimport tensorflow as tftf.enable_eager_execution()## THRESH_BINARY = 0# THRESH_BINARY_INV = 1# THRESH_TRUNC = 2# THRESH_TOZERO = 3# THRESH_TOZERO_INV = 4#src = cv.imread("D:/images/lena.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w = src.shape[:2]# 自动阈值分割 TRIANGLEgray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_TRIANGLE)print("ret :", ret)cv.imshow("binary", binary)result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = cv.cvtColor(binary, cv.COLOR_GRAY2BGR)cv.putText(result, "input", (10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.putText(result, "binary, threshold = " + str(ret), (w+10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.imshow("result", result)cv.imwrite("D:/binary_result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像二值寻找算法(TRIANGLE)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-042-图像二值寻找算法(OTSU)]]></title>
    <url>%2F2019%2F04%2F13%2Fopencv-042%2F</url>
    <content type="text"><![CDATA[知识点图像二值化，除了我们上次分享的手动阈值设置与根据灰度图像均值的方法之外，还有几个根据图像直方图实现自动全局阈值寻找的方法，OpenCV中支持的有OTSU与Triangle两种直方图阈值寻找算法。其中OTSU的是通过计算类间最大方差来确定分割阈值的阈值选择算法，OTSU算法对直方图有两个峰，中间有明显波谷的直方图对应图像二值化效果比较好，而对于只有一个单峰的直方图对应的图像分割效果没有双峰的好。 OpenCV中OTSU算法使用只需要在threshold函数的type类型声明THRESH_OTSU即可. 代码（c++,python）1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像二值寻找算法 – OTSU */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 自动阈值寻找与二值化 Mat gray, binary; cvtColor(src, gray, COLOR_BGR2GRAY); double T = threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU); cout &lt;&lt; "threshold : " &lt;&lt; T &lt;&lt; endl; imshow("binary", binary); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324252627282930import cv2 as cvimport numpy as np## THRESH_BINARY = 0# THRESH_BINARY_INV = 1# THRESH_TRUNC = 2# THRESH_TOZERO = 3# THRESH_TOZERO_INV = 4#src = cv.imread("D:/images/lena.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w = src.shape[:2]# 自动阈值分割 OTSUgray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)print("ret :", ret)cv.imshow("binary", binary)result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = cv.cvtColor(binary, cv.COLOR_GRAY2BGR)cv.putText(result, "input", (10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.putText(result, "binary, threshold = " + str(ret), (w+10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.imshow("result", result)cv.imwrite("D:/binary_result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像二值寻找算法(OTSU)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-041-基本阈值操作]]></title>
    <url>%2F2019%2F04%2F13%2Fopencv-041%2F</url>
    <content type="text"><![CDATA[知识点 API 12345678910111213double cv::threshold( InputArray src, OutputArray dst, double thresh, double maxval, int type)其中type表示阈值分割的方法，支持如下五种：THRESH_BINARY = 0 二值分割THRESH_BINARY_INV = 1 反向二值分割THRESH_TRUNC = 2 截断THRESH_TOZERO = 3 取零THRESH_TOZERO_INV = 4 反向取零 代码（c++,python）1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 基本阈值操作 */int main() &#123; Mat src = imread("../images/master.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); int T = mean(src)[0]; Mat gray, binary; cvtColor(src, gray, COLOR_BGR2GRAY); for (int i = 0; i &lt; 5; ++i) &#123;// THRESH_BINARY = 0// THRESH_BINARY_INV = 1// THRESH_TRUNC = 2// THRESH_TOZERO = 3// THRESH_TOZERO_INV = 4 threshold(gray, binary, T, 255, i); imshow(format("binary_%d", i), binary); &#125; waitKey(0); return 0;&#125; 1234567891011121314151617181920212223import cv2 as cvimport numpy as np## THRESH_BINARY = 0# THRESH_BINARY_INV = 1# THRESH_TRUNC = 2# THRESH_TOZERO = 3# THRESH_TOZERO_INV = 4#src = cv.imread("D:/images/master.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)T = 127# 转换为灰度图像gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)for i in range(5): ret, binary = cv.threshold(gray, T, 255, i) cv.imshow("binary_" + str(i), binary)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>基本阈值操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-039-图像模板匹配]]></title>
    <url>%2F2019%2F04%2F12%2Fopencv-039%2F</url>
    <content type="text"><![CDATA[知识点模板匹配被称为最简单的模式识别方法、同时也被很多人认为是最没有用的模式识别方法。这里里面有很大的误区，就是模板匹配是工作条件限制比较严格，只有满足理论设置的条件以后，模板匹配才会比较好的开始工作，而且它不是基于特征的匹配，所以有很多弊端，但是不妨碍它成为入门级别模式识别的方法，通过它可以学习到很多相关的原理性内容，为后续学习打下良好的基础。 API 123456789101112131415161718192021222324void cv::matchTemplate ( InputArray image, InputArray templ, OutputArray result, int method, InputArray mask = noArray() ) Python:result = cv.matchTemplate( image, templ, method[, result[, mask]] )其中method表示模板匹配时候采用的计算像素相似程度的方法，常见有如下TM_SQDIFF = 0TM_SQDIFF_NORMED = 1平方不同与平方不同的归一化版本TM_CCORR = 2TM_CCORR_NORMED = 3相关性，值越大相关性越强，表示匹配程度越高。归一化版本值在0～1之间，1表示高度匹配，0表示完全不匹配TM_CCOEFF = 4TM_CCOEFF_NORMED = 5相关因子，值越大相关性越强，表示匹配程度越高。归一化版本值在0～1之间，1表示高度匹配，0表示完全不匹配 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;const float t = 0.95;/* * 图像模板匹配 */int main() &#123; Mat src = imread("../images/llk.jpg"); Mat tpl = imread("../images/llk_tpl.png"); if (src.empty() || tpl.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); imshow("match_template", tpl); int res_h = src.rows - tpl.rows + 1; int res_w = src.cols - tpl.cols + 1; Mat result = Mat::zeros(Size(res_w, res_h), CV_32FC1); matchTemplate(src, tpl, result, TM_CCOEFF_NORMED); imshow("result", result); for (int row = 0; row &lt; result.rows; ++row) &#123; for (int col = 0; col &lt; result.cols; ++col) &#123; float v = result.at&lt;float&gt;(row, col); if (v &gt; t)&#123; rectangle(src, Point(col, row), Point(col + tpl.cols, row+tpl.rows), Scalar(255,0,0)); &#125; &#125; &#125; imshow("template_result", src); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425import cv2 as cvimport numpy as npdef template_demo(): src = cv.imread("D:/images/llk.jpg") tpl = cv.imread("D:/images/llk_tpl.png") cv.imshow("input", src) cv.imshow("tpl", tpl) th, tw = tpl.shape[:2] result = cv.matchTemplate(src, tpl, cv.TM_CCORR_NORMED) cv.imshow("result", result) cv.imwrite("D:/039_003.png", np.uint8(result*255)) t = 0.98 loc = np.where(result &gt; t) for pt in zip(*loc[::-1]): cv.rectangle(src, pt, (pt[0] + tw, pt[1] + th), (255, 0, 0), 1, 8, 0) cv.imshow("llk-demo", src) cv.imwrite("D:/039_004.png", src)template_demo()cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像模板匹配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-040-二值图像介绍]]></title>
    <url>%2F2019%2F04%2F12%2Fopencv-040%2F</url>
    <content type="text"><![CDATA[知识点 二值图像就是只有黑白两种颜色表示的图像，其中0 – 表示黑色， 1 – 表示白色(255) 。二值图像处理与分析在机器视觉与机器人视觉中非常重要，涉及到非常多的图像处理相关的知识，常见的二值图像分析包括轮廓分析、对象测量、轮廓匹配与识别、形态学处理与分割、各种形状检测与拟合、投影与逻辑操作、轮廓特征提取与编码等。此外图像二值化的方法也有很多，OpenCV主要是支持几种经典的二值化算法。 从编程与代码角度，OpenCV中二值图像单通道的、字节类型的Mat对象、对于任意的输入图像首先需要把图像转换为灰度、然后通过二值化方法转换为二值图像。本质上，从灰度到二值图像，是对数据的二分类分割，所以很多数据处理的方法都可以使用，但是图像是特殊类型的数据，它有很多限制条件，决定了只有一些合适的方法才会取得比较好的效果。这些算法的最主要的一个任务就是寻找合理的分割阈值T、对于给定任意一个像素点灰度值P(x, y) &gt; T ? 255 : 0 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 二值图像介绍 */int main() &#123; Mat src = imread("../images/master.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 转为灰度图像 Mat gray, binary; cvtColor(src, gray, COLOR_BGR2GRAY); int t = 127; Scalar m = mean(src); int t_mean = m[0]; // 转二值图像 binary = Mat::zeros(src.size(), CV_8UC1); for (int row = 0; row &lt; src.rows; ++row) &#123; for (int col = 0; col &lt; src.cols; ++col) &#123; int pv = gray.at&lt;uchar&gt;(row, col); pv &gt; t ? binary.at&lt;uchar&gt;(row, col) = 255 : binary.at&lt;uchar&gt;(row, col) = 0; &#125; &#125; imshow("binary_t=127", binary); //imshow("binary_t=mean", binary); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425262728import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/master.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)T = 127# 转换为灰度图像gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)h, w = gray.shapeT = cv.mean(gray)[0]print("current threshold value : ", T)# 二值图像binary = np.zeros((h, w), dtype=np.uint8)for row in range(h): for col in range(w): pv = gray[row, col] if pv &gt; T: binary[row, col] = 255 else: binary[row, col] = 0cv.imshow("binary", binary)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>二值图像介绍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-038-拉普拉斯金字塔]]></title>
    <url>%2F2019%2F04%2F11%2Fopencv-038%2F</url>
    <content type="text"><![CDATA[知识点对输入图像实现金字塔的reduce操作就会生成不同分辨率的图像、对这些图像进行金字塔expand操作，然后使用reduce减去expand之后的结果就会得到图像拉普拉斯金字塔图像。举例如下：输入图像G(0)金字塔reduce操作生成 G(1), G(2), G(3)拉普拉斯金字塔：L0 = G(0)-expand(G(1))L1 = G(1)-expand(G(2))L2 = G(2)–expand(G(3))G(0)减去expand(G(1))得到的结果就是两次高斯模糊输出的不同，所以L0称为DOG（高斯不同）、它约等于LOG所以又称为拉普拉斯金字塔。所以要求的图像的拉普拉斯金字塔，首先要进行金字塔的reduce操作，然后在通过expand操作，最后相减得到拉普拉斯金字塔图像。 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;void pyramid_up(Mat &amp;image, vector&lt;Mat&gt; &amp;pyramid_images, int level);void laplaian_demo(vector&lt;Mat&gt; &amp;pyramid_images, Mat &amp;image);/* * 拉普拉斯金字塔 */int main() &#123; Mat src = imread("../images/test1.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); vector&lt;Mat&gt; p_images; pyramid_up(src, p_images, 2); laplaian_demo(p_images, src); waitKey(0); return 0;&#125;void laplaian_demo(vector&lt;Mat&gt; &amp;pyramid_images, Mat &amp;image) &#123; for (int i = pyramid_images.size() - 1; i &gt; -1; --i) &#123; Mat dst; if (i - 1 &lt; 0) &#123; pyrUp(pyramid_images[i], dst, image.size()); subtract(image, dst, dst); dst = dst + Scalar(127, 127, 127);# 调亮度， 实际中不能这么用 imshow(format("laplaian_layer_%d", i), dst); &#125; else &#123; pyrUp(pyramid_images[i], dst, pyramid_images[i-1].size()); subtract(pyramid_images[i - 1], dst, dst); dst = dst + Scalar(127, 127, 127); imshow(format("laplaian_layer_%d", i), dst); &#125; &#125;&#125;void pyramid_up(Mat &amp;image, vector&lt;Mat&gt; &amp;pyramid_images, int level) &#123; Mat temp = image.clone(); Mat dst; for (int i = 0; i &lt; level; ++i) &#123; pyrDown(temp, dst); //imshow(format("pyramid_up_%d", i), dst); temp = dst.clone(); pyramid_images.push_back(temp); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839import cv2 as cvimport numpy as npdef laplaian_demo(pyramid_images): level = len(pyramid_images) for i in range(level-1, -1, -1): if (i-1) &lt; 0: h, w = src.shape[:2] expand = cv.pyrUp(pyramid_images[i], dstsize=(w, h)) lpls = cv.subtract(src, expand) + 127 cv.imshow("lpls_" + str(i), lpls) else: h, w = pyramid_images[i-1].shape[:2] expand = cv.pyrUp(pyramid_images[i], dstsize=(w, h)) lpls = cv.subtract(pyramid_images[i-1], expand) + 127 cv.imshow("lpls_"+str(i), lpls)def pyramid_up(image, level=3): temp = image.copy() # cv.imshow("input", image) pyramid_images = [] for i in range(level): dst = cv.pyrDown(temp) pyramid_images.append(dst) # cv.imshow("pyramid_up_" + str(i), dst) temp = dst.copy() return pyramid_imagessrc = cv.imread("D:/images/master.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)# pyramid_up(src)laplaian_demo(pyramid_up(src))cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>拉普拉斯金字塔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-037-图像金字塔]]></title>
    <url>%2F2019%2F04%2F11%2Fopencv-037%2F</url>
    <content type="text"><![CDATA[知识点图像金字塔是对一张输入图像先模糊再下采样为原来大小的1/4（宽高缩小一半）、不断重复模糊与下采样的过程就得到了不同分辨率的输出图像，叠加在一起就形成了图像金字塔、所以图像金字塔是图像的空间多分辨率存在形式。这里的模糊是指高斯模糊，所以这个方式生成的金字塔图像又称为高斯金字塔图像。高斯金字塔图像有两个基本操作： reduce 是从原图生成高斯金字塔图像、生成一系列低分辨图像 expand 是从高斯金字塔图像反向生成高分辨率图像 规则： 图像金字塔在redude过程或者expand过程中必须是逐层 reduce过程中每一层都是前一层的1/4 API reduce 操作 pyrDownexpand操作 pyrUp 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;void pyramid_up(Mat &amp;image, vector&lt;Mat&gt; &amp;pyramid_images, int level);void pyramid_down(vector&lt;Mat&gt; &amp;pyramid_images);int main() &#123; Mat src = imread("../images/test1.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); vector&lt;Mat&gt; p_images; pyramid_up(src, p_images, 2); pyramid_down(p_images); waitKey(0); return 0;&#125;void pyramid_down(vector&lt;Mat&gt; &amp;pyramid_images) &#123; for (int i = pyramid_images.size() - 1; i &gt; -1; --i) &#123; Mat dst; pyrUp(pyramid_images[i], dst); imshow(format("pyramid_down_%d", i), dst); &#125;&#125;void pyramid_up(Mat &amp;image, vector&lt;Mat&gt; &amp;pyramid_images, int level) &#123; Mat temp = image.clone(); Mat dst; for (int i = 0; i &lt; level; ++i) &#123; pyrDown(temp, dst); imshow(format("pyramid_up_%d", i), dst); temp = dst.clone(); pyramid_images.push_back(temp); &#125;&#125; 12345678910111213141516171819202122232425262728293031import cv2 as cvdef pyramid_down(pyramid_images): level = len(pyramid_images) print("level = ",level) for i in range(level-1, -1, -1): expand = cv.pyrUp(pyramid_images[i]) cv.imshow("pyramid_down_"+str(i), expand)def pyramid_up(image, level=3): temp = image.copy() # cv.imshow("input", image) pyramid_images = [] for i in range(level): dst = cv.pyrDown(temp) pyramid_images.append(dst) # cv.imshow("pyramid_up_" + str(i), dst) temp = dst.copy() return pyramid_imagessrc = cv.imread("D:/images/master.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)# pyramid_up(src)pyramid_down(pyramid_up(src))cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像金字塔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-036-Canny边缘检测器]]></title>
    <url>%2F2019%2F04%2F10%2Fopencv-036%2F</url>
    <content type="text"><![CDATA[知识点1986年，JOHN CANNY 提出一个很好的边缘检测算法，被称为Canny编边缘检测器。Canny边缘检测器是一种经典的图像边缘检测与提取算法，应用广泛，主要是因为Canny边缘检测具备以下特点： 有效的噪声抑制 更强的完整边缘提取能力 Canny算法是如何做到精准的边缘提取的，主要是靠下面五个步骤： 高斯模糊 – 抑制噪声 梯度提取得到边缘候选 角度计算与非最大信号抑制 高低阈值链接、获取完整边缘 输出边缘 API 123456789101112void cv::Canny( InputArray image, OutputArray edges, double threshold1, double threshold2, int apertureSize = 3, bool L2gradient = false)threshold1 是Canny边缘检测算法第四步中高低阈值链接中低阈值threshold2 是Canny边缘检测算法第四步中高低阈值链接中高阈值、高低阈值之比在2:1～3:1之间最后一个参数是计算gradient的方法L1或者L2 代码（c++,python）1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * Canny边缘检测器 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat edges, edges_src; Canny(src, edges, 100, 300); // 提取彩色边缘 bitwise_and(src, src, edges_src, edges); imshow("edges", edges); imshow("edges_src", edges_src); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/master.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)# t1 = 100, t2 = 3*t1 = 300edge = cv.Canny(src, 100, 300)cv.imshow("mask image", edge)cv.imwrite("D:/edge.png", edge)edge_src = cv.bitwise_and(src, src, mask=edge)h, w = src.shape[:2]result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = edge_srccv.putText(result, "original image", (10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.putText(result, "edge image", (w+10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.imshow("edge detector", result)cv.imwrite("D:/result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>Canny边缘检测器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-035-USM-锐化增强算法]]></title>
    <url>%2F2019%2F04%2F10%2Fopencv-035%2F</url>
    <content type="text"><![CDATA[知识点图像卷积处理实现锐化有一种常用的算法叫做Unsharpen Mask方法，这种锐化的方法就是对原图像先做一个高斯模糊，然后用原来的图像减去一个系数乘以高斯模糊之后的图像，然后再把值Scale到0～255的RGB像素值范围之内。基于USM锐化的方法可以去除一些细小的干扰细节和噪声，比一般直接使用卷积锐化算子得到的图像锐化结果更加真实可信。 USM锐化公式表示如下：（源图像– w*高斯模糊）/（1-w）；其中w表示权重（0.1～0.9），默认为0.6 OpenCV中的代码实现步骤 高斯模糊 权重叠加 输出结果 代码（c++,python）123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat blur_img, usm; GaussianBlur(src, blur_img, Size(0,0), 25); addWeighted(src, 1.5, blur_img, -0.5, 0, usm); imshow("usm", usm); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/master.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)# sigma = 5、15、25blur_img = cv.GaussianBlur(src, (0, 0), 5)usm = cv.addWeighted(src, 1.5, blur_img, -0.5, 0)cv.imshow("mask image", usm)h, w = src.shape[:2]result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = usmcv.putText(result, "original image", (10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.putText(result, "sharpen image", (w+10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.imshow("sharpen_image", result)cv.imwrite("D:/result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>USM-锐化增强算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-034-图像锐化]]></title>
    <url>%2F2019%2F04%2F09%2Fopencv-034%2F</url>
    <content type="text"><![CDATA[知识点图像卷积的主要有三功能分别是图像的模糊/去噪、图像梯度/边缘发现、图像锐化/增强，前面的两个功能我们以前通过相关知识点的分享加以了解，学习了相关API的使用。图像锐化的本质是图像拉普拉斯滤波加原图权重像素叠加的输出 ： 123-1 -1 -1-1 C -1-1 -1 -1 当C值大于8时候表示图像锐化、越接近8表示锐化效果越好 当C值等于8时候图像的高通滤波 当C值越大，图像锐化效果在减弱、中心像素的作用在提升 代码（c++,python）123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像锐化 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat sharpen_op = (Mat_&lt;char&gt;(3,3) &lt;&lt; -1, -1, -1, -1, 9, -1, -1, -1, -1); // Mat sharpen_op1 = (Mat_&lt;char&gt;(3,3) &lt;&lt; 0, -1, 0, // -1, 9, -1, // 0, -1, 0); Mat dst; filter2D(src, dst, CV_32F, sharpen_op); convertScaleAbs(dst, dst); imshow("sharpen", dst); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/test.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)# sharpen_op = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]], dtype=np.float32)sharpen_op = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)sharpen_image = cv.filter2D(src, cv.CV_32F, sharpen_op)sharpen_image = cv.convertScaleAbs(sharpen_image)cv.imshow("sharpen_image", sharpen_image)h, w = src.shape[:2]result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = sharpen_imagecv.putText(result, "original image", (10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.putText(result, "sharpen image", (w+10, 30), cv.FONT_ITALIC, 1.0, (0, 0, 255), 2)cv.imshow("sharpen_image", result)cv.imwrite("D:/result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像锐化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-033-图像梯度之拉普拉斯算子(二阶导数算子)]]></title>
    <url>%2F2019%2F04%2F09%2Fopencv-033%2F</url>
    <content type="text"><![CDATA[知识点图像的一阶导数算子可以得到图像梯度局部梯度相应值，二阶导数可以通过快速的图像像素值强度的变化来检测图像边缘，其检测图像边缘的原理跟图像的一阶导数有点类似，只是在二阶导数是求X、Y方向的二阶偏导数，对图像来说： X方向的二阶偏导数就是 dx = f(x+1, y) + f(x-1, y) – 2*f(x, y) Y方向的二阶偏导数就是 dy = f(x, y+1) + f(x, y-1) – 2*f(x, y) 对X方向与Y方向进行叠加最终就得到delta对应的二阶导数算子。 API 12345678910111213// OpenCV中Laplacian滤波函数就是二阶导数发现边缘的函数void cv::Laplacian( InputArray src, OutputArray dst, int ddepth, // 深度默认是-1表示输入与输出图像相同 int ksize = 1,// 必须是奇数， 等于1是四邻域算子，大于1改用八邻域算子 double scale = 1, double delta = 0, // 对输出图像加上常量值 int borderType = BORDER_DEFAULT ) Python:dst = cv.Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]] ) 代码（c++,python）12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 拉普拉斯算子(二阶导数算子) */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat blured, dst; GaussianBlur(src, blured, Size(3,3), 0); Laplacian(blured, dst, CV_32F, 1, 1.0, 127.0); convertScaleAbs(dst, dst); imshow("Laplacian", dst); waitKey(0); return 0;&#125; 1234567891011121314151617181920import cv2 as cvimport numpy as npimage = cv.imread("D:/images/yuan_test.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", image)h, w = image.shape[:2]src = cv.GaussianBlur(image, (0, 0), 1)dst = cv.Laplacian(src, cv.CV_32F, ksize=3, delta=127)dst = cv.convertScaleAbs(dst)result = np.zeros([h, w*2, 3], dtype=image.dtype)result[0:h,0:w,:] = imageresult[0:h,w:2*w,:] = dstcv.imshow("result", result)cv.imwrite("D:/laplacian_08.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>拉普拉斯算子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-032-图像梯度之robert算子与prewitt算子]]></title>
    <url>%2F2019%2F04%2F09%2Fopencv-032%2F</url>
    <content type="text"><![CDATA[知识点图像的一阶导数算子除了sobel算子之外，常见的还有robert算子与prewitt算子，它们也都是非常好的可以检测图像的梯度边缘信息，通过OpenCV中自定义滤波器，使用自定义创建的robert与prewitt算子就可以实现图像的rober与prewitt梯度边缘检测。 API 123456789101112filter2D( InputArray src, OutputArray dst, int ddepth, InputArray kernel, Point anchor = Point(-1,-1), double delta = 0, int borderType = BORDER_DEFAULT )Python:dst =cv.filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // Robert算子 Mat robert_x = (Mat_&lt;int&gt;(2, 2) &lt;&lt; 1, 0, 0, -1); Mat robert_y = (Mat_&lt;int&gt;(2, 2) &lt;&lt; 0, -1, 1, 0); Mat robert_grad_x, robert_grad_y, robert_grad; filter2D(src, robert_grad_x, CV_16S, robert_x); filter2D(src, robert_grad_y, CV_16S, robert_y); convertScaleAbs(robert_grad_x, robert_grad_x); convertScaleAbs(robert_grad_y, robert_grad_y); add(robert_grad_x, robert_grad_y, robert_grad); convertScaleAbs(robert_grad, robert_grad); imshow("robert_grad_x", robert_grad_x); imshow("robert_grad_y", robert_grad_y); imshow("robert_grad", robert_grad); // 定义Prewitt算子 Mat prewitt_x = (Mat_&lt;char&gt;(3, 3) &lt;&lt; -1, 0, 1, -1, 0, 1, -1, 0, 1); Mat prewitt_y = (Mat_&lt;char&gt;(3, 3) &lt;&lt; -1, -1, -1, 0, 0, 0, 1, 1, 1); Mat prewitt_grad_x, prewitt_grad_y, prewitt_grad; filter2D(src, prewitt_grad_x, CV_32F, prewitt_x); filter2D(src, prewitt_grad_y, CV_32F, prewitt_y); convertScaleAbs(prewitt_grad_x, prewitt_grad_x); convertScaleAbs(prewitt_grad_y, prewitt_grad_y); add(prewitt_grad_x, prewitt_grad_y, prewitt_grad); convertScaleAbs(prewitt_grad, prewitt_grad); imshow("prewitt_grad_x", prewitt_grad_x); imshow("prewitt_grad_y", prewitt_grad_y); imshow("prewitt_grad", prewitt_grad); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/test.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)robert_x = np.array([[1, 0],[0, -1]], dtype=np.float32)robert_y = np.array([[0, -1],[1, 0]], dtype=np.float32)prewitt_x = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=np.float32)prewitt_y = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]], dtype=np.float32)robert_grad_x = cv.filter2D(src, cv.CV_16S, robert_x)robert_grad_y = cv.filter2D(src, cv.CV_16S, robert_y)robert_grad_x = cv.convertScaleAbs(robert_grad_x)robert_grad_y = cv.convertScaleAbs(robert_grad_y)prewitt_grad_x = cv.filter2D(src, cv.CV_32F, prewitt_x)prewitt_grad_y = cv.filter2D(src, cv.CV_32F, prewitt_y)prewitt_grad_x = cv.convertScaleAbs(prewitt_grad_x)prewitt_grad_y = cv.convertScaleAbs(prewitt_grad_y)# cv.imshow("robert x", robert_grad_x);# cv.imshow("robert y", robert_grad_y);# cv.imshow("prewitt x", prewitt_grad_x);# cv.imshow("prewitt y", prewitt_grad_y);h, w = src.shape[:2]robert_result = np.zeros([h, w*2, 3], dtype=src.dtype)robert_result[0:h,0:w,:] = robert_grad_xrobert_result[0:h,w:2*w,:] = robert_grad_ycv.imshow("robert_result", robert_result)prewitt_result = np.zeros([h, w*2, 3], dtype=src.dtype)prewitt_result[0:h,0:w,:] = prewitt_grad_xprewitt_result[0:h,w:2*w,:] = prewitt_grad_ycv.imshow("prewitt_result", prewitt_result)cv.imwrite("D:/prewitt.png", prewitt_result)cv.imwrite("D:/robert.png", robert_result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>robert算子</tag>
        <tag>prewitt算子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-031-图像梯度之Sobel算子]]></title>
    <url>%2F2019%2F04%2F09%2Fopencv-031%2F</url>
    <content type="text"><![CDATA[知识点卷积的作用除了实现图像模糊或者去噪，还可以寻找一张图像上所有梯度信息，这些梯度信息是图像的最原始特征数据，进一步处理之后就可以生成一些比较高级的特征用来表示一张图像实现基于图像特征的匹配，图像分类等应用。Sobel算子是一种很经典的图像梯度提取算子，其本质是基于图像空间域卷积，背后的思想是图像一阶导数算子的理论支持。 API 12345678910111213void cv::Sobel( InputArray src, // 输入图像 OutputArray dst, // 输出结果 int ddepth, // 图像深度CV_32F int dx,// 1，X方向 一阶导数 int dy, // 1，Y方向 一阶导数 int ksize = 3, // 窗口大小 double scale = 1, // 放缩比率，1 表示不变 double delta = 0, // 对输出结果图像加上常量值 int borderType = BORDER_DEFAULT ) Python:dst = cv.Sobel(src, ddepth, dx, dy[, dst[, ksize[, scale[, delta[, borderType]]]]]) 代码（c++,python）123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;int main() &#123; Mat src = imread("../images/test3.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat grad_x, grad_y, grad; // 求取x方向和y方向梯度 Sobel(src, grad_x, CV_32F, 1, 0); Sobel(src, grad_y, CV_32F, 0, 1); convertScaleAbs(grad_x, grad_x); convertScaleAbs(grad_y, grad_y); // 求取总梯度 add(grad_x, grad_y, grad, Mat(), CV_16S); convertScaleAbs(grad, grad); imshow("grad_x", grad_x); imshow("grad_y", grad_y); imshow("grad", grad); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425262728import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/grad.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w = src.shape[:2]x_grad = cv.Sobel(src, cv.CV_32F, 1, 0)y_grad = cv.Sobel(src, cv.CV_32F, 0, 1)x_grad = cv.convertScaleAbs(x_grad)y_grad = cv.convertScaleAbs(y_grad)# cv.imshow("x_grad", x_grad)# cv.imshow("y_grad", y_grad)dst = cv.add(x_grad, y_grad, dtype=cv.CV_16S)dst = cv.convertScaleAbs(dst)cv.imshow("gradient", dst)result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = dstcv.imshow("result", result)cv.imwrite("D:/result.png", dst)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>Sobel算子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-030-自定义滤波器]]></title>
    <url>%2F2019%2F04%2F09%2Fopencv-030%2F</url>
    <content type="text"><![CDATA[知识点图像卷积最主要功能有图像模糊、锐化、梯度边缘等，前面已经分享图像卷积模糊的相关知识点，OpenCV除了支持上述的卷积模糊（均值与边缘保留）还支持自定义卷积核，实现自定义的滤波操作。自定义卷积核常见的主要是均值、锐化、梯度等算子。 下面的三个自定义卷积核分别可以实现卷积的均值模糊、锐化、梯度功能： 1231，1， 1 0， -1， 0 1， 01，1， 1 -1， 5， -1 0， -11，1， 1 0， -1， 0 API int ddepth, // 默认-1，表示输入与输出图像类型一致，但是当涉及浮点数计算时候，需要设置为CV_32F。滤波完成之后需要使用convertScaleAbs函数将结果转换为字节类型。 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 自定义滤波 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat dst1, dst2, dst3; // 均值模糊 Mat kernel1 = Mat::ones(5, 5, CV_32F) / (float) (25); filter2D(src, dst1, -1, kernel1); // 锐化 Mat kernel2 = (Mat_&lt;char&gt;(3, 3) &lt;&lt; 0, -1, 0, -1, 5, -1, 0, -1, 0); filter2D(src, dst2, -1, kernel2); // 梯度 Mat kernel3 = (Mat_&lt;int&gt;(2, 2) &lt;&lt; 1, 0, 0, -1); filter2D(src, dst3, CV_32F, kernel3); convertScaleAbs(dst3, dst3); // 转换为字节类型，非常重要 imshow("blur=5x5", dst1); imshow("shape=3x3", dst2); imshow("gradient=2x2", dst3); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/test.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)blur_op = np.ones([5, 5], dtype=np.float32)/25.shape_op = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32)grad_op = np.array([[1, 0],[0, -1]], dtype=np.float32)dst1 = cv.filter2D(src, -1, blur_op)dst2 = cv.filter2D(src, -1, shape_op)dst3 = cv.filter2D(src, cv.CV_32F, grad_op)dst3 = cv.convertScaleAbs(dst3)cv.imshow("blur=5x5", dst1);cv.imshow("shape=3x3", dst2);cv.imshow("gradient=2x2", dst3);cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>自定义滤波器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决 Clion-opencv-undefined reference to "XXX" 问题]]></title>
    <url>%2F2019%2F04%2F09%2FClion_opencv_undefined_reference_to%2F</url>
    <content type="text"><![CDATA[问题描述在CLion使用opencv4 的一些函数时，出现 “ undefined reference to “ 的问题，如下图： 原因查看CMakeLists.txt opencv官网查看edgePreservingFilter函数 edgePreservingFilter函数需要导入photo库，而CMakeLists.txt中没有导入 解决方法CMakeLists.txt修改如下： 成功解决。]]></content>
      <categories>
        <category>环境配置与安装</category>
      </categories>
      <tags>
        <tag>Clion-opencv-undefined_reference_to</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-029-快速的图像边缘滤波算法]]></title>
    <url>%2F2019%2F04%2F08%2Fopencv-029%2F</url>
    <content type="text"><![CDATA[知识点高斯双边模糊与mean shift均值模糊两种边缘保留滤波算法，都因为计算量比较大，无法实时实现图像边缘保留滤波，限制了它们的使用场景，OpenCV中还实现了一种快速的边缘保留滤波算法。高斯双边与mean shift均值在计算时候使用五维向量是其计算量大速度慢的根本原因，该算法通过等价变换到低纬维度空间，实现了数据降维与快速计算。 API 其中 sigma_s的取值范围为0～200， sigma_r的取值范围为0～1 当sigma_s取值不变时候，sigma_r越大图像滤波效果越明显 当sigma_r取值不变时候，窗口sigma_s越大图像模糊效果越明显 当sgma_r取值很小的时候，窗口sigma_s取值无论如何变化，图像双边滤波效果都不好！ 代码（c++,python）1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 快速的图像边缘滤波算法 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat dst; edgePreservingFilter(src, dst, 1, 60, 0.44); imshow("result", dst); waitKey(0); return 0;&#125; 123456789101112131415161718import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/example.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w = src.shape[:2]dst = cv.edgePreservingFilter(src, sigma_s=100, sigma_r=0.4, flags=cv.RECURS_FILTER)result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = dstcv.imshow("result", result)cv.imwrite("D:/result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>快速的图像边缘滤波算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-028-图像积分图算法]]></title>
    <url>%2F2019%2F04%2F07%2Fopencv-028%2F</url>
    <content type="text"><![CDATA[知识点积分图像是Crow在1984年首次提出，是为了在多尺度透视投影中提高渲染速度，是一种快速计算图像区域和与平方和的算法。其核心思想是对每个图像建立自己的积分图查找表，在图像积分处理计算阶段根据预先建立的积分图查找表，直接查找从而实现对均值卷积线性时间计算，做到了卷积执行的时间与半径窗口大小的无关联。图像积分图在图像特征提取HAAR/SURF、二值图像分析、图像相似相关性NCC计算、图像卷积快速计算等方面均有应用，是图像处理中的经典算法之一。 图像积分图建立与查找在积分图像(Integral Image - ii)上任意位置(x, y)处的ii(x, y)表示该点左上角所有像素之和， 其中(x,y)是图像像素点坐标。 API integral( InputArray src, // 输入图像 OutputArray sum, // 和表 OutputArray sqsum, // 平方和表 OutputArray tilted, // 瓦块和表 int sdepth = -1, // 和表数据深度常见CV_32S int sqdepth = -1 // 平方和表数据深度 常见 CV_32F) 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;void blur_demo(Mat &amp;image, Mat &amp;sum);void edge_demo(Mat &amp;image, Mat &amp;sum);int getblockSum(Mat &amp;sum, int x1, int y1, int x2, int y2, int i);/* * 图像积分图算法 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 计算积分图 Mat sum, sqrsum; integral(src, sum, sqrsum); /* * 积分图应用 */ int type = 0; // 模糊应用 blur_demo(src, sum); // 边缘检测 edge_demo(src, sum); waitKey(0); return 0;&#125;void blur_demo(Mat &amp;image, Mat &amp;sum) &#123; int w = image.cols; int h = image.rows; Mat result = Mat::zeros(image.size(), image.type()); int x2 = 0, y2 = 0; int x1 = 0, y1 = 0; int ksize = 5; int radius = ksize / 2; int ch = image.channels(); int cx = 0, cy = 0; for (int row = 0; row &lt; h + radius; row++) &#123; y2 = (row + 1)&gt;h ? h : (row + 1); y1 = (row - ksize) &lt; 0 ? 0 : (row - ksize); for (int col = 0; col &lt; w + radius; col++) &#123; x2 = (col + 1)&gt;w ? w : (col + 1); x1 = (col - ksize) &lt; 0 ? 0 : (col - ksize); cx = (col - radius) &lt; 0 ? 0 : col - radius; cy = (row - radius) &lt; 0 ? 0 : row - radius; int num = (x2 - x1)*(y2 - y1); for (int i = 0; i &lt; ch; i++) &#123; // 积分图查找和表，计算卷积 int s = getblockSum(sum, x1, y1, x2, y2, i); result.at&lt;Vec3b&gt;(cy, cx)[i] = saturate_cast&lt;uchar&gt;(s / num); &#125; &#125; &#125; imshow("blur_demo", result);&#125;/*** 3x3 sobel 垂直边缘检测演示*/void edge_demo(Mat &amp;image, Mat &amp;sum) &#123; int w = image.cols; int h = image.rows; Mat result = Mat::zeros(image.size(), CV_32SC3); int x2 = 0, y2 = 0; int x1 = 0, y1 = 0; int ksize = 3; // 算子大小，可以修改，越大边缘效应越明显 int radius = ksize / 2; int ch = image.channels(); int cx = 0, cy = 0; for (int row = 0; row &lt; h + radius; row++) &#123; y2 = (row + 1)&gt;h ? h : (row + 1); y1 = (row - ksize) &lt; 0 ? 0 : (row - ksize); for (int col = 0; col &lt; w + radius; col++) &#123; x2 = (col + 1)&gt;w ? w : (col + 1); x1 = (col - ksize) &lt; 0 ? 0 : (col - ksize); cx = (col - radius) &lt; 0 ? 0 : col - radius; cy = (row - radius) &lt; 0 ? 0 : row - radius; int num = (x2 - x1)*(y2 - y1); for (int i = 0; i &lt; ch; i++) &#123; // 积分图查找和表，计算卷积 int s1 = getblockSum(sum, x1, y1, cx, y2, i); int s2 = getblockSum(sum, cx, y1, x2, y2, i); result.at&lt;Vec3i&gt;(cy, cx)[i] = saturate_cast&lt;int&gt;(s2 - s1); &#125; &#125; &#125; Mat dst, gray; convertScaleAbs(result, dst); normalize(dst, dst, 0, 255, NORM_MINMAX); cvtColor(dst, gray, COLOR_BGR2GRAY); imshow("edge_demo", gray);&#125;int getblockSum(Mat &amp;sum, int x1, int y1, int x2, int y2, int i) &#123; int tl = sum.at&lt;Vec3i&gt;(y1, x1)[i]; int tr = sum.at&lt;Vec3i&gt;(y2, x1)[i]; int bl = sum.at&lt;Vec3i&gt;(y1, x2)[i]; int br = sum.at&lt;Vec3i&gt;(y2, x2)[i]; int s = (br - bl - tr + tl); return s;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243import cv2 as cvimport numpy as npdef get_block_sum(ii, x1, y1, x2, y2, index): tl = ii[y1, x1][index] tr = ii[y2, x1][index] bl = ii[y1, x2][index] br = ii[y2, x2][index] s = (br - bl - tr + tl) return sdef blur_demo(image, ii): h, w, dims = image.shape result = np.zeros(image.shape, image.dtype) ksize = 15 radius = ksize // 2 for row in range(0, h + radius, 1): y2 = h if (row + 1)&gt; h else (row + 1) y1 = 0 if (row - ksize) &lt; 0 else (row - ksize) for col in range(0, w + radius, 1): x2 = w if (col + 1)&gt;w else (col + 1) x1 = 0 if (col - ksize) &lt; 0 else (col - ksize) cx = 0 if (col - radius) &lt; 0 else (col - radius) cy = 0 if (row - radius) &lt; 0 else (row - radius) num = (x2 - x1)*(y2 - y1) for i in range(0, 3, 1): s = get_block_sum(ii, x1, y1, x2, y2, i) result[cy, cx][i] = s // num cv.imshow("integral fast blur", result) cv.imwrite("D:/result.png", result)src = cv.imread("D:/images/test1.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)sum_table = cv.integral(src, sdepth=cv.CV_32S)blur_demo(src, sum_table)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像积分图算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-027-边缘保留滤波算法 – 均值迁移模糊(mean-shift blur)]]></title>
    <url>%2F2019%2F04%2F07%2Fopencv-027%2F</url>
    <content type="text"><![CDATA[知识点均值迁移模糊是图像边缘保留滤波算法中一种，经常用来在对图像进行分水岭分割之前去噪声，可以大幅度提升分水岭分割的效果。 均值迁移模糊的主要思想如下：就是在图像进行开窗的时候，同时考虑像素值空间范围分布，只有符合分布的像素点才参与计算，计算得到像素均值与空间位置均值，使用新的均值位置作为窗口中心位置继续基于给定像素值空间分布计算均值与均值位置，如此不断迁移中心位置直到不再变化位置（dx=dy=0），但是在实际情况中我们会人为设置一个停止条件比如迁移几次，这样就可以把最后的RGB均值赋值给中心位置。 API 代码（c++,python）1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 均值迁移模糊 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat dst; pyrMeanShiftFiltering(src, dst, 15, 30); imshow("mean_shift_blur", dst); waitKey(0); return 0;&#125; 1234567891011121314151617import cv2 as cvimport numpy as npsrc = cv.imread("D:/images/example.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w = src.shape[:2]dst = cv.pyrMeanShiftFiltering(src, 15, 30, termcrit=(cv.TERM_CRITERIA_MAX_ITER+cv.TERM_CRITERIA_EPS, 5, 1))result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = dstcv.imshow("result", result)cv.imwrite("D:/result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>均值迁移模糊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-026-边缘保留滤波算法(EPF)–高斯双边模糊]]></title>
    <url>%2F2019%2F04%2F06%2Fopencv-026%2F</url>
    <content type="text"><![CDATA[知识点前面我们介绍的图像卷积处理无论是均值还是高斯都是属于模糊卷积，它们都有一个共同的特点就是模糊之后图像的边缘信息不复存在，受到了破坏。我们今天介绍的滤波方法有能力通过卷积处理实现图像模糊的同时对图像边缘不会造成破坏，滤波之后的输出完整的保存了图像整体边缘（轮廓）信息，我们称这类滤波算法为边缘保留滤波算法（EPF）。最常见的边缘保留滤波算法有以下几种 高斯双边模糊 Meanshift均值迁移模糊 局部均方差模糊 OpenCV中对边缘保留滤波还有一个专门的API 高斯模糊是考虑图像空间位置对权重的影响，但是它没有考虑图像像素分布对图像卷积输出的影响，双边模糊考虑了像素值分布的影响，对像素值空间分布差异较大的进行保留从而完整的保留了图像的边缘信息。 原理 API 代码（c++,python）1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 高斯双边模糊 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat dst; bilateralFilter(src, dst, 0, 100, 10, 4); imshow("gaussian_bilater_blur", dst); waitKey(0); return 0;&#125; 1234567891011121314151617import cv2 as cvimport numpy as npsrc = cv.imread("../images/test.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w = src.shape[:2]dst = cv.bilateralFilter(src, 0, 100, 10)result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = dstcv.imshow("result", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>高斯双边模糊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪吃蛇小项目(c++实现)]]></title>
    <url>%2F2019%2F04%2F05%2Ftanchishe%2F</url>
    <content type="text"><![CDATA[模块结构 墙模块 食物模块 蛇模块 主程序 代码墙模块(wall.h) 123456789101112131415161718192021#ifndef TANCHISHE_WALL_H#define TANCHISHE_WALL_H#include &lt;iostream&gt;using namespace std;class Wall&#123;public: enum &#123;ROW = 20, COL = 30&#125;; // 初始化墙壁 void initWall(); // 画出墙壁 void drawWall(); // 根据索引设置二维数据里的内容 void setWall(int x, int y, char c); // 根据索引获取当前位置的符号 char getWall(int x, int y);private: char gameArray[ROW][COL];&#125;;#endif //TANCHISHE_WALL_H 食物模块(food.h) 123456789101112131415161718#ifndef TANCHISHE_FOOD_H#define TANCHISHE_FOOD_H#include &lt;iostream&gt;#include "wall.h"using namespace std;class Food&#123;public: Food(Wall &amp;tempWall); // 设置食物 void setFood();private: int foodX; int foodY; Wall &amp;wall;&#125;;#endif //TANCHISHE_FOOD_H 蛇模块(snake.h) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#ifndef TANCHISHE_SNAKE_H#define TANCHISHE_SNAKE_H#include &lt;iostream&gt;#include "wall.h"#include "food.h"using namespace std;class Snake &#123;public: Snake(Wall &amp;tempWall, Food &amp;tempFood); enum &#123; UP = 'w', DOWN = 's', LEFT = 'a', RIGHT = 'd' &#125;; struct Point &#123; int x; int y; Point *next; &#125;; // 初始化 void initSnake(); // 销毁节点 void destroyPoint(); // 添加节点 void addPoint(int x, int y); // 删除节点 void delPoint(); // 移动蛇 bool move(char key); // 设定难度 // 获取刷屏时间 int getSleepTime(); // 获取蛇身段 int countList(); // 获取分数 int getScore();private: Point *pHead; Wall &amp;wall; Food &amp;food; bool isRool; // 判断循环表示&#125;;#endif //TANCHISHE_SNAKE_H 主程序(game.cpp) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;iostream&gt;#include "wall.h"#include "snake.h"#include "food.h"#include &lt;ctime&gt;#include &lt;conio.h&gt;#include &lt;windows.h&gt;// 定位光标void gotoxy(HANDLE hOut1, int x, int y) &#123; COORD pos; pos.X = x; pos.Y = y; SetConsoleCursorPosition(hOut1, pos);&#125;HANDLE hOut = GetStdHandle(STD_OUTPUT_HANDLE); // 定义显示器句柄变量int main() &#123; // 添加随机数种子 srand((unsigned int) time(NULL)); // 是否死亡的标识 bool isDead = false; // 上一次按键标识 bool preKey = true; Wall wall; wall.initWall(); wall.drawWall(); Food food(wall); food.setFood(); Snake snake(wall, food); snake.initSnake(); gotoxy(hOut, 0, Wall::ROW); cout &lt;&lt; "score：" &lt;&lt; snake.getScore() &lt;&lt; " points" &lt;&lt; endl; while (!isDead) &#123; // 接受用户输入 char key = _getch(); // 第一次按左键，不激活游戏 if (preKey &amp;&amp; key == snake.LEFT) &#123; continue; &#125; preKey = false; do &#123; if (key == snake.UP || key == snake.DOWN || key == snake.LEFT || key == snake.RIGHT) &#123; if (snake.move(key)) &#123; //system("cls"); //wall.drawWall(); gotoxy(hOut, 0, Wall::ROW); cout &lt;&lt; "score：" &lt;&lt; snake.getScore() &lt;&lt; " points" &lt;&lt; endl; Sleep(snake.getSleepTime()); &#125; else &#123; isDead = true; break; &#125; &#125; else &#123; cout &lt;&lt; "input error, please input again" &lt;&lt; endl; break; &#125; &#125; while (!_kbhit()); // 没有键盘输入的时候，返回0 &#125; system("pause"); return 0;&#125; 结果 代码地址github]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>贪吃蛇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-025-图像去噪声]]></title>
    <url>%2F2019%2F04%2F04%2Fopencv-025%2F</url>
    <content type="text"><![CDATA[知识点图像去噪声在OCR、机器人视觉与机器视觉领域应用开发中是重要的图像预处理手段之一，对图像二值化与二值分析很有帮助，OpenCV中常见的图像去噪声的方法有 均值去噪声 高斯模糊去噪声 非局部均值去噪声 双边滤波去噪声 形态学去噪声 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;void add_gaussian_noise(Mat &amp;image);/* * 图像去噪 */int main() &#123; Mat src = imread("../images/test.png"); Mat src_clone = src.clone(); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 产生高斯噪声 add_gaussian_noise(src); Mat res1, res2, res3, res4; // 均值去噪 blur(src, res1, Size(3, 3)); imshow("mean_blur", res1); // 高斯去噪 GaussianBlur(src, res2, Size(5, 5), 0); imshow("gaussian_blur", res2); // 中值去噪 medianBlur(src, res3, 3); imshow("median_blur", res3); // 非局部均值去噪 fastNlMeansDenoisingColored(src, res4， 15， 15， 10， 30); imshow("NLmeans_blur", res4); waitKey(0); return 0;&#125;void add_gaussian_noise(Mat &amp;image) &#123; Mat noise = Mat::zeros(image.size(), image.type()); // 产生高斯噪声 randn(noise, (15, 15, 15), (30, 30, 30)); Mat dst; add(image, noise, dst); imshow("gaussian_noise", dst); dst.copyTo(image);&#125; 1234567891011121314151617181920212223242526272829303132import cv2 as cvimport numpy as npdef gaussian_noise(image): noise = np.zeros(image.shape, image.dtype) m = (15, 15, 15) s = (30, 30, 30) cv.randn(noise, m, s) dst = cv.add(image, noise) cv.imshow("gaussian noise", dst) return dstsrc = cv.imread("D:\\code-workspace\\Clion-workspace\\learnOpencv\\images\\test.png")cv.imshow("input", src)h, w = src.shape[:2]src = gaussian_noise(src)result1 = cv.blur(src, (5, 5))cv.imshow("mean_blur", result1)result2 = cv.GaussianBlur(src, (5, 5), 0)cv.imshow("gaussian_blur", result2)result3 = cv.medianBlur(src, 5)cv.imshow("median_blur", result3)result4 = cv.fastNlMeansDenoisingColored(src, None, 15, 15, 10, 30)cv.imshow("NLmeans_blur", result4)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像去噪声</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[降噪自动编码器]]></title>
    <url>%2F2019%2F04%2F03%2FDenoiseAutoEncoder%2F</url>
    <content type="text"><![CDATA[知识点 参数初始化问题 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126import numpy as npimport sklearn.preprocessing as prepimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# Xavier均匀初始化def xavier_init(fan_in, fan_out, constant = 1): low = -constant * np.sqrt(6.0 / (fan_in + fan_out)) high = constant * np.sqrt(6.0 / (fan_in + fan_out)) return tf.random_uniform((fan_in, fan_out), minval=low, maxval=high, dtype=tf.float32)# 加性高斯噪声的自动编码器class AdditiveGaussianNoiseAutoencoder(object): def __init__(self, n_input, n_hidden, transfer_function=tf.nn.softplus, optimizer=tf.train.AdamOptimizer(), scale=0.1): self.n_input = n_input self.n_hidden = n_hidden self.transfer = transfer_function self.training_scale = scale self.weights = dict() # 构建计算图 with tf.name_scope('raw_input'): self.x = tf.placeholder(tf.float32, [None, self.n_input]) with tf.name_scope('NoiseAdder'): self.scale = tf.placeholder(tf.float32) self.noise_x = self.x + self.scale * tf.random_normal((n_input,)) with tf.name_scope('encoder'): self.weights['w1'] = tf.Variable(xavier_init(self.n_input, self.n_hidden), name='weight1') self.weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype=tf.float32), name='bias1') self.hidden = self.transfer(tf.add(tf.matmul(self.noise_x, self.weights['w1']), self.weights['b1'])) with tf.name_scope('reconstruction'): self.weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype=tf.float32), name='weight2') self.weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype=tf.float32), name='bias2') self.reconstruction = tf.nn.xw_plus_b(self.hidden, self.weights['w2'], self.weights['b2']) # hidden * w2 + b2 with tf.name_scope('loss'): self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2)) with tf.name_scope('train'): self.optimizer = optimizer.minimize(self.cost) init = tf.global_variables_initializer() self.sess = tf.Session() self.sess.run(init) print("begin to run session...") # 在一个批次上训练模型 def partial_fit(self, X): cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict=&#123;self.x: X, self.scale: self.training_scale&#125;) return cost # 在给定样本集合上计算损失（用于测试阶段） def calc_total_cost(self, X): return self.sess.run(self.cost, feed_dict=&#123;self.x: X, self.scale: self.training_scale&#125;) # 返回自编码器隐含层的输出结果，获得抽象后的高阶特征表示 def transform(self, X): return self.sess.run(self.hidden, feed_dict=&#123;self.x: X, self.scale: self.training_scale&#125;) # 将隐藏层的高阶特征作为输入，将其重建为原始输入数据 def generate(self, hidden = None): if hidden == None: hidden = np.random.normal(size=self.weights['b1']) return self.sess.run(self.reconstruction, feed_dict=&#123;self.hidden: hidden&#125;) # 整体运行一遍复原过程，包括提取高阶特征以及重建原始数据，输入原始数据，输出复原后的数据 def reconstruction(self, X): return self.sess.run(self.reconstruction, feed_dict=&#123;self.x: X, self.scale: self.training_scale&#125;) # 获取隐含层的权重 def getWeights(self): return self.sess.run(self.weights['w1']) # 获取隐含层的偏置 def getBiases(self): return self.sess.run(self.weights['b1'])AGN_AutoEncoder = AdditiveGaussianNoiseAutoencoder(n_input=784, n_hidden=200, optimizer=tf.train.AdamOptimizer(learning_rate=0.01), scale=0.01)print("把计算图写入事件文件，在TensorBoard里面查看")writer = tf.summary.FileWriter(logdir='logs', graph=AGN_AutoEncoder.sess.graph)writer.close()# 读取数据集mnist = input_data.read_data_sets('../mnist_data/', one_hot=True)# 使用sklearn.preprocessing 的数据标准化操作(0均值标准差为1) 预处理数据# 首先在训练集上估计均值与方差，然后将其作用到训练集和测试集def standard_scale(x_train, x_test): preprocesser = prep.StandardScaler().fit(x_train) x_train = preprocesser.transform(x_train) x_test = preprocesser.transform(x_test) return x_train, x_test# 获取随机block数据的函数：取一个从0到len(data) - batch_size的随机整数# 以这个随机整数为起始索引，抽出一个batch_size的批次样本def get_random_block_from_data(data, batch_size): start_index = np.random.randint(0, len(data) - batch_size) return data[start_index: start_index + batch_size]# 使用标准化操作变换数据集X_train, X_test = standard_scale(mnist.train.images, mnist.test.images)# 定义训练参数n_samples = int(mnist.train.num_examples)training_epochs = 20batch_size = 128display_step = 1 # 输出训练结果的间隔# 开始训练，每次epoch开始时将avg_cost设为0，计算总共需要的batch数量，# 这里使用的是有放回抽样，所以不能保证每个样本被抽到并参与训练for epoch in range(training_epochs): avg_cost = 0 total_batch = int(n_samples / batch_size) for i in range(total_batch): batch_xs = get_random_block_from_data(X_train, batch_size) cost = AGN_AutoEncoder.partial_fit(batch_xs) avg_cost += cost / batch_size avg_cost /= total_batch if epoch % display_step == 0: print("epoch : %03d, cost = %.3f" % (epoch + 1, avg_cost))# 计算测试集上的costprint("total cost :", str(AGN_AutoEncoder.calc_total_cost(X_test))) 计算图 代码地址github]]></content>
      <categories>
        <category>ML/DL</category>
      </categories>
      <tags>
        <tag>降噪自动编码器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动编码器(含两个隐藏层)]]></title>
    <url>%2F2019%2F04%2F03%2FAutoEncoder%2F</url>
    <content type="text"><![CDATA[知识点 自动编码器分类 降噪自动编码器代码 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143import matplotlib.pyplot as pltimport numpy as npimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# 控制训练过程的参数learning_rate = 0.01training_epochs = 20batch_size = 256display_step = 5examples_to_show = 10# w网络模型参数n_input_units = 784 # 输入神经元数量 MNIST data input (img shape : 28*28)n_hidden1_units = 256 # 编码起第一隐藏层神经元数量（让编码器和解码器都有同样规模的隐藏层n_hidden2_units = 128 # 编码起第二隐藏层神经元数量（让编码器和解码器都有同样规模的隐藏层n_output_units = n_input_units # 解码器输出层神经元数量必须等于输入数据的units数量# 对一个张量进行全面汇总(均值，标准差，最大最小值，直方图)def varible_summaries(var): with tf.name_scope('summaries'): mean = tf.reduce_mean(var) stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean))) tf.summary.scalar('mean', mean) tf.summary.scalar('stddev', stddev) tf.summary.scalar('max', tf.reduce_max(var)) tf.summary.scalar('min', tf.reduce_min(var)) tf.summary.histogram('histogram', var)# 根据输入输出节点数量返回权重def WeightsVarible(n_in, n_out, name_str='weights'): return tf.Variable(tf.random_normal([n_in, n_out]), dtype=tf.float32, name=name_str)# 根据输出节点数量返回偏置def BiasesVarible(n_out, name_str='biases'): return tf.Variable(tf.random_normal([n_out]), dtype=tf.float32, name=name_str)# 构建编码器def Encoder(x_origin, activate_func=tf.nn.sigmoid): # 编码器第一隐藏层 with tf.name_scope('Layer1'): weights = WeightsVarible(n_input_units, n_hidden1_units) biases = BiasesVarible(n_hidden1_units) x_code1 = activate_func(tf.nn.xw_plus_b(x_origin, weights, biases)) varible_summaries(weights) # 编码器第二隐藏层 with tf.name_scope('Layer2'): weights = WeightsVarible(n_hidden1_units, n_hidden2_units) biases = BiasesVarible(n_hidden2_units) x_code = activate_func(tf.nn.xw_plus_b(x_code1, weights, biases)) varible_summaries(weights) return x_code# 构建解吗器def Decoder(x_code, activate_func=tf.nn.sigmoid): # 解码器第一隐藏层 with tf.name_scope('Layer'): weights = WeightsVarible(n_hidden2_units, n_hidden1_units) biases = BiasesVarible(n_hidden1_units) x_decode1 = activate_func(tf.nn.xw_plus_b(x_code, weights, biases)) varible_summaries(weights) # 解码器第二隐藏层 with tf.name_scope('Layer'): weights = WeightsVarible(n_hidden1_units, n_output_units) biases = BiasesVarible(n_output_units) x_decode = activate_func(tf.nn.xw_plus_b(x_decode1, weights, biases)) varible_summaries(weights) return x_decode# 调用上面写的函数构造计算图with tf.Graph().as_default(): # 计算图输入 with tf.name_scope('X_origin'): X_origin = tf.placeholder(tf.float32, [None, n_input_units]) # 构建编码器 with tf.name_scope('Encoder'): X_code = Encoder(X_origin) # 构建解吗器 with tf.name_scope('Decoder'): X_decode = Decoder(X_code) # 定义损失节点 with tf.name_scope('Loss'): Loss = tf.reduce_mean(tf.pow(X_origin - X_decode, 2)) # 定义优化器 with tf.name_scope('Train'): Optimizer = tf.train.RMSPropOptimizer(learning_rate) Train = Optimizer.minimize(Loss) # 为计算图添加损失节点的标量汇总(scalar summary) with tf.name_scope('LossSummary'): tf.summary.scalar('loss', Loss) tf.summary.scalar('learning_rate', learning_rate) # 为计算图添加图像汇总 with tf.name_scope('ImageSummary'): image_origin = tf.reshape(X_origin, [-1, 28, 28, 1]) image_reconstructed = tf.reshape(X_decode, [-1, 28, 28, 1]) tf.summary.image('image_origin', image_origin, 10) tf.summary.image('image_reconstructed', image_reconstructed, 10) # 聚合所有汇总节点 merged_summary = tf.summary.merge_all() init = tf.global_variables_initializer() print("把计算图写入事件文件，在TensorBoard里面查看") writer = tf.summary.FileWriter(logdir='logs', graph=tf.get_default_graph()) writer.flush() # 读取数据集 mnist = input_data.read_data_sets('mnist_data/', one_hot=True) with tf.Session() as sess: sess.run(init) total_batch = int(mnist.train.num_examples / batch_size) for epoch in range(training_epochs): for i in range(total_batch): batch_xs, batch_ys = mnist.train.next_batch(batch_size) _, loss = sess.run([Train, Loss], feed_dict=&#123;X_origin: batch_xs&#125;) if epoch % display_step == 0: print("epoch : %03d, loss = %.3f" % (epoch + 1, loss)) # 运行汇总节点，更新事件文件 summary_str = sess.run(merged_summary, feed_dict=&#123;X_origin: batch_xs&#125;) writer.add_summary(summary_str, epoch) writer.flush() writer.close() print("训练完毕！") # 把训练好的编码器-解码器模型用在测试集上，输出重建后的样本数据 reconstructions = sess.run(X_decode, feed_dict=&#123;X_origin: mnist.test.images[:examples_to_show]&#125;) # 比较原始图像与重建后的图像 f, a = plt.subplots(2, 10, figsize=(10, 2)) for i in range(examples_to_show): a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28))) a[1][i].imshow(np.reshape(reconstructions[i], (28, 28))) f.show() plt.draw() 结果计算图 测试结果 代码地址github]]></content>
      <categories>
        <category>ML/DL</category>
      </categories>
      <tags>
        <tag>自动编码器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-024-图像噪声]]></title>
    <url>%2F2019%2F04%2F03%2Fopencv-024%2F</url>
    <content type="text"><![CDATA[知识点图像噪声产生的原因很复杂，有的可能是数字信号在传输过程中发生了丢失或者受到干扰，有的是成像设备或者环境本身导致成像质量不稳定，反应到图像上就是图像的亮度与颜色呈现某种程度的不一致性。从噪声的类型上，常见的图像噪声可以分为如下几种： 椒盐噪声，是一种随机在图像中出现的稀疏分布的黑白像素点， 对椒盐噪声一种有效的去噪手段就是图像中值滤波 高斯噪声/符合高斯分布一般会在数码相机的图像采集(acquisition)阶段发生,这个时候它的物理/电/光等各种信号都可能导致产生高斯分布噪声。 均匀分布噪声均匀/规则噪声一般都是因为某些规律性的错误导致的 代码演示 图像椒盐噪声生成 图像高斯噪声生成 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;void add_salt_pepper_noise(Mat &amp;image);void add_gaussian_noise(Mat &amp;image);/* * 噪声生成 */int main() &#123; Mat src = imread("../images/test.png"); Mat src_clone = src.clone(); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; //imshow("input", src); // 产生椒盐噪声 add_salt_pepper_noise(src_clone); // 产生高斯噪声 add_gaussian_noise(src); waitKey(0); return 0;&#125;void add_gaussian_noise(Mat &amp;image) &#123; Mat noise = Mat::zeros(image.size(), image.type()); // 产生高斯噪声 randn(noise, (15,15,15), (30,30,30)); Mat dst; add(image, noise, dst); imshow("gaussian_noise", dst);&#125;void add_salt_pepper_noise(Mat &amp;image) &#123; // 随机数产生器 RNG rng(12345); for (int i = 0; i &lt; 1000; ++i) &#123; int x = rng.uniform(0, image.rows); int y = rng.uniform(0, image.cols); if (i % 2 == 1) &#123; image.at&lt;Vec3b&gt;(y, x) = Vec3b(255, 255, 255); &#125; else &#123; image.at&lt;Vec3b&gt;(y, x) = Vec3b(0, 0, 0); &#125; &#125; imshow("saltp_epper", image);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142import cv2 as cvimport numpy as npdef add_salt_pepper_noise(image): h, w = image.shape[:2] nums = 10000 rows = np.random.randint(0, h, nums, dtype=np.int) cols = np.random.randint(0, w, nums, dtype=np.int) for i in range(nums): if i % 2 == 1: image[rows[i], cols[i]] = (255, 255, 255) else: image[rows[i], cols[i]] = (0, 0, 0) return imagedef gaussian_noise(image): noise = np.zeros(image.shape, image.dtype) m = (15, 15, 15) s = (30, 30, 30) cv.randn(noise, m, s) dst = cv.add(image, noise) cv.imshow("gaussian noise", dst) return dstsrc = cv.imread("D:/vcprojects/images/cos.jpg")h, w = src.shape[:2]copy = np.copy(src)copy = add_salt_pepper_noise(copy)result = np.zeros([h, w*2, 3], dtype=src.dtype)result[0:h,0:w,:] = srcresult[0:h,w:2*w,:] = copycv.putText(result, "original image", (10, 30), cv.FONT_HERSHEY_PLAIN, 2.0, (0, 255, 255), 1)cv.putText(result, "salt pepper image", (w+10, 30), cv.FONT_HERSHEY_PLAIN, 2.0, (0, 255, 255), 1)cv.imshow("salt pepper noise", result)cv.imwrite("D:/result.png", result)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像噪声</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-023-中值模糊]]></title>
    <url>%2F2019%2F04%2F03%2Fopencv-023%2F</url>
    <content type="text"><![CDATA[知识点中值滤波本质上是统计排序滤波器的一种，中值滤波对图像特定噪声类型（椒盐噪声）会取得比较好的去噪效果，也是常见的图像去噪声与增强的方法之一。中值滤波也是窗口在图像上移动，其覆盖的对应ROI区域下，所有像素值排序，取中值作为中心像素点的输出值。 API 代码（c++,python）1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;int main() &#123; Mat src = imread("../images/sp_noise.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat dst; medianBlur(src, dst, 5); imshow("medianBlur", dst); waitKey(0); return 0;&#125; 12345678910111213import cv2 as cvimport numpy as npsrc = cv.imread("D:/sp_noise.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)dst = cv.medianBlur(src, 5)cv.imshow("blur ksize=5", dst)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>中值模糊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-022-图像均值模糊与高斯模糊]]></title>
    <url>%2F2019%2F04%2F02%2Fopencv-022%2F</url>
    <content type="text"><![CDATA[知识点均值模糊 是卷积核的系数完全一致，高斯模糊考虑了中心像素距离的影响，对距离中心像素使用高斯分布公式生成不同的权重系数给卷积核，然后用此卷积核完成图像卷积得到输出结果就是图像高斯模糊之后的输出。 参考：高斯模糊原理-阮一峰 API void GaussianBlur( InputArray src, OutputArray dst, Size ksize, // Ksize为高斯滤波器窗口大小 double sigmaX, // X方向滤波系数 double sigmaY=0, // Y方向滤波系数 int borderType=BORDER_DEFAULT // 默认边缘插值方法)当Size(0, 0)就会从sigmaX开始计算生成高斯卷积核系数，当时size不为零时优先从size开始计算高斯卷积核系数 代码（c++,python）12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 均值模糊与高斯模糊 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat dst1, dst2, dst3; blur(src, dst1, Size(5, 5)); GaussianBlur(src, dst2, Size(5, 5), 15, 0); GaussianBlur(src, dst3, Size(15, 15), 15, 0); imshow("blur ksize=5", dst1); imshow("gaussian ksize=5", dst2); imshow("gaussian ksize=15", dst3); waitKey(0); return 0;&#125; 123456789101112131415161718import cv2 as cvimport numpy as npsrc = cv.imread("D:/javaopencv/snow.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)dst1 = cv.blur(src, (5, 5))dst2 = cv.GaussianBlur(src, (5, 5), sigmaX=15)dst3 = cv.GaussianBlur(src, (0, 0), sigmaX=15)cv.imshow("blur ksize=5", dst1)cv.imshow("gaussian ksize=5", dst2)cv.imshow("gaussian sigmax=15", dst3)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>均值模糊与高斯模糊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-021-图像卷积及均值模糊]]></title>
    <url>%2F2019%2F04%2F01%2Fopencv-021%2F</url>
    <content type="text"><![CDATA[知识点图像卷积可以看成是一个窗口区域在另外一个大的图像上移动，对每个窗口覆盖的区域都进行点乘得到的值作为中心像素点的输出值。窗口的移动是从左到右，从上到下。窗口可以理解成一个指定大小的二维矩阵，里面有预先指定的值。（注意与深度学习卷积的区别） API 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像卷积及均值模糊 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // 均值模糊 Mat dst; blur(src, dst, Size(15, 15), Point(-1, -1), 4); imshow("dst", dst); // 3x3 均值模糊，自定义版本实现 for (int row = 1; row &lt; h-1; row++) &#123; for (int col = 1; col &lt; w-1; col++) &#123; Vec3b p1 = src.at&lt;Vec3b&gt;(row-1, col-1); Vec3b p2 = src.at&lt;Vec3b&gt;(row-1, col); Vec3b p3 = src.at&lt;Vec3b&gt;(row-1, col+1); Vec3b p4 = src.at&lt;Vec3b&gt;(row, col-1); Vec3b p5 = src.at&lt;Vec3b&gt;(row, col); Vec3b p6 = src.at&lt;Vec3b&gt;(row, col+1); Vec3b p7 = src.at&lt;Vec3b&gt;(row+1, col-1); Vec3b p8 = src.at&lt;Vec3b&gt;(row+1, col); Vec3b p9 = src.at&lt;Vec3b&gt;(row+1, col+1); int b = p1[0] + p2[0] + p3[0] + p4[0] + p5[0] + p6[0] + p7[0] + p8[0] + p9[0]; int g = p1[1] + p2[1] + p3[1] + p4[1] + p5[1] + p6[1] + p7[1] + p8[1] + p9[1]; int r = p1[2] + p2[2] + p3[2] + p4[2] + p5[2] + p6[2] + p7[2] + p8[2] + p9[2]; dst.at&lt;Vec3b&gt;(row, col)[0] = saturate_cast&lt;uchar&gt;(b / 9); dst.at&lt;Vec3b&gt;(row, col)[1] = saturate_cast&lt;uchar&gt;(g / 9); dst.at&lt;Vec3b&gt;(row, col)[2] = saturate_cast&lt;uchar&gt;(r / 9); &#125; &#125; waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435import cv2 as cvimport numpy as npdef custom_blur(src): h, w, ch = src.shape print("h , w, ch", h, w, ch) result = np.copy(src) for row in range(1, h-1, 1): for col in range(1, w-1, 1): v1 = np.int32(src[row-1, col-1]) v2 = np.int32(src[row-1, col]) v3 = np.int32(src[row-1, col+1]) v4 = np.int32(src[row, col-1]) v5 = np.int32(src[row, col]) v6 = np.int32(src[row, col+1]) v7 = np.int32(src[row+1, col-1]) v8 = np.int32(src[row+1, col]) v9 = np.int32(src[row+1, col+1]) b = v1[0] + v2[0] + v3[0] + v4[0] + v5[0] + v6[0] + v7[0] + v8[0] + v9[0]; g = v1[1] + v2[1] + v3[1] + v4[1] + v5[1] + v6[1] + v7[1] + v8[1] + v9[1]; r = v1[2] + v2[2] + v3[2] + v4[2] + v5[2] + v6[2] + v7[2] + v8[2] + v9[2]; result[row, col] = [b//9, g//9, r//9] cv.imshow("result", result)src = cv.imread("D:/vcprojects/images/lena.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)dst = cv.blur(src, (15, 15))cv.imshow("blur", dst)custom_blur(src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像卷积及均值模糊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy[..., None]的理解]]></title>
    <url>%2F2019%2F04%2F01%2Fnumpy_None%2F</url>
    <content type="text"><![CDATA[numpy数组维度1import numpy as np 12arr_1 = np.array([1, 2, 3, 4])print(arr_1, '\n' , 'shape of arr_1:', arr_1.shape, '， dimension of arr_1:',np.ndim(arr_1)) output: arr_1 = [1 2 3 4] shape of arr_1: (4,) ， dimension of arr_1: 1 12arr_2 = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])print(arr_2, '\n' , 'shape of arr_2:', arr_2.shape, '， dimension of arr_2:',np.ndim(arr_2)) output: arr_2 = [[1 2 3 4] [5 6 7 8]] shape of arr_2: (2, 4) ， dimension of arr_2: 2 12arr_3 = np.array([[[1, 2, 3, 4], [5, 6, 7, 8]], [[1, 2, 3, 4], [5, 6, 7, 8]], [[1, 2, 3, 4], [5, 6, 7, 8]]])print(arr_3, '\n' , 'shape of arr_3:', arr_3.shape, '， dimension of arr_3:',np.ndim(arr_3)) output: arr_3 = [[[1 2 3 4] [5 6 7 8]] [[1 2 3 4] [5 6 7 8]] [[1 2 3 4] [5 6 7 8]]] shape of arr_3: (3, 2, 4) ， dimension of arr_3: 3 numpy数组切片中[…]的理解假设 x 是一个数组，np.ndim(x) == 5 x[1,2,...] == x[1,2,:,:,:] x[...,3] == x[:,:,:,:,3] x[4,...,5,:] == x[4,:,:,5,:] numpy数组切片中None的理解None 的作用就是在相应的位置上增加了一个维度，在这个维度上只有一个元素 假设 x.shape == (a, b)，则 (a, b) ==&gt; [None, :, :] ==&gt; (1, a, b) (a, b) ==&gt; [:, None, :] ==&gt; (a, 1, b) (a, b) ==&gt; [:, :, None] ==&gt; (a, b, 1) 123import numpy as nparr = np.array([[1,2,3],[4,5,6]])print(arr, '\n' , 'shape of arr:', arr.shape, '， dimension of arr:',np.ndim(arr)) output: arr = [[1 2 3] [4 5 6]] shape of arr: (2, 3) ， dimension of arr: 2 12None_1 = arr[None, :, :]print(None_1, '\n' , 'shape of None_1:', None_1.shape, '， dimension of None_1:',np.ndim(None_1)) output: None_1 = [[[1 2 3] [4 5 6]]] shape of None_1: (1, 2, 3) ， dimension of None_1: 3 12None_2 = arr[:, None, :]print(None_2, '\n' , 'shape of None_2:', None_2.shape, '， dimension of None_2:',np.ndim(None_2)) output: None_2 = [[[1 2 3]] [[4 5 6]]] shape of None_2: (2, 1, 3) ， dimension of None_2: 3 12None_3 = arr[:, :, None]print(None_3, '\n' , 'shape of None_3:', None_3.shape, '， dimension of None_3:',np.ndim(None_3)) output: None_3 = [[[1] [2] [3]] [[4] [5] [6]]] shape of None_3: (2, 3, 1) ， dimension of None_3: 3 numpy[…, None]的理解12None_3 = arr[..., None] # 等价于 None_3 = arr[:, :, None]print(None_3, '\n' , 'shape of None_3:', None_3.shape, '， dimension of None_3:',np.ndim(None_3)) output: None_3 = [[[1] [2] [3]] [[4] [5] [6]]] shape of None_3: (2, 3, 1) ， dimension of None_3: 3 12y = np.arange(12).reshape((2,2,3))print(y, '\n' , 'shape of y:', y.shape, '， dimension of y:',np.ndim(y)) output: y = [[[ 0 1 2] [ 3 4 5]] [[ 6 7 8] [ 9 10 11]]] shape of y: (2, 2, 3) ， dimension of y: 3 12y = y[..., None]print(y, '\n' , 'shape of y:', y.shape, '， dimension of y:',np.ndim(y)) output: y = [[[[ 0] [ 1] [ 2]] [[ 3] [ 4] [ 5]]] [[[ 6] [ 7] [ 8]] [[ 9] [10] [11]]]] shape of y: (2, 2, 3, 1) ， dimension of y: 4]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-020-图像直方图反向投影]]></title>
    <url>%2F2019%2F03%2F30%2Fopencv-020%2F</url>
    <content type="text"><![CDATA[知识点文字解释图像直方图反向投影是通过构建指定模板图像的二维直方图空间与目标的二维直方图空间，进行直方图数据归一化之后， 进行比率操作，对所有得到非零数值，生成查找表对原图像进行像素映射之后，再进行图像模糊输出的结果。 直方图反向投影流程 计算直方图 计算比率R LUT查找表 卷积模糊 归一化输出 API 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;void backProjection_demo(Mat &amp;mat, Mat &amp;model);/* * 图像直方图反向投影 */int main() &#123; Mat src = imread("../images/target.png"); Mat model = imread("../images/sample.png"); if (src.empty() || model.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; namedWindow("model", WINDOW_NORMAL); imshow("input", src); imshow("model", model); backProjection_demo(src, model); waitKey(0); return 0;&#125;void backProjection_demo(Mat &amp;image, Mat &amp;model) &#123; Mat image_hsv, model_hsv; cvtColor(image, image_hsv, COLOR_BGR2HSV); cvtColor(model, model_hsv, COLOR_BGR2HSV); // 定义直方图参数与属性 int h_bins = 32, s_bins = 32; int histSize[] = &#123;h_bins, s_bins&#125;; float h_ranges[] = &#123;0, 180&#125;, s_ranges[] = &#123;0, 256&#125;; const float* ranges[] = &#123;h_ranges, s_ranges&#125;; int channels[] = &#123;0, 1&#125;; Mat roiHist; calcHist(&amp;model_hsv, 1, channels, Mat(), roiHist, 2, histSize, ranges); normalize(roiHist, roiHist, 0, 255, NORM_MINMAX, -1, Mat()); MatND backproj; calcBackProject(&amp;image_hsv, 1, channels, roiHist, backproj, ranges); imshow("BackProj", backproj);&#125; 1234567891011121314151617181920212223242526272829303132333435363738import cv2 as cvimport numpy as npfrom matplotlib import pyplot as pltdef back_projection_demo(): sample = cv.imread("D:/javaopencv/sample.png") # hist2d_demo(sample) target = cv.imread("D:/javaopencv/target.png") # hist2d_demo(target) roi_hsv = cv.cvtColor(sample, cv.COLOR_BGR2HSV) target_hsv = cv.cvtColor(target, cv.COLOR_BGR2HSV) # show images cv.imshow("sample", sample) cv.imshow("target", target) roiHist = cv.calcHist([roi_hsv], [0, 1], None, [32, 32], [0, 180, 0, 256]) cv.normalize(roiHist, roiHist, 0, 255, cv.NORM_MINMAX) dst = cv.calcBackProject([target_hsv], [0, 1], roiHist, [0, 180, 0, 256], 1) cv.imshow("backProjectionDemo", dst)def hist2d_demo(image): hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV) hist = cv.calcHist([hsv], [0, 1], None, [32, 32], [0, 180, 0, 256]) dst = cv.resize(hist, (400, 400)) cv.imshow("image", image) cv.imshow("hist", dst) plt.imshow(hist, interpolation='nearest') plt.title("2D Histogram") plt.show()back_projection_demo()cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像直方图反向投影</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-019-图像直方图比较]]></title>
    <url>%2F2019%2F03%2F30%2Fopencv-019%2F</url>
    <content type="text"><![CDATA[知识点图像直方图比较，就是计算两幅图像的直方图数据，比较两组数据的相似性，从而得到两幅图像之间的相似程度，直方图比较在早期的CBIR(以图搜图)中是应用很常见的技术手段，通常会结合边缘处理、词袋等技术一起使用。APIcompareHist(hist1, hist2, method)常见比较方法有 相关性(常用) 卡方 交叉 巴氏(常用) 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像直方图比较 */int main() &#123; Mat src1 = imread("../images/left01.jpg"); Mat src2 = imread("../images/left13.jpg"); if (src1.empty() || src2.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input1", src1); imshow("input2", src2); // 一般在HSV色彩空间进行计算 Mat hsv1, hsv2; cvtColor(src1, hsv1, COLOR_BGR2HSV); cvtColor(src2, hsv2, COLOR_BGR2HSV); int h_bins = 60, s_bins = 64; int histSize[] = &#123;h_bins, s_bins&#125;; float h_ranges[] = &#123;0, 180&#125;; float s_ranges[] = &#123;0, 256&#125;; const float* ranges[] = &#123;h_ranges, s_ranges&#125;; int channels[] = &#123;0, 1&#125;; Mat hist1, hist2; calcHist(&amp;hsv1, 1, channels, Mat(), hist1, 2, histSize, ranges); calcHist(&amp;hsv2, 1, channels, Mat(), hist2, 2, histSize, ranges); normalize(hist1, hist1, 0, 1, NORM_MINMAX, -1, Mat()); normalize(hist2, hist2, 0, 1, NORM_MINMAX, -1, Mat()); // 比较 double src1_src2_1 = compareHist(hist1, hist2, HISTCMP_CORREL); double src1_src2_2 = compareHist(hist1, hist2, HISTCMP_BHATTACHARYYA); printf("HISTCMP_CORREL : %.2f\n", src1_src2_1); printf("HISTCMP_BHATTACHARYYA : %.2f\n", src1_src2_1); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import cv2 as cvimport numpy as npsrc1 = cv.imread("D:/vcprojects/images/m1.png")src2 = cv.imread("D:/vcprojects/images/m2.png")src3 = cv.imread("D:/vcprojects/images/flower.png")src4 = cv.imread("D:/vcprojects/images/wm_test.png")cv.imshow("input1", src1)cv.imshow("input2", src2)cv.imshow("input3", src3)cv.imshow("input4", src4)hsv1 = cv.cvtColor(src1, cv.COLOR_BGR2HSV)hsv2 = cv.cvtColor(src2, cv.COLOR_BGR2HSV)hsv3 = cv.cvtColor(src3, cv.COLOR_BGR2HSV)hsv4 = cv.cvtColor(src4, cv.COLOR_BGR2HSV)hist1 = cv.calcHist([hsv1], [0, 1], None, [60, 64], [0, 180, 0, 256])hist2 = cv.calcHist([hsv2], [0, 1], None, [60, 64], [0, 180, 0, 256])hist3 = cv.calcHist([hsv3], [0, 1], None, [60, 64], [0, 180, 0, 256])hist4 = cv.calcHist([hsv4], [0, 1], None, [60, 64], [0, 180, 0, 256])cv.normalize(hist1, hist1, 0, 1.0, cv.NORM_MINMAX, dtype=np.float32)cv.normalize(hist2, hist2, 0, 1.0, cv.NORM_MINMAX)cv.normalize(hist3, hist3, 0, 1.0, cv.NORM_MINMAX)cv.normalize(hist4, hist4, 0, 1.0, cv.NORM_MINMAX)methods = [cv.HISTCMP_CORREL, cv.HISTCMP_CHISQR, cv.HISTCMP_INTERSECT, cv.HISTCMP_BHATTACHARYYA]str_method = ""for method in methods: src1_src2 = cv.compareHist(hist1, hist2, method) src3_src4 = cv.compareHist(hist3, hist4, method) if method == cv.HISTCMP_CORREL: str_method = "Correlation" if method == cv.HISTCMP_CHISQR: str_method = "Chi-square" if method == cv.HISTCMP_INTERSECT: str_method = "Intersection" if method == cv.HISTCMP_BHATTACHARYYA: str_method = "Bhattacharyya" print("%s src1_src2 = %.2f, src3_src4 = %.2f"%(str_method, src1_src2, src3_src4))cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像直方图比较</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-018-图像直方图均衡化]]></title>
    <url>%2F2019%2F03%2F29%2Fopencv-018%2F</url>
    <content type="text"><![CDATA[知识点图像直方图均衡化可以用于图像增强、对输入图像进行直方图均衡化处理，提升后续对象检测的准确率，在OpenCV人脸检测的代码演示中已经很常见。此外对医学影像图像与卫星遥感图像也经常通过直方图均衡化来提升图像质量。 API equalizeHist(src, dst) 代码（c++,python）123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像直方图均衡化 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; Mat gray, dst; cvtColor(src, gray, COLOR_BGR2GRAY); equalizeHist(gray, dst); imshow("input", gray); imshow("eq", dst); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324252627282930313233import cv2 as cvimport numpy as npfrom matplotlib import pyplot as pltdef custom_hist(gray): h, w = gray.shape hist = np.zeros([256], dtype=np.int32) for row in range(h): for col in range(w): pv = gray[row, col] hist[pv] += 1 y_pos = np.arange(0, 256, 1, dtype=np.int32) plt.bar(y_pos, hist, align='center', color='r', alpha=0.5) plt.xticks(y_pos, y_pos) plt.ylabel('Frequency') plt.title('Histogram') plt.show()src = cv.imread("../images/test.png")gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", gray)dst = cv.equalizeHist(gray)cv.imshow("eh", dst)custom_hist(gray)custom_hist(dst)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像直方图均衡化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-017-图像直方图]]></title>
    <url>%2F2019%2F03%2F28%2Fopencv-017%2F</url>
    <content type="text"><![CDATA[知识点图像直方图的解释图像直方图是图像像素值的统计学特征、计算代价较小，具有图像平移、旋转、缩放不变性等众多优点，广泛地应用于图像处理的各个领域，特别是灰度图像的阈值分割、基于颜色的图像检索以及图像分类、反向投影跟踪。常见的分为 灰度直方图 颜色直方图 Bins是指直方图的大小范围， 对于像素值取值在0～255之间的，最少有256个bin，此外还可以有16、32、48、128等，256除以bin的大小应该是整数倍。 OpenCV中相关APIcalcHist(&amp;bgr_plane[0], 1, 0, Mat(), b_hist, 1, bins, ranges);cv.calcHist([image], [i], None, [256], [0, 256]) 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;vector&gt;using namespace std;using namespace cv;const int bins = 256;Mat src;const char *winTitle = "input image";void showHistogram();/* * 图像直方图 */int main() &#123; src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow(winTitle, src); showHistogram(); waitKey(0); return 0;&#125;void showHistogram() &#123; // 三通道分离 vector&lt;Mat&gt; bgr_plane; split(src, bgr_plane); // 定义参数变量 const int channels[1] = &#123;0&#125;; const int bins[1] = &#123;256&#125;; float hranges[2] = &#123;0, 255&#125;; const float *ranges[1] = &#123;hranges&#125;; Mat b_hist, g_hist, r_hist; // 计算三通道直方图 calcHist(&amp;bgr_plane[0], 1, 0, Mat(), b_hist, 1, bins, ranges); calcHist(&amp;bgr_plane[1], 1, 0, Mat(), g_hist, 1, bins, ranges); calcHist(&amp;bgr_plane[2], 1, 0, Mat(), r_hist, 1, bins, ranges); /* * 显示直方图 */ int hist_w = 512; int hist_h = 400; int bin_w = cvRound((double) hist_w / bins[0]); Mat histImage = Mat::zeros(hist_h, hist_w, CV_8UC3); // 归一化直方图数据 normalize(b_hist, b_hist, 0, histImage.rows, NORM_MINMAX, -1); normalize(g_hist, g_hist, 0, histImage.rows, NORM_MINMAX, -1); normalize(r_hist, r_hist, 0, histImage.rows, NORM_MINMAX, -1); // 绘制直方图曲线 for (int i = 1; i &lt; bins[0]; ++i) &#123; line(histImage, Point(bin_w * (i - 1), hist_h - cvRound(b_hist.at&lt;float&gt;(i - 1))), Point(bin_w * (i), hist_h - cvRound(b_hist.at&lt;float&gt;(i))), Scalar(255, 0, 0), 2, 8, 0); line(histImage, Point(bin_w * (i - 1), hist_h - cvRound(g_hist.at&lt;float&gt;(i - 1))), Point(bin_w * (i), hist_h - cvRound(g_hist.at&lt;float&gt;(i))), Scalar(0, 255, 0), 2, 8, 0); line(histImage, Point(bin_w * (i - 1), hist_h - cvRound(r_hist.at&lt;float&gt;(i - 1))), Point(bin_w * (i), hist_h - cvRound(r_hist.at&lt;float&gt;(i))), Scalar(0, 0, 255), 2, 8, 0); &#125; imshow("Histogram", histImage);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142import cv2 as cvimport numpy as npfrom matplotlib import pyplot as pltdef custom_hist(gray): h, w = gray.shape hist = np.zeros([256], dtype=np.int32) for row in range(h): for col in range(w): pv = gray[row, col] hist[pv] += 1 y_pos = np.arange(0, 256, 1, dtype=np.int32) plt.bar(y_pos, hist, align='center', color='r', alpha=0.5) plt.xticks(y_pos, y_pos) plt.ylabel('Frequency') plt.title('Histogram') # plt.plot(hist, color='r') # plt.xlim([0, 256]) plt.show()def image_hist(image): cv.imshow("input", image) color = ('blue', 'green', 'red') for i, color in enumerate(color): hist = cv.calcHist([image], [i], None, [256], [0, 256]) plt.plot(hist, color=color) plt.xlim([0, 256]) plt.show()src = cv.imread("../images/test.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)cv.imshow("input", gray)#custom_hist(gray)image_hist(src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像直方图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-016-图像ROI与ROI操作]]></title>
    <url>%2F2019%2F03%2F28%2Fopencv-016%2F</url>
    <content type="text"><![CDATA[知识点图像的ROI(region of interest)是指图像中感兴趣区域、在OpenCV中图像设置图像ROI区域，实现只对ROI区域操作。 矩形ROI区域提取 矩形ROI区域copy 不规则ROI区域 ROI区域mask生成 像素位 and操作 提取到ROI区域 加背景or操作 add 背景与ROI区域 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * ROI及相关操作 */int main() &#123; Mat src = imread("../images/test.png"); imshow("input", src); int h = src.rows; int w = src.cols; // 获取ROI int cy = h / 2; int cx = w / 2; Rect rect(cx - 100, cy - 100, 200, 200); // 注意：roi 与 src指向同一块内存区域，改变roi,src也会改变 Mat roi = src(rect); imshow("roi", roi); // 人物背景图，换背景 // load image Mat image = imread("../images/boy.jpg"); imshow("input", image); // generate mask Mat hsv, mask, mask_not; cvtColor(image, hsv, COLOR_BGR2HSV); inRange(hsv, Scalar(35, 43, 46), Scalar(99, 255, 255), mask); imshow("mask", mask); // extract person Mat person; bitwise_not(mask, mask_not); imshow("mask_not", mask_not); bitwise_and(image, image, person, mask_not); imshow("person", person); // gengerate background Mat background = Mat::zeros(image.size(), image.type()); background.setTo(Scalar(255, 0 ,0)); imshow("background", background); // combine background + person Mat dst; bitwise_or(person, background, dst, mask); add(dst, person, dst); imshow("dst", dst); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import cv2 as cvimport numpy as npsrc = cv.imread("D:/javaopencv/dahlia_4.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w = src.shape[:2]# 获取ROIcy = h//2cx = w//2roi = src[cy-100:cy+100,cx-100:cx+100,:]cv.imshow("roi", roi)# copy ROIimage = np.copy(roi)# modify ROIroi[:, :, 0] = 0cv.imshow("result", src)# modify copy roiimage[:, :, 2] = 0cv.imshow("result", src)cv.imshow("copy roi", image)# example with ROI - generate masksrc2 = cv.imread("D:/javaopencv/tinygreen.png");cv.imshow("src2", src2)hsv = cv.cvtColor(src2, cv.COLOR_BGR2HSV)mask = cv.inRange(hsv, (35, 43, 46), (99, 255, 255))# extract person ROImask = cv.bitwise_not(mask)person = cv.bitwise_and(src2, src2, mask=mask);# generate backgroundresult = np.zeros(src2.shape, src2.dtype)result[:,:,0] = 255# combine background + personmask = cv.bitwise_not(mask)dst = cv.bitwise_or(person, result, mask=mask)dst = cv.add(dst, person)cv.imshow("dst", dst)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像ROI与ROI操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-015-绘制几何形状及随机数的生成]]></title>
    <url>%2F2019%2F03%2F28%2Fopencv-015%2F</url>
    <content type="text"><![CDATA[知识点绘制几何形状 绘制直线 绘制圆 绘制矩形 绘制椭圆 填充几何形状 OpenCV没有专门的填充方法，只是把绘制几何形状时候的线宽thickness参数值设置为负数即表示填充该几何形状或者使用参数CV_FILLED 随机数方法：RNG 表示OpenCV C++版本中的随机数对象，rng.uniform(a, b)生成[a, b)之间的随机数，包含a，但是不包含b。 np.random.rand() 表示numpy中随机数生成，生成浮点数0～1的随机数, 包含0，不包含1。 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 绘制几何形状及随机数 */int main() &#123; Mat image = Mat::zeros(Size(512, 512), CV_8UC3); Rect rect(100, 100, 200, 200); // 绘制 rectangle(image, rect, Scalar(255, 0, 0), 2, LINE_8, 0); circle(image, Point(256, 256), 50, Scalar(0, 255, 0), 2, LINE_8, 0); ellipse(image, Point(256, 256), Size(150, 50), 360, 0, 360, Scalar(0, 0, 255), 2, LINE_8, 0); imshow("image_draw", image); // 填充 thickness=-1 or FILLED rectangle(image, rect, Scalar(255, 0, 0), FILLED, LINE_8, 0); ellipse(image, Point(256, 256), Size(150, 50), 360, 0, 360, Scalar(0, 0, 255), FILLED, LINE_8, 0); circle(image, Point(256, 256), 50, Scalar(0, 255, 0), -1, LINE_8, 0); imshow("image_fill", image); // 随机数 RNG rng(0xFFFFFF); image.setTo(Scalar(0, 0, 0)); Mat image_copy = image.clone(); for (int i = 0; i &lt; 100000; ++i) &#123; int x1 = rng.uniform(0, 512); int y1 = rng.uniform(0, 512); int x2 = rng.uniform(0, 512); int y2 = rng.uniform(0, 512); int b = rng.uniform(0, 256); int g = rng.uniform(0, 256); int r = rng.uniform(0, 256); rect.x = x1; rect.y = y1; rect.width = x2 - x1; rect.height = y2 - y1; // LINE_AA 反锯齿 line(image, Point(x1, y1), Point(x2, y2), Scalar(b, g, r), 1, LINE_AA, 0); rectangle(image_copy, rect, Scalar(b, g, r), 1, LINE_AA, 0); imshow("image_line", image); imshow("image_rect", image_copy); char c = waitKey(20); if (c == 27)&#123; // ESC break; &#125; &#125; waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829303132import cv2 as cvimport numpy as npimage = np.zeros((512, 512, 3), dtype=np.uint8)cv.rectangle(image, (100, 100), (300, 300), (255, 0, 0), 2, cv.LINE_8, 0)cv.circle(image, (256, 256), 50, (0, 0, 255), 2, cv.LINE_8, 0)cv.ellipse(image, (256, 256), (150, 50), 360, 0, 360, (0, 255, 0), 2, cv.LINE_8, 0)cv.imshow("image", image)cv.waitKey(0)for i in range(100000): image[:,:,:]= 0 x1 = np.random.rand() * 512 y1 = np.random.rand() * 512 x2 = np.random.rand() * 512 y2 = np.random.rand() * 512 b = np.random.randint(0, 256) g = np.random.randint(0, 256) r = np.random.randint(0, 256) # cv.line(image, (np.int(x1), np.int(y1)), (np.int(x2), np.int(y2)), (b, g, r), 4, cv.LINE_8, 0) cv.rectangle(image, (np.int(x1), np.int(y1)), (np.int(x2), np.int(y2)), (b, g, r), 1, cv.LINE_8, 0) cv.imshow("image", image) c = cv.waitKey(20) if c == 27: break # ESCä¸cv.imshow("image", image)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>绘制几何形状</tag>
        <tag>随机数生成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-014-使用resize进行图像插值(Image Interpolation)]]></title>
    <url>%2F2019%2F03%2F27%2Fopencv-014%2F</url>
    <content type="text"><![CDATA[知识点最常见四种插值算法 INTER_NEAREST = 0 #最近邻插值，速度快，没考虑周围像素影响 INTER_LINEAR = 1 #双线性插值 INTER_CUBIC = 2 #双立方插值，高质量 INTER_LANCZOS4 = 4 #高质量 关于这四种插值算法的详细代码实现与解释 三种常见双立方插值算法-CSDN 图像放缩之双立方插值 图像放缩之双线性内插值 Lanczos采样放缩算法 相关的应用场景几何变换、透视变换、插值计算新像素 API resize(InputArray src, OutputArray dst, Size dsize, double fx=0, double fy=0, int interpolation=INTER_LINEAR ) 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像插值 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); int h = src.rows; int w = src.cols; float fx = 0.0, fy = 0.0; Mat dst = Mat::zeros(src.size(), src.type()); Size S(w * 2, h * 2); resize(src, dst, S, fx, fy, INTER_NEAREST); imshow("INTER_NEAREST", dst); resize(src, dst, S, fx, fy, INTER_LINEAR); imshow("INTER_LINEAR", dst); resize(src, dst, S, fx, fy, INTER_CUBIC); imshow("INTER_CUBIC", dst); resize(src, dst, S, fx, fy, INTER_LANCZOS4); imshow("INTER_LANCZOS4", dst); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324import cv2 as cvsrc = cv.imread("D:/vcprojects/images/test.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w = src.shape[:2]print(h, w)dst = cv.resize(src, (w*2, h*2), fx=0.75, fy=0.75, interpolation=cv.INTER_NEAREST)cv.imshow("INTER_NEAREST", dst)dst = cv.resize(src, (w*2, h*2), interpolation=cv.INTER_LINEAR)cv.imshow("INTER_LINEAR", dst)dst = cv.resize(src, (w*2, h*2), interpolation=cv.INTER_CUBIC)cv.imshow("INTER_CUBIC", dst)dst = cv.resize(src, (w*2, h*2), interpolation=cv.INTER_LANCZOS4)cv.imshow("INTER_LANCZOS4", dst)cv.warpAffine()cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像插值</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-013-图像翻转(Image Flip)]]></title>
    <url>%2F2019%2F03%2F27%2Fopencv-013%2F</url>
    <content type="text"><![CDATA[知识点图像翻转的本质像素映射，OpenCV支持三种图像翻转方式 X轴翻转，flipcode = 0 Y轴翻转, flipcode = 1 XY轴翻转, flipcode = -1 相关的APIflip(src, dst, flipcode) src输入参数 dst 翻转后图像 flipcode 应用：摄像头拍摄后经常需要翻转 代码（c++,python）1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像翻转 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); Mat dst; // X轴 倒影 flip(src, dst, 0); imshow("x_flip", dst); // Y轴 镜像 flip(src, dst, 1); imshow("y_flip", dst); // XY轴 对角 flip(src, dst, -1); imshow("xy_flip", dst); waitKey(0); return 0;&#125; 123456789101112131415161718192021222324252627282930import cv2 as cvimport numpy as npsrc = cv.imread("D:/vcprojects/images/test.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)# X Flip 倒影dst1 = cv.flip(src, 0);cv.imshow("x-flip", dst1);# Y Flip 镜像dst2 = cv.flip(src, 1);cv.imshow("y-flip", dst2);# XY Flip 对角dst3 = cv.flip(src, -1);cv.imshow("xy-flip", dst3);# custom y-fliph, w, ch = src.shapedst = np.zeros(src.shape, src.dtype)for row in range(h): for col in range(w): b, g, r = src[row, col] dst[row, w - col - 1] = [b, g, r]cv.imshow("custom-y-flip", dst)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像翻转</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-012-视频读写]]></title>
    <url>%2F2019%2F03%2F26%2Fopencv-012%2F</url>
    <content type="text"><![CDATA[知识点VideoCapture 视频文件读取、摄像头读取、视频流读取VideoWriter 视频写出、文件保存、 CAP_PROP_FRAME_HEIGHT #高度 CAP_PROP_FRAME_WIDTH #宽度 CAP_PROP_FRAME_COUNT #数量 CAP_PROP_FPS #帧率 不支持音频编码与解码保存，不是一个音视频处理的库！主要是分析与解析视频内容。保存文件最大支持单个文件为2G。 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 视频读写 */int main() &#123; // 打开摄像头 // VideoCapture capture(0); // 打开视频文件 VideoCapture capture; capture.open("../images/vtest.avi"); if (!capture.isOpened()) &#123; cout &lt;&lt; "could not load video.." &lt;&lt; endl; return -1; &#125; Size S = Size((int) capture.get(CAP_PROP_FRAME_WIDTH), (int) capture.get(CAP_PROP_FRAME_HEIGHT)); int fps = capture.get(CAP_PROP_FPS); cout &lt;&lt; "capture fps: " &lt;&lt; fps &lt;&lt; endl; VideoWriter writer("D:/test.mp4", cv::VideoWriter::fourcc('D', 'I','V','X'), fps, S, true); Mat frame; while(capture.read(frame))&#123; imshow("input", frame); writer.write(frame); char c = waitKey(50); if(c == 27)&#123; break; &#125; &#125; capture.release(); writer.release(); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526import cv2 as cvimport numpy as npcapture = cv.VideoCapture("D:/vcprojects/images/768x576.avi")# capture = cv.VideoCapture(0) 打开摄像头height = capture.get(cv.CAP_PROP_FRAME_HEIGHT)width = capture.get(cv.CAP_PROP_FRAME_WIDTH)count = capture.get(cv.CAP_PROP_FRAME_COUNT)fps = capture.get(cv.CAP_PROP_FPS)print(height, width, count, fps)out = cv.VideoWriter("D:/test.mp4", cv.VideoWriter_fourcc('D', 'I', 'V', 'X'), 15, (np.int(width), np.int(height)), True)while True: ret, frame = capture.read() if ret is True: cv.imshow("video-input", frame) out.write(frame) c = cv.waitKey(50) if c == 27: # ESC break else: breakcapture.release()out.release() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>视频读写</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-011-图像像素归一化]]></title>
    <url>%2F2019%2F03%2F25%2Fopencv-011%2F</url>
    <content type="text"><![CDATA[知识点OpenCV中提供了四种归一化的方法 NORM_MINMAX NORM_INF NORM_L1 NORM_L2 最常用的就是NORM_MINMAX归一化方法. 四种归一化方法示例 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像像素归一化 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; // imshow("input", src); Mat gray; cvtColor(src, gray, COLOR_BGR2GRAY); imshow("input", gray); // 显示图像用uchar类型，计算时转为float类型 gray.convertTo(gray, CV_32F); // NORM_MINMAX Mat dst = Mat::zeros(gray.size(), CV_32FC1); normalize(gray, dst, 1.0, 0, NORM_MINMAX); Mat res = dst * 255; res.convertTo(dst, CV_8UC1); // 显示图像用uchar类型 imshow("NORM_MINMAX", dst); // scale and shift by NORM_INF normalize(gray, dst, 1.0, 0, NORM_INF); res = dst * 255; res.convertTo(dst, CV_8UC1); imshow("NORM_INF", dst); // scale and shift by NORM_L1 normalize(gray, dst, 1.0, 0, NORM_L1); res = dst * 10000000; res.convertTo(dst, CV_8UC1); imshow("NORM_L1", dst); // scale and shift by NORM_L2 normalize(gray, dst, 1.0, 0, NORM_L2); res = dst * 10000; res.convertTo(dst, CV_8UC1); imshow("NORM_L2", dst); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738import cv2 as cvimport numpy as npsrc = cv.imread("D:/vcprojects/images/test.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)# 转换为浮点数类型数组gray = np.float32(gray)print(gray)# scale and shift by NORM_MINMAXdst = np.zeros(gray.shape, dtype=np.float32)cv.normalize(gray, dst=dst, alpha=0, beta=1.0, norm_type=cv.NORM_MINMAX)print(dst)cv.imshow("NORM_MINMAX", np.uint8(dst*255))# scale and shift by NORM_INFdst = np.zeros(gray.shape, dtype=np.float32)cv.normalize(gray, dst=dst, alpha=1.0, beta=0, norm_type=cv.NORM_INF)print(dst)cv.imshow("NORM_INF", np.uint8(dst*255))# scale and shift by NORM_L1dst = np.zeros(gray.shape, dtype=np.float32)cv.normalize(gray, dst=dst, alpha=1.0, beta=0, norm_type=cv.NORM_L1)print(dst)cv.imshow("NORM_L1", np.uint8(dst*10000000))# scale and shift by NORM_L2dst = np.zeros(gray.shape, dtype=np.float32)cv.normalize(gray, dst=dst, alpha=1.0, beta=0, norm_type=cv.NORM_L2)print(dst)cv.imshow("NORM_L2", np.uint8(dst*10000))cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像像素归一化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-010-图像像素值统计及应用（普通图像转化为二值图像）]]></title>
    <url>%2F2019%2F03%2F25%2Fopencv-010%2F</url>
    <content type="text"><![CDATA[知识点 最小(min) 最大(max) 均值(mean) 标准方差(standard deviation) API知识点 最大最小值minMaxLoc 计算均值与标准方差meanStdDev 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像像素值统计及应用（普通图像转化为二值图像） */int main() &#123; Mat src_bgr = imread("../images/test.png"); Mat src_gray; cvtColor(src_bgr, src_gray, COLOR_BGR2GRAY); if (src_bgr.empty() || src_gray.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input_bgr", src_bgr); // 计算灰度图像的最大最小值 double minVal, maxVal; Point minLoc, maxLoc; minMaxLoc(src_gray, &amp;minVal, &amp;maxVal, &amp;minLoc, &amp;maxLoc); cout &lt;&lt; "paramenters of src_gray:" &lt;&lt; endl; printf("min:%.2f, max:%.2f \n", minVal, maxVal); printf("min loc: (%d, %d) \n", minLoc.x, minLoc.y); printf("max loc: (%d, %d) \n", maxLoc.x, maxLoc.y); // 普通图像转二值图像 Mat mean, stddev; meanStdDev(src_bgr, mean, stddev); cout &lt;&lt; "paramenters of src_bgr:" &lt;&lt; endl; printf("blue channel mean:%.2f, stddev: %.2f \n", mean.at&lt;double&gt;(0, 0), stddev.at&lt;double&gt;(0, 0)); printf("green channel mean:%.2f, stddev: %.2f \n", mean.at&lt;double&gt;(1, 0), stddev.at&lt;double&gt;(1, 0)); printf("red channel mean:%.2f, stddev: %.2f \n", mean.at&lt;double&gt;(2, 0), stddev.at&lt;double&gt;(2, 0)); for (int row = 0; row &lt; src_bgr.rows; ++row) &#123; for (int col = 0; col &lt; src_bgr.cols; ++col) &#123; Vec3b bgr = src_bgr.at&lt;Vec3b&gt;(row, col); bgr[0] = bgr[0] &lt; mean.at&lt;double&gt;(0, 0) ? 0 : 255; bgr[1] = bgr[1] &lt; mean.at&lt;double&gt;(1, 0) ? 0 : 255; bgr[2] = bgr[2] &lt; mean.at&lt;double&gt;(2, 0) ? 0 : 255; src_bgr.at&lt;Vec3b&gt;(row, col) = bgr; &#125; &#125; imshow("binary", src_bgr); waitKey(0); return 0;&#125; 1234567891011121314151617181920import cv2 as cvimport numpy as npsrc = cv.imread("../images/test.png", cv.IMREAD_GRAYSCALE)cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)min, max, minLoc, maxLoc = cv.minMaxLoc(src)print("min: %.2f, max: %.2f"% (min, max))print("min loc: ", minLoc)print("max loc: ", maxLoc)means, stddev = cv.meanStdDev(src)print("mean: %.2f, stddev: %.2f"% (means, stddev))src[np.where(src &lt; means)] = 0src[np.where(src &gt; means)] = 255cv.imshow("binary", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像像素值统计</tag>
        <tag>普通图像转化为二值图像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-009-色彩空间及其应用（提取图像的前景和背景）]]></title>
    <url>%2F2019%2F03%2F25%2Fopencv-009%2F</url>
    <content type="text"><![CDATA[知识点 RGB色彩空间 HSV色彩空间 -维基百科 ### 直方图算法中常用 YUV色彩空间 YCrCb色彩空间 # 皮肤检测常用 API知识点 色彩空间转换cvtColor 提取指定色彩范围区域inRange 代码（c++,python）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 色彩空间及其应用 */int main() &#123; Mat src = imread("../images/test.png"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); // RGB ==&gt; HSV YUV YCrCb Mat hsv, yuv, ycrcb; cvtColor(src, hsv, COLOR_BGR2HSV); cvtColor(src, yuv, COLOR_BGR2YUV); cvtColor(src, ycrcb, COLOR_BGR2YCrCb); imshow("hsv", hsv); imshow("yuv", yuv); imshow("ycrcb", ycrcb); /* * 提取图像前景和背景 */ Mat src2 = imread("../images/boy.jpg"); imshow("input boy", src2); cvtColor(src2, hsv, COLOR_BGR2HSV); // 从HSV表中查到绿色的最低值和最高值，建立掩模 Mat mask, mask_not; inRange(hsv, Scalar(35, 43, 46), Scalar(77, 255, 255), mask); imshow("mask", mask); Mat fg, bg; // 提取背景 bitwise_and(src2, src2, bg, mask); // 提取前景 bitwise_not(mask, mask_not); imshow("mask_not", mask_not); bitwise_and(src2, src2, fg, mask_not); imshow("background", bg); imshow("foreground" ,fg); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425262728import cv2 as cvsrc = cv.imread("../images/test.png")cv.namedWindow("rgb", cv.WINDOW_AUTOSIZE)cv.imshow("rgb", src)# RGB to HSVhsv = cv.cvtColor(src, cv.COLOR_BGR2HSV)cv.imshow("hsv", hsv)# RGB to YUVyuv = cv.cvtColor(src, cv.COLOR_BGR2YUV)cv.imshow("yuv", yuv)# RGB to YUVycrcb = cv.cvtColor(src, cv.COLOR_BGR2YCrCb)cv.imshow("ycrcb", ycrcb)src2 = cv.imread("../images/boy.jpg");cv.imshow("src2", src2)hsv = cv.cvtColor(src2, cv.COLOR_BGR2HSV)mask = cv.inRange(hsv, (35, 43, 46), (99, 255, 255))dst = cv.bitwise_and(src2, src2, mask=mask)cv.imshow("mask", mask)cv.imshow("dst", dst)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>色彩空间</tag>
        <tag>提取图像前景和背景</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-008-图像通道的分离与合并]]></title>
    <url>%2F2019%2F03%2F24%2Fopencv-008%2F</url>
    <content type="text"><![CDATA[知识点OpenCV中默认imread函数加载图像文件，加载进来的是三通道彩色图像，色彩空间是RGB色彩空间、通道顺序是BGR（蓝色、绿色、红色）、对于三通道的图像OpenCV中提供了两个API函数用以实现通道分离与合并。 split // 通道分类 merge // 通道合并 扩展在很多CNN的卷积神经网络中输入的图像一般会要求[h, w, ch]其中h是高度、w是指宽度、ch是指通道数数目、OpenCV DNN模块中关于图像分类的googlenet模型输入[224,224,3]表示的就是224x224大小的三通道的彩色图像输入。 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像通道分离与合并 */int main() &#123; Mat src = imread("../images/baboon.jpg"); if (src.empty()) &#123; cout &lt;&lt; "could not load image.." &lt;&lt; endl; &#125; imshow("input", src); vector&lt;Mat&gt; mv; // mv用于存储图像分离后各通道像素 Mat dst1, dst2, dst3; // 令蓝色通道为0 split(src, mv); mv[0] = Scalar(0); merge(mv, dst1); imshow("blue == 0", dst1); // 令绿色通道为0 split(src, mv); mv[1] = Scalar(0); merge(mv, dst2); imshow("green == 0", dst2); // 令红色通道为0 split(src, mv); mv[2] = Scalar(0); merge(mv, dst3); imshow("red == 0", dst3); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526import cv2 as cvsrc = cv.imread("../images/baboon.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)# 蓝色通道为零mv = cv.split(src)mv[0][:, :] = 0dst1 = cv.merge(mv)cv.imshow("output1", dst1)# 绿色通道为零mv = cv.split(src)mv[1][:, :] = 0dst2 = cv.merge(mv)cv.imshow("output2", dst2)# 红色通道为零mv = cv.split(src)mv[2][:, :] = 0dst3 = cv.merge(mv)cv.imshow("output3", dst3)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像通道的分离与合并</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-007-图像像素之逻辑操作]]></title>
    <url>%2F2019%2F03%2F24%2Fopencv-007%2F</url>
    <content type="text"><![CDATA[知识点下面三个操作类似，都是针对两张图像的位操作 bitwise_and bitwise_xor bitwise_or 针对输入图像, 图像取反操作，二值图像分析中经常用 bitwise_not 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;/* * 图像像素的逻辑操作 */int main() &#123; // create image one, CV_8UC3创建三通道图像 Mat src1 = Mat::zeros(Size(400, 400), CV_8UC3); Rect rect(100,100,100,100); // Scalar() 参数为BGR三通道值，绿色和红色加起来是黄色 src1(rect) = Scalar(0, 255, 255); imshow("input1", src1); // create image two Mat src2 = Mat::zeros(Size(400, 400), CV_8UC3); rect.x = 150; rect.y = 150; src2(rect) = Scalar(0, 0, 255); imshow("input2", src2); // 逻辑操作 Mat dst1, dst2, dst3; bitwise_and(src1, src2, dst1); bitwise_xor(src1, src2, dst2); bitwise_or(src1, src2, dst3); imshow("and", dst1); imshow("xor", dst2); imshow("or", dst3); // 演示取反操作 Mat src = imread("../images/test1.jpg"); Mat dst; imshow("input", src); bitwise_not(src,dst); imshow("not", dst); waitKey(0); return 0;&#125; 1234567891011121314151617181920212223242526272829import cv2 as cvimport numpy as np# create image onesrc1 = np.zeros(shape=[400, 400, 3], dtype=np.uint8)src1[100:200, 100:200, 1] = 255src1[100:200, 100:200, 2] = 255cv.imshow("input1", src1)# create image twosrc2 = np.zeros(shape=[400, 400, 3], dtype=np.uint8)src2[150:250, 150:250, 2] = 255cv.imshow("input2", src2)dst1 = cv.bitwise_and(src1, src2)dst2 = cv.bitwise_xor(src1, src2)dst3 = cv.bitwise_or(src1, src2)cv.imshow("dst1", dst1)cv.imshow("dst2", dst2)cv.imshow("dst3", dst3)src = cv.imread("../images/test1.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)dst = cv.bitwise_not(src)cv.imshow("dst", dst)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像像素逻辑操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生成假数据用于卷积神经网络模型训练]]></title>
    <url>%2F2019%2F03%2F24%2Fget_faked_data%2F</url>
    <content type="text"><![CDATA[背景在设计神经网络时，用于测试的imageNet等数据集太大，所以生成假数据用来测试神经网络能不能正常运行 代码123456789101112131415161718192021import tensorflow as tf# 参数设置batch_size = 32image_size = 24image_channel = 3n_classes = 10# 生成假数据用于训练模型def get_faked_train_batch(batch_size): images = tf.Variable(tf.random_normal(shape=[batch_size, image_size, image_size, image_channel], mean=0.0, stddev=1.0, dtype=tf.float32)) # tf.random_uniform() 标准均匀分布 labels = tf.Variable(tf.random_uniform(shape=[batch_size], minval=0, maxval=n_classes, dtype=tf.int32)) return images, labels # 生成假数据用于测试模型def get_faked_test_batch(batch_size): images = tf.Variable(tf.random_normal(shape=[batch_size, image_size, image_size, image_channel], mean=0.0, stddev=1.0, dtype=tf.float32)) # tf.random_uniform() 标准均匀分布 labels = tf.Variable(tf.random_uniform(shape=[batch_size], minval=0, maxval=n_classes, dtype=tf.int32)) return images, labels]]></content>
      <categories>
        <category>ML/DL</category>
      </categories>
      <tags>
        <tag>卷积神经网络假数据生成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-006-Look Up Table(LUT)查找表的使用]]></title>
    <url>%2F2019%2F03%2F23%2Fopencv-006%2F</url>
    <content type="text"><![CDATA[知识点LUT查找表的简单原理 LUT查找表的作用 颜色匹配，比如讲灰度图像进行伪彩色增强 加快计算速度 API：applyColorMap(src, dst, COLORMAP) src 表示输入图像 dst表示输出图像 匹配到的颜色LUT， OpenCV支持13种颜色风格的查找表映射 COLORMAP ：13种色彩风格 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;// 自定义LUTMat &amp;myColorMap(Mat &amp;image);/* * Look Up Table(LUT)查找表的使用 */int main() &#123; Mat src = imread("../images/LinuxLogo.jpg"); imshow("input", src); // 使用LUT Mat dst; applyColorMap(src, dst, COLORMAP_SUMMER); imshow("colorMap", dst); // 使用自己的LUT Mat my_dst, gray; cvtColor(src, gray, COLOR_BGR2GRAY); my_dst = myColorMap(gray); imshow("my_dst", my_dst); waitKey(0); return 0;&#125;// 自定义LUTMat &amp;myColorMap(Mat &amp;image) &#123; int lut[256]; for (int i = 0; i &lt; 256; ++i) &#123; if (i &lt; 127) lut[i] = 0; else lut[i] = 255; &#125; for (int row = 0; row &lt; image.rows; ++row) &#123; for (int col = 0; col &lt; image.cols; ++col) &#123; int pv = image.at&lt;uchar&gt;(row, col); image.at&lt;uchar&gt;(row, col) = lut[pv]; &#125; &#125; return image;&#125; 12345678910import cv2 as cvsrc = cv.imread("../images/LinuxLogo.jpg")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)dst = cv.applyColorMap(src, cv.COLORMAP_COOL)cv.imshow("output", dst)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>查找表（LUT）</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-005-像素算术操作]]></title>
    <url>%2F2019%2F03%2F23%2Fopencv-005%2F</url>
    <content type="text"><![CDATA[知识点像素算术操作 加add、减subtract、乘multiply、除divide saturate_cast&lt;T&gt;(value) # 类型转换注意点：图像的数据类型、通道数目、大小必须相同 代码（c++,python）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;/* * 图像像素的加减乘除，两张图像大小类型要完全相同 */ int main()&#123; Mat src1 = imread("../images/opencv_images/LinuxLogo.jpg"); Mat src2 = imread("../images/opencv_images/WindowsLogo.jpg"); if(src1.empty() || src2.empty())&#123; cout&lt;&lt;"conld not read image..."&lt;&lt;endl; return -1; &#125; imshow("input1", src1); imshow("input2", src2); // 加法 Mat add_result = Mat::zeros(src1.size(),src1.type()); add(src1, src2, add_result); imshow("add_result", add_result); // 带权重的加法，一般推荐使用这个 Mat add_weight_result = Mat::zeros(src1.size(),src1.type()); addWeighted(src1, 0.5, src2, (1.0 - 0.5), 0.0, add_weight_result); imshow("add_weight_result", add_weight_result); // 减法 Mat sub_result = Mat::zeros(src1.size(),src1.type()); subtract(src1, src2, sub_result); imshow("sub_result", sub_result); // 乘法 Mat mul_result = Mat::zeros(src1.size(),src1.type()); multiply(src1, src2, mul_result); imshow("mul_result", mul_result); // 除法 Mat div_result = Mat::zeros(src1.size(),src1.type()); divide(src1, src2, div_result); imshow("div_result", div_result); // 自己实现加法操作 int b1 = 0, g1 = 0, r1 = 0; int b2 = 0, g2 = 0, r2 = 0; int b = 0, g = 0, r = 0; Mat my_add_result = Mat::zeros(src1.size(), src1.type()); for (int row = 0; row &lt; src1.rows; ++row) &#123; for (int col = 0; col &lt; src1.cols; ++col) &#123; b1 = src1.at&lt;Vec3b&gt;(row, col)[0]; g1 = src1.at&lt;Vec3b&gt;(row, col)[1]; r1 = src1.at&lt;Vec3b&gt;(row, col)[2]; b2 = src2.at&lt;Vec3b&gt;(row, col)[0]; g2 = src2.at&lt;Vec3b&gt;(row, col)[1]; r2 = src2.at&lt;Vec3b&gt;(row, col)[2]; // b1:0~255,b2:0~255, b1+b2可能大于255，所以需要转换，通过saturate_cast&lt;uchar&gt;() my_add_result.at&lt;Vec3b&gt;(row, col)[0] = saturate_cast&lt;uchar&gt;(b1 + b2); my_add_result.at&lt;Vec3b&gt;(row, col)[1] = saturate_cast&lt;uchar&gt;(g1 + g2); my_add_result.at&lt;Vec3b&gt;(row, col)[2] = saturate_cast&lt;uchar&gt;(r1 + r2); &#125; &#125; imshow("my_add_result", my_add_result); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425262728import cv2 as cvimport numpy as npsrc1 = cv.imread("../images/opencv_images/LinuxLogo.jpg");src2 = cv.imread("../images/opencv_images/WindowsLogo.jpg");cv.imshow("input1", src1)cv.imshow("input2", src2)h, w, ch = src1.shapeprint("h , w, ch", h, w, ch)add_result = np.zeros(src1.shape, src1.dtype);cv.add(src1, src2, add_result);cv.imshow("add_result", add_result);sub_result = np.zeros(src1.shape, src1.dtype);cv.subtract(src1, src2, sub_result);cv.imshow("sub_result", sub_result);mul_result = np.zeros(src1.shape, src1.dtype);cv.multiply(src1, src2, mul_result);cv.imshow("mul_result", mul_result);div_result = np.zeros(src1.shape, src1.dtype);cv.divide(src1, src2, div_result);cv.imshow("div_result", div_result);cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像像素算术操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用tensorflow对cifar10数据集进行图像分类]]></title>
    <url>%2F2019%2F03%2F22%2Fcifar10%2F</url>
    <content type="text"><![CDATA[步骤 定义神经网络计算图 运行计算图 导包12345import tensorflow as tfimport osimport cifar10_input # tensorflow/modle模块中自带案例，可以去github下载import numpy as npos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' 设置算法超参数1234567891011learning_rate_init = 0.001l2loss_ratio = 0.001keep_prob = 0.7 #dropouttraining_epochs = 5batch_size = 100display_step = 100conv1_kernel_num = 64conv2_kernel_num = 64fc1_units_num = 256fc2_units_num = 128fc3_units_num = cifar10_input.NUM_CLASSES 数据集中输入图像的参数123456dataset_dir = './cifar10_data/'image_size = cifar10_input.IMAGE_SIZEimage_channel = 3n_classes = cifar10_input.NUM_CLASSESnum_examples_per_epoch_for_train = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_TRAINnum_examples_per_epoch_for_eval = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL 得到每一批次的训练数据123456def get_distorted_train_batch(data_dir, batch_size): if not data_dir: raise ValueError('please supply a data_dir') data_dir = os.path.join(data_dir, 'cifar-10-batches-bin') images, labels = cifar10_input.distorted_inputs(data_dir=data_dir, batch_size=batch_size) return images, labels 得到每一批次的测试数据123456def get_undistorted_eval_batch(data_dir, eval_data, batch_size): if not data_dir: raise ValueError('please supply a data_dir') data_dir = os.path.join(data_dir, 'cifar-10-batches-bin') images, labels = cifar10_input.inputs(eval_data=eval_data, data_dir=data_dir, batch_size=batch_size) return images, labels 根据指定的维数返回初始化好的指定名称的权重 Variable12345678def WeightsVariable(shape, name_str='weights', stddev=0.1): # 单cpu initial = tf.truncated_normal(shape=shape, stddev=stddev, dtype=tf.float32) return tf.Variable(initial, dtype=tf.float32, name=name_str) # 多gpu # weights = tf.get_variable(name_str, shape=shape, dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer_conv2d()) # return weights 根据指定的维数返回初始化好的指定名称的权重 Variable123def BiasesVariable(shape, name_str='biases', init_value=0.0): initial = tf.constant(init_value, shape=shape) return tf.Variable(initial, dtype=tf.float32, name=name_str) 2维卷积层的封装（包含激活函数）1234567def Conv2d(x, W, b, stride=1, padding='SAME', activation=tf.nn.relu, act_name='relu'): with tf.name_scope('conv2d_bias'): y = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding=padding) y = tf.nn.bias_add(y, b) with tf.name_scope(act_name): y = activation(y) return y 2维池化层pool的封装12def Pool2d(x, pool=tf.nn.max_pool, k=2, stride=2, padding='SAME'): return pool(x, ksize=[1, k, k, 1], strides=[1, stride, stride, 1], padding=padding) 全连接层的封装1234567def FullyConnected(x, W, b, activation=tf.nn.relu, act_name='relu'): with tf.name_scope('Wx_b'): y = tf.matmul(x, W) y = tf.add(y, b) with tf.name_scope(act_name): y = activation(y) return y 为每一层的激活输出添加汇总节点123def AddActivationSummary(x): tf.summary.histogram('/activations', x) tf.summary.scalar('/sparsity', tf.nn.zero_fraction(x)) # 稀疏性 为所有损失节点添加标量汇总操作12345678910def AddLossesSummary(losses): # 计算所有损失的滑动平均 loss_averages = tf.train.ExponentialMovingAverage(decay=0.9, name='avg') loss_averages_op = loss_averages.apply(losses) # 为所有损失及平滑处理的损失绑定标量汇总节点 for loss in losses: tf.summary.scalar(loss.op.name + '(raw)', loss) tf.summary.scalar(loss.op.name + '(avg)', loss_averages.average(loss)) return loss_averages_op 打印每一层输出张量的shape12def print_layers_shape(t): print(t.op.name, ' ', t.get_shape().as_list()) 前向推断过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263def Inference(images_holder): # 第一个卷积层 with tf.name_scope('Conv2d_1'): weights = WeightsVariable(shape=[5, 5, image_channel, conv1_kernel_num], stddev=5e-2) biases = BiasesVariable(shape=[conv1_kernel_num]) conv1_out = Conv2d(images_holder, weights, biases) AddActivationSummary(conv1_out) print_layers_shape(conv1_out) # 第一个池化层 with tf.name_scope('Pool2d_1'): pool1_out = Pool2d(conv1_out, k=3, stride=2) # 第二个卷积层 with tf.name_scope('Conv2d_2'): weights = WeightsVariable(shape=[5, 5, conv1_kernel_num, conv2_kernel_num], stddev=5e-2) biases = BiasesVariable(shape=[conv2_kernel_num]) conv2_out = Conv2d(pool1_out, weights, biases) AddActivationSummary(conv2_out) # 第二个池化层 with tf.name_scope('Pool2d_2'): pool2_out = Pool2d(conv2_out, k=3, stride=2) # 将二维特征图变为一维特征向量 with tf.name_scope('FeatsReshape'): features = tf.reshape(pool2_out, [batch_size, -1]) feats_dim = features.get_shape()[1].value # 得到上一行 -1 所指代的值 # 第一个全连接层 with tf.name_scope('FC1_nonlinear'): weights = WeightsVariable(shape=[feats_dim, fc1_units_num], stddev=4e-2) biases = BiasesVariable(shape=[fc1_units_num], init_value=0.1) fc1_out = FullyConnected(features, weights, biases) AddActivationSummary(fc1_out) # 加入L2损失 with tf.name_scope('L2_loss'): weight_loss = tf.multiply(tf.nn.l2_loss(weights), l2loss_ratio, name='fc1_weight_loss') tf.add_to_collection('losses', weight_loss) # Dropout # with tf.name_scope('dropout_1'): # fc1_dropout = tf.nn.dropout(fc1_out, keep_prob=keep_prob) # 第二个全连接层 with tf.name_scope('FC2_nonlinear'): weights = WeightsVariable(shape=[fc1_units_num, fc2_units_num], stddev=4e-2) biases = BiasesVariable(shape=[fc2_units_num], init_value=0.1) fc2_out = FullyConnected(fc1_out, weights, biases) AddActivationSummary(fc2_out) # 加入L2损失 with tf.name_scope('L2_loss'): weight_loss = tf.multiply(tf.nn.l2_loss(weights), l2loss_ratio, name='fc2_weight_loss') tf.add_to_collection('losses', weight_loss) # 第三个全连接层 with tf.name_scope('FC3_linear'): weights = WeightsVariable(shape=[fc2_units_num, fc3_units_num], stddev=1.0/fc2_units_num) biases = BiasesVariable(shape=[fc3_units_num]) logits = FullyConnected(fc2_out, weights, biases, activation=tf.identity, act_name='linear') AddActivationSummary(logits) return logits 调用上面写的函数构造计算图，并设计会话流程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111def TrainModel(): with tf.Graph().as_default(): # 计算图输入 with tf.name_scope('Inputs'): images_holder = tf.placeholder(tf.float32, [batch_size, image_size, image_size, image_channel], name='images') labels_holder = tf.placeholder(tf.int32, [batch_size], name='labels') # 计算图前向推断过程 with tf.name_scope('Inference'): logits = Inference(images_holder) # 定义损失层 with tf.name_scope('Loss'): cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_holder, logits=logits) cross_entropy_loss = tf.reduce_mean(cross_entropy, name='xentropy_loss') tf.add_to_collection('losses', cross_entropy_loss) # 总损失 = 交叉熵损失 + L2损失 total_loss = tf.add_n(tf.get_collection('losses'), name='total_loss') average_losses = AddLossesSummary(tf.get_collection('losses') + [total_loss]) # 定义优化训练层 with tf.name_scope('Train'): learning_rate = tf.placeholder(tf.float32) global_step = tf.Variable(0, name='global_step', trainable=False, dtype=tf.int64) optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate) train_op = optimizer.minimize(total_loss, global_step=global_step) # 定义模型评估层 with tf.name_scope('Evaluate'): top_K_op = tf.nn.in_top_k(predictions=logits, targets=labels_holder, k=1) # 定义获取训练样本批次的节点 with tf.name_scope('GetTrainBatch'): images_train, labels_train = get_distorted_train_batch(data_dir=dataset_dir, batch_size=batch_size) # 定义获取测试样本批次的节点 with tf.name_scope('GetTestBatch'): images_test, labels_test = get_undistorted_eval_batch(eval_data=True, data_dir=dataset_dir, batch_size=batch_size) # 收集所有汇总节点 merged_summaries = tf.summary.merge_all() # 添加所有变量的初始化节点 init_op = tf.global_variables_initializer() print("把计算图写入事件文件...") # graph_writer = tf.summary.FileWriter(logdir='events/', graph=tf.get_default_graph()) # graph_writer.close() summary_writer = tf.summary.FileWriter(logdir='events/') summary_writer.add_graph(graph=tf.get_default_graph()) summary_writer.flush() with tf.Session() as sess: sess.run(init_op) print('==&gt;&gt;&gt;&gt;&gt;&gt;&gt;==开始在训练集上训练模型==&lt;&lt;&lt;&lt;&lt;&lt;&lt;==') total_batches = int(num_examples_per_epoch_for_train / batch_size) print("per batch size: ", batch_size) print("train sample count per epoch:", num_examples_per_epoch_for_train) print("total batch count per epoch:", total_batches) # 启动数据读取队列 tf.train.start_queue_runners() # 记录模型被训练的步数 training_step = 0 # 训练指定轮数，每一轮的训练样本总数为：num_examples_per_epoch_for_train for epoch in range(training_epochs): # 每一轮都要把所有的batch跑一遍 for batch_idx in range(total_batches): # 运行获取批次训练数据的计算图，取出一个批次数据 images_batch, labels_batch = sess.run([images_train, labels_train]) # 运行优化器训练节点 _, loss_value, avg_losses= sess.run([train_op, total_loss, average_losses], feed_dict=&#123;images_holder:images_batch, labels_holder:labels_batch, learning_rate:learning_rate_init&#125;) # 每调用一次训练节点，training_step就加1，最终 == training_epochs * total_batch training_step = sess.run(global_step) # 每训练display_step次，计算当前模型的损失和分类准确率 if training_step % display_step == 0: # 运行Evaluate节点，计算当前批次的训练样本的准确率 predictions = sess.run([top_K_op], feed_dict=&#123;images_holder:images_batch, labels_holder:labels_batch&#125;) # 计算当前批次的预测正确样本量 batch_accuracy = np.sum(predictions) / batch_size print("train step: " + str(training_step) + ", train loss= " + "&#123;:.6f&#125;".format(loss_value) + ", train accuracy=" + "&#123;:.5f&#125;".format(batch_accuracy)) # 运行汇总节点 summaries_str = sess.run(merged_summaries, feed_dict= &#123;images_holder: images_batch, labels_holder: labels_batch&#125;) summary_writer.add_summary(summary=summaries_str, global_step=training_step) summary_writer.flush() summary_writer.close() print("训练完毕！") print('==&gt;&gt;&gt;&gt;&gt;&gt;&gt;==开始在测试集上评估模型==&lt;&lt;&lt;&lt;&lt;&lt;&lt;==') total_batches = int(num_examples_per_epoch_for_eval / batch_size) total_examples = total_batches * batch_size # 当除不尽batch_size时，num_examples_per_epoch_for_evalv ！= total_examples print("per batch size: ", batch_size) print("test sample count per epoch:", total_examples) print("total batch count per epoch:", total_batches) correc_predicted = 0 for test_step in range(total_batches): # 运行获取批次测试数据的计算图，取出一个批次数据 images_batch, labels_batch = sess.run([images_test, labels_test]) # 运行Evaluate节点，计算当前批次的训练样本的准确率 predictions = sess.run([top_K_op], feed_dict=&#123;images_holder:images_batch, labels_holder:labels_batch&#125;) # 累计每个批次的预测正确样本量 correc_predicted += np.sum(predictions) accuracy_score = correc_predicted / total_examples print("--------&gt;accuracy on test examples: ",accuracy_score) 123456def main(argv=None): train_dir = './events/' if tf.gfile.Exists(train_dir): tf.gfile.DeleteRecursively(train_dir) tf.gfile.MakeDirs(train_dir) TrainModel() 12if __name__ == '__main__': tf.app.run() 结果 训练结果 测试结果 Tensorboard 中查看 代码地址github中没有上传cifar10数据集，需要的话请从百度云下载，或自行下载，按照如下解压 github 百度云 提取码：xw3x]]></content>
      <categories>
        <category>ML/DL</category>
      </categories>
      <tags>
        <tag>图像分类</tag>
        <tag>tensorflow</tag>
        <tag>cifar10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-004-图像像素读写操作]]></title>
    <url>%2F2019%2F03%2F21%2Fopencv-004%2F</url>
    <content type="text"><![CDATA[知识点 C++中的像素遍历与访问 数组遍历 指针方式遍历 Python中的像素遍历与访问 数组遍历 代码（c++,python）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;/** * 读取图像，实现像素反转 */int main() &#123; Mat src = imread("../images/liuyifei_1.png"); Mat src_copy = src.clone(); int height = src.rows; int width = src.cols; int ch = src.channels(); imshow("input", src); // 直接读取图像像素 for (int row = 0; row &lt; height; ++row) &#123; for (int col = 0; col &lt; width; ++col) &#123; if (ch == 3) &#123; Vec3b bgr = src.at&lt;Vec3b&gt;(row, col); bgr[0] = 255 - bgr[0]; bgr[1] = 255 - bgr[1]; bgr[2] = 255 - bgr[2]; src.at&lt;Vec3b&gt;(row, col) = bgr; &#125; else if (ch == 1) &#123; int gray = src.at&lt;uchar&gt;(row, col); src.at&lt;uchar&gt;(row, col) = 255 - gray; &#125; &#125; &#125; imshow("output1", src); // 指针读取 Mat result = Mat::zeros(src_copy.size(), src_copy.type()); int blue = 0, green = 0, red = 0; int gray; for (int row = 0; row &lt; height; ++row) &#123; // curr_row为第row行的首地址，遍历时，前三个字节表示的是第一个像素的BGR值， // 注意BGR值顺序，接下来三个字节是第二个像素的值。 uchar *curr_row = src_copy.ptr&lt;uchar&gt;(row); uchar *result_row = result.ptr&lt;uchar&gt;(row); for (int col = 0; col &lt; width; ++col) &#123; if (ch == 3) &#123; blue = *curr_row++; green = *curr_row++; red = *curr_row++; *result_row++ = 255 - blue; *result_row++ = 255 - green; *result_row++ = 255 - red; &#125; else if (ch == 1) &#123; gray = *curr_row++; *result_row++ = gray; &#125; &#125; &#125; imshow("output2", result); waitKey(0); return 0;&#125; 123456789101112131415161718import cv2 as cvsrc = cv.imread("../images/liuyifei_1.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)h, w, ch = src.shapeprint("h , w, ch", h, w, ch)for row in range(h): for col in range(w): b, g, r = src[row, col] b = 255 - b g = 255 - g r = 255 - r src[row, col] = [b, g, r]cv.imshow("output", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>图像像素读写</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-003-图像对象(Mat)创建与赋值]]></title>
    <url>%2F2019%2F03%2F21%2Fopencv-003%2F</url>
    <content type="text"><![CDATA[知识点 C++中Mat对象与创建 Python中Numpy数组对象 代码（c++,python）123456789101112131415161718192021222324252627282930#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;int main()&#123; Mat src = imread("../images/liuyifei_1.png"); // 通过克隆或复制创建图像对象，m1和src指向不同内存块 Mat m1 = src.clone(); Mat m2; src.copyTo(m2); // 赋值法，m3和src指向同一内存块 Mat m3 = src; // 创建空白图像 Mat m4 = Mat::zeros(src.size(),src.type()); Mat m5 = Mat::zeros(Size(512,512),CV_8UC3); Mat m6 = Mat::ones(Size(512,512),CV_8UC3); // kernel: [0, -1, 0 // -1, 5, -1 // 0, -1, 0] Mat kernel = (Mat_&lt;char&gt;(3,3)&lt;&lt;0,-1,0,-1,5,-1,0,-1,0); waitKey(0); return 0;&#125; 12345678910111213141516171819202122232425262728import cv2 as cvimport numpy as npsrc = cv.imread("../images/liuyifei_1.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)# 克隆图像m1 = np.copy(src)# 赋值m2 = srcsrc[100:200,200:300,:] = 255 # 第三维代表图像通道cv.imshow("m2",m2)m3 = np.zeros(src.shape, src.dtype)cv.imshow("m3", m3)m4 = np.zeros([512,512], np.uint8)# m4[:,:] =127 try to give gray value 127cv.imshow("m4", m4)m5 = np.ones(shape=[512,512,3], dtype=np.uint8)m5[:,:,0] = 255cv.imshow("m5", m5)cv.waitKey(0)cv.destroyAllWindows() 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>Mat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-002-色彩空间转换(cvtcolor)与图像保存(imwrite)]]></title>
    <url>%2F2019%2F03%2F20%2Fopencv-002%2F</url>
    <content type="text"><![CDATA[知识点 色彩空间转换函数- cvtColor COLOR_BGR2GRAY = 6 彩色到灰度 COLOR_GRAY2BGR = 8 灰度到彩色 COLOR_BGR2HSV = 40 BGR到HSV COLOR_HSV2BGR = 54 HSV到 BGR 图像保存 - imwrite 第一个参数是图像保存路径 第二个参数是图像内存对象 代码（c++,python）1234567891011121314151617181920212223242526#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;int main()&#123; Mat src = imread("../images/liuyifei_1.png"); if (src.empty())&#123; cout &lt;&lt; "could not load image..." &lt;&lt; endl; return -1; &#125; namedWindow("input"); imshow("input",src); Mat dst; cvtColor(src,dst,COLOR_BGR2GRAY); imwrite("../images/result1.png",dst); namedWindow("output gray"); imshow("output gray",dst); waitKey(0); return 0;&#125; 123456789import cv2 as cvsrc = cv.imread("../images/liuyifei_1.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)cv.imshow("gray", gray)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>色彩空间转换(cvtcolor)</tag>
        <tag>图像保存(imwrite)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clion无法读取相对路径文件或图像的解决方法]]></title>
    <url>%2F2019%2F03%2F20%2FClion_path_problem%2F</url>
    <content type="text"><![CDATA[项目目录 相对路径错误写法12// opencv读取图像，此时无法读取Mat image = imread("images/liuyifei_1.png") 解决方案 1 - 使用绝对路径1Mat image = imread("D:\\code-workspace\\Clion-workspace\\learnOpencv\\images\\liuyifei_1.png") 解决方案 2 - 返回根目录1Mat image = imread("../images/liuyifei_1.png") 解决方案 3 - 设置项目工作目录 设置项目工作目录 代码如下 12// 此时读取成功Mat image = imread("images/liuyifei_1.png")]]></content>
      <tags>
        <tag>Clion</tag>
        <tag>相对路径问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-001-读取(imread)与显示(imshow)图像]]></title>
    <url>%2F2019%2F03%2F20%2Fopencv-001%2F</url>
    <content type="text"><![CDATA[知识点 读取图像 - imread() 显示图像 - imshow() 代码（c++,python）123456789101112131415161718192021#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;int main() &#123; // Mat image = imread("../images/liuyifei_1.png"); // 读取的时候加参数，使读取后为灰度图像 Mat image = imread("../images/liuyifei_1.png",IMREAD_GRAYSCALE); if (image.empty()) &#123; cout &lt;&lt; "could not load image..." &lt;&lt; endl; return -1; &#125; namedWindow("input"); imshow("input",image); waitKey(0); return 0;&#125; 1234567import cv2 as cvsrc = cv.imread("../images/liuyifei_1.png")cv.namedWindow("input", cv.WINDOW_AUTOSIZE)cv.imshow("input", src)cv.waitKey(0)cv.destroyAllWindows() 结果 代码地址github]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>读取并显示图像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip配置阿里云镜像]]></title>
    <url>%2F2019%2F03%2F19%2Fpip_windows_aliyun%2F</url>
    <content type="text"><![CDATA[windows新建pip配置文件夹 在windows “文件资源管理器” 地址栏输入%APPDATA% 按回车，创建pip文件夹，用于存放pip配置文件 在pip文件夹中新建名为：pip.ini 的配置文件 在pip.ini中输入以下内容 123[global]trusted-host = mirrors.aliyun.comindex-url = https://mirrors.aliyun.com/pypi/simple linux新建.pip文件夹 1mkdir .pip 新建pip.conf文件 12cd .piptouch pip.conf 在pip.conf中输入以下内容 1vim pip.conf 123[global]trusted-host = mirrors.aliyun.comindex-url = https://mirrors.aliyun.com/pypi/simple]]></content>
      <categories>
        <category>环境配置与安装</category>
      </categories>
      <tags>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下Clion配置opencv]]></title>
    <url>%2F2019%2F03%2F19%2Fopencv_Clion%2F</url>
    <content type="text"><![CDATA[所需环境MinGw + Cmake + Clion + opencv 安装MinGw参考：install MinGw 安装Cmake参考：install Cmake Cmake下载网址：Cmake download 注：Cmake最好安装跟Clion中配置一样的版本，省的麻烦 安装 opencv 下载地址 ：opencv download 解压到 opencv4文件夹中 解压后： 配置环境变量： Clion 配置 编译opencv源码 打开Cmake-GUI，选择源码路径和输出路径 点击Configure，选择MinGW Makefiles，点击Finish，开始编译 等待一段时间后，会有很多报红，再次点击Configure，红色消失，点击Generate 进入输出目录，在cmd 运行下面代码，等待完成 1mingw32-make -j8 运行mingw32-make install，等待片刻，输出目录下会多出install文件夹 添加…\install\x64\mingw\bin 添加到path系统环境变量环境变量 编辑CMakeLists.txt1234567891011121314151617cmake_minimum_required(VERSION 3.13)project(learnOpencv)set(CMAKE_CXX_STANDARD 11)# Where to find CMake modules and OpenCVset(OpenCV_DIR "D:\\software\\opencv4\\MinGW64_build\\install")set(CMAKE_MODULE_PATH $&#123;CMAKE_MODULE_PATH&#125; "$&#123;CMAKE_SOURCE_DIR&#125;/cmake/")find_package(OpenCV REQUIRED)include_directories($&#123;OpenCV_INCLUDE_DIRS&#125;)add_executable(learnOpencv test.cpp)# add libs you needset(OpenCV_LIBS opencv_core opencv_imgproc opencv_highgui opencv_imgcodecs)# linkingtarget_link_libraries(learnOpencv $&#123;OpenCV_LIBS&#125;) 注意：opencv4必须要c++11支持 测试12345678910111213#include &lt;opencv2\opencv.hpp&gt;using namespace cv;int main()&#123; Mat img = imread("D:\\code-workspace\\Clion-workspace\\learnOpencv\\images\\1.png",WINDOW_AUTOSIZE); namedWindow("刘亦菲"); imshow("刘亦菲", img); waitKey(0); return 0;&#125;]]></content>
      <categories>
        <category>环境配置与安装</category>
      </categories>
      <tags>
        <tag>Clion</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python安装opencv]]></title>
    <url>%2F2019%2F03%2F19%2Fopencv_python%2F</url>
    <content type="text"><![CDATA[安装opencv123456# opencv-python 和 opencv-contrib-python只能安装一个，后者带有扩展包，建议直接安后者pip install opencv-python# 安装opencv-contrib-python前，要先卸载opencv-pythonpip uninstall opencv-pythonpip install opencv-contrib-python 更新opencv1pip install --upgrade opencv-python]]></content>
      <categories>
        <category>环境配置与安装</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS2017配置opencv]]></title>
    <url>%2F2019%2F03%2F19%2Fopencv_vs2017%2F</url>
    <content type="text"><![CDATA[安装 opencv 下载地址 ：opencv download 解压到 opencv4文件夹中 解压后： 配置环境变量： VS2017中配置opencv 新建一个工程 依次点击：视图 ==&gt; 其他窗口 ==&gt; 属性管理器 添加包含目录 添加库目录 添加附加依赖项 重启VS2017 测试 测试代码 1234567891011121314#include &lt;opencv2\opencv.hpp&gt;using namespace cv;int main()&#123; Mat img = imread("1.png"); namedWindow("hahaha"); imshow("hahaha", img); waitKey(0); return 0;&#125; 测试结果]]></content>
      <categories>
        <category>环境配置与安装</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>VS2017</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装jupyter notebook插件]]></title>
    <url>%2F2019%2F03%2F02%2FjupyterPlugin%2F</url>
    <content type="text"><![CDATA[步骤12python -m pip install jupyter_contrib_nbextensionsjupyter contrib nbextension install --user --skip-running-check Autopep8 –&gt; 格式化代码]]></content>
      <categories>
        <category>环境配置与安装</category>
      </categories>
      <tags>
        <tag>jupyter notebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用keras用常规神经网络训练MNIST数据集]]></title>
    <url>%2F2019%2F03%2F02%2FmnistLinearNN%2F</url>
    <content type="text"><![CDATA[加载mnist数据集123456from keras.datasets import mnist(x_train,y_train),(x_test,y_test) = mnist.load_data() # 将下载好的mnist.npz方在 ~/.keras/datasets/ 目录下print(x_train.shape,type(x_train))print(y_train.shape,type(y_train))print(x_test.shape,type(x_test))print(y_test.shape,type(y_test)) (60000, 28, 28) &lt;class &apos;numpy.ndarray&apos;&gt; (60000,) &lt;class &apos;numpy.ndarray&apos;&gt; (10000, 28, 28) &lt;class &apos;numpy.ndarray&apos;&gt; (10000,) &lt;class &apos;numpy.ndarray&apos;&gt; 数据处理：规范化1234# 将图形从[28,28]变为[784,]X_train = x_train.reshape(60000,784)X_test = x_test.reshape(10000,784)print(X_train.shape,X_test.shape) (60000, 784) (10000, 784) 123456# 将数据转换为float32，为了进行归一化，不然/255得到全部是0X_train = X_train.astype('float32')X_test = X_test.astype('float32')# 数据归一化X_train /= 255X_test /= 255 统计训练数据中个标签数量12345import numpy as npimport matplotlib.pyplot as pltlabel, count = np.unique(y_train, return_counts=True)print(label, count) [0 1 2 3 4 5 6 7 8 9] [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949] 123456789101112fig = plt.figure(figsize=(8, 5))plt.bar(label, count, width=0.7, align='center')plt.title("Label Distribution")plt.xlabel('Label')plt.ylabel('Count')plt.xticks(label)plt.ylim(0, 7500)for a, b in zip(label, count): plt.text(a, b, '%d' % b, ha='center', va='bottom', fontsize=10)plt.show() 对标签进行one-hot编码123456789101112131415161718192021# import tensorflow as tf# n_classes = 10# Y_train = tf.one_hot(y_train, n_classes)# Y_test = tf.one_hot(y_test, n_classes)# with tf.Session() as sess:# sess.run(tf.global_variables_initializer())# Y_train=sess.run(Y_train)# Y_test=sess.run(Y_test)# print(Y_train.shape)# 下面代码同上，使用tensorflow需要建立会话，简单转换keras更方便from keras.utils import np_utilsn_classes = 10Y_train = np_utils.to_categorical(y_train,n_classes)Y_test = np_utils.to_categorical(y_test,n_classes)print(Y_train.shape) (60000, 10) 12print(y_train[0])print(Y_train[0]) 5 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] 使用Keras sequential model 定义神经网络1234567891011121314# 使用keras定义线性网络很方便from keras.models import Sequentialfrom keras.layers.core import Dense, Activationmodel = Sequential()# 第一隐藏层model.add(Dense(512, input_shape=(784,)))model.add(Activation('relu'))# 第二隐藏层model.add(Dense(512))model.add(Activation('relu'))# 输出层model.add(Dense(10))model.add(Activation('softmax')) 编译模型1model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) 训练模型，并将指标保存到history中12history = model.fit(X_train, Y_train, batch_size=128, epochs=5, verbose=2, validation_data=(X_test, Y_test)) Train on 60000 samples, validate on 10000 samples Epoch 1/5 - 7s - loss: 0.2156 - acc: 0.9373 - val_loss: 0.0970 - val_acc: 0.9710 Epoch 2/5 - 7s - loss: 0.0804 - acc: 0.9758 - val_loss: 0.0769 - val_acc: 0.9770 Epoch 3/5 - 7s - loss: 0.0504 - acc: 0.9838 - val_loss: 0.0791 - val_acc: 0.9746 Epoch 4/5 - 7s - loss: 0.0350 - acc: 0.9891 - val_loss: 0.0659 - val_acc: 0.9804 Epoch 5/5 - 8s - loss: 0.0264 - acc: 0.9913 - val_loss: 0.0734 - val_acc: 0.9794 可视化指标12345678910111213141516171819fig = plt.figure()plt.subplot(211)plt.plot(history.history['acc'])plt.plot(history.history['val_acc'])plt.title('Model Accuracy')plt.xlabel('epoch')plt.ylabel('accuracy')plt.legend(['train','test'])plt.subplot(212)plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('Model Loss')plt.xlabel('epoch')plt.ylabel('loss')plt.legend(['train','test'])plt.tight_layout()plt.show() 保存模型123456789101112import osimport tensorflow.gfile as gfilesave_dir = '.\model'if gfile.Exists(save_dir): gfile.DeleteRecursively(save_dir)gfile.MakeDirs(save_dir)model_name = 'keras_mnist.h5'model_path = os.path.join(save_dir,model_name)model.save(model_path)print('Saved trained model at %s' % model_path) Saved trained model at .\model\keras_mnist.h5 加载模型123from keras.models import load_modelmnist_model = load_model(model_path) 统计模型在测试集上的分类结果123456789loss_and_metrics = mnist_model.evaluate(X_test, Y_test, verbose=2)print("Test Loss: &#123;&#125;".format(loss_and_metrics[0]))print("Test Accuracy: &#123;&#125;%".format(loss_and_metrics[1]*100))predicted_classes = mnist_model.predict_classes(X_test)correct_indices = np.nonzero(predicted_classes == y_test)[0]incorrect_indices = np.nonzero(predicted_classes != y_test)[0]print("Classified correctly count: &#123;&#125;".format(len(correct_indices)))print("Classified incorrectly count: &#123;&#125;".format(len(incorrect_indices))) Test Loss: 0.07340353026344673 Test Accuracy: 97.94% Classified correctly count: 9794 Classified incorrectly count: 206 代码地址github]]></content>
      <categories>
        <category>ML/DL</category>
      </categories>
      <tags>
        <tag>mnist</tag>
        <tag>keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用keras用卷积神经网络训练MNIST数据集]]></title>
    <url>%2F2019%2F03%2F02%2FmnistCNN%2F</url>
    <content type="text"><![CDATA[加载mnist数据集123456from keras.datasets import mnist(x_train,y_train),(x_test,y_test) = mnist.load_data() # 将下载好的mnist.npz方在 ~/.keras/datasets/ 目录下print(x_train.shape,type(x_train))print(y_train.shape,type(y_train))print(x_test.shape,type(x_test))print(y_test.shape,type(y_test)) (60000, 28, 28) &lt;class &apos;numpy.ndarray&apos;&gt; (60000,) &lt;class &apos;numpy.ndarray&apos;&gt; (10000, 28, 28) &lt;class &apos;numpy.ndarray&apos;&gt; (10000,) &lt;class &apos;numpy.ndarray&apos;&gt; 数据处理：规范化channels_last对应的输入：(batch,height,width,channels) channels_first对应的输入：(batch,channels,height,width) 默认channels_last，修改：~/.keras/keras.json 123456789101112131415from keras import backend as Kimg_rows, img_cols = 28, 28if K.image_data_format() == 'channels_first': x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) input_shape = (1, img_rows, img_cols)else: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) input_shape = (img_rows, img_cols, 1)print(x_train.shape, type(x_train))print(x_test.shape, type(x_test)) (60000, 28, 28, 1) &lt;class &apos;numpy.ndarray&apos;&gt; (10000, 28, 28, 1) &lt;class &apos;numpy.ndarray&apos;&gt; 123456# 将数据转换为float32，为了进行归一化，不然/255得到全部是0X_train = x_train.astype('float32')X_test = x_test.astype('float32')# 数据归一化X_train /= 255X_test /= 255 统计训练数据中个标签数量12345import numpy as npimport matplotlib.pyplot as pltlabel, count = np.unique(y_train, return_counts=True)print(label, count) [0 1 2 3 4 5 6 7 8 9] [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949] 123456789101112fig = plt.figure(figsize=(8, 5))plt.bar(label, count, width=0.7, align='center')plt.title("Label Distribution")plt.xlabel('Label')plt.ylabel('Count')plt.xticks(label)plt.ylim(0, 7500)for a, b in zip(label, count): plt.text(a, b, '%d' % b, ha='center', va='bottom', fontsize=10)plt.show() 对标签进行one-hot编码1234567from keras.utils import np_utilsn_classes = 10Y_train = np_utils.to_categorical(y_train,n_classes)Y_test = np_utils.to_categorical(y_test,n_classes)print(Y_train.shape) (60000, 10) 12print(y_train[0])print(Y_train[0]) 5 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] 使用Keras sequential model 定义MNIST CNN网络123456789101112131415161718192021222324from keras.models import Sequentialfrom keras.layers import Dense, Dropout, Flattenfrom keras.layers import Conv2D, MaxPooling2Dmodel = Sequential()## Feature Extraction# 第一层卷积，32个3*3的卷积核，激活函数使用relumodel.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=input_shape))# 第二层卷积，64个3*3的卷积核，激活函数使用relumodel.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))# 最大池化层model.add(MaxPooling2D(pool_size=(2,2)))# Dropout 25% 的输入神经元model.add(Dropout(0.25))# 将Pooled feature map 摊平后输入全连接网络model.add(Flatten())## Classification# 全连接层model.add(Dense(128,activation='relu'))# Dropout 50% 的输入神经元model.add(Dropout(0.5))# 使用softmax 激活函数做多分类，输出各数字的概率model.add(Dense(10, activation='softmax')) 查看 MNIST CNN 模型网络结构1model.summary() _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 _________________________________________________________________ conv2d_2 (Conv2D) (None, 24, 24, 64) 18496 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64) 0 _________________________________________________________________ dropout_1 (Dropout) (None, 12, 12, 64) 0 _________________________________________________________________ flatten_1 (Flatten) (None, 9216) 0 _________________________________________________________________ dense_1 (Dense) (None, 128) 1179776 _________________________________________________________________ dropout_2 (Dropout) (None, 128) 0 _________________________________________________________________ dense_2 (Dense) (None, 10) 1290 ================================================================= Total params: 1,199,882 Trainable params: 1,199,882 Non-trainable params: 0 _________________________________________________________________ 12for layer in model.layers: print(layer.get_output_at(0).get_shape().as_list()) [None, 26, 26, 32] [None, 24, 24, 64] [None, 12, 12, 64] [None, 12, 12, 64] [None, None] [None, 128] [None, 128] [None, 10] 编译模型1model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) 训练模型，并将指标保存到history中1history = model.fit(X_train, Y_train, batch_size=128, epochs=5,verbose=2, validation_data=(X_test, Y_test)) Train on 60000 samples, validate on 10000 samples Epoch 1/5 - 131s - loss: 0.2330 - acc: 0.9290 - val_loss: 0.0540 - val_acc: 0.9817 Epoch 2/5 - 146s - loss: 0.0853 - acc: 0.9747 - val_loss: 0.0372 - val_acc: 0.9882 Epoch 3/5 - 136s - loss: 0.0605 - acc: 0.9812 - val_loss: 0.0315 - val_acc: 0.9898 Epoch 4/5 - 129s - loss: 0.0514 - acc: 0.9843 - val_loss: 0.0283 - val_acc: 0.9913 Epoch 5/5 - 130s - loss: 0.0416 - acc: 0.9873 - val_loss: 0.0272 - val_acc: 0.9911 可视化指标12345678910111213141516171819fig = plt.figure()plt.subplot(211)plt.plot(history.history['acc'])plt.plot(history.history['val_acc'])plt.title('Model Accuracy')plt.xlabel('epoch')plt.ylabel('accuracy')plt.legend(['train','test'])plt.subplot(212)plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('Model Loss')plt.xlabel('epoch')plt.ylabel('loss')plt.legend(['train','test'])plt.tight_layout()plt.show() 保存模型123456789101112import osimport tensorflow.gfile as gfilesave_dir = '.\model'if gfile.Exists(save_dir): gfile.DeleteRecursively(save_dir)gfile.MakeDirs(save_dir)model_name = 'keras_mnist.h5'model_path = os.path.join(save_dir,model_name)model.save(model_path)print('Saved trained model at %s' % model_path) Saved trained model at .\model\keras_mnist.h5 加载模型123from keras.models import load_modelmnist_model = load_model(model_path) 统计模型在测试集上的分类结果123456789loss_and_metrics = mnist_model.evaluate(X_test, Y_test, verbose=2)print("Test Loss: &#123;&#125;".format(loss_and_metrics[0]))print("Test Accuracy: &#123;&#125;%".format(loss_and_metrics[1]*100))predicted_classes = mnist_model.predict_classes(X_test)correct_indices = np.nonzero(predicted_classes == y_test)[0]incorrect_indices = np.nonzero(predicted_classes != y_test)[0]print("Classified correctly count: &#123;&#125;".format(len(correct_indices)))print("Classified incorrectly count: &#123;&#125;".format(len(incorrect_indices))) Test Loss: 0.027159390095694836 Test Accuracy: 99.11% Classified correctly count: 9911 Classified incorrectly count: 89 代码地址github]]></content>
      <categories>
        <category>ML/DL</category>
      </categories>
      <tags>
        <tag>mnist</tag>
        <tag>keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv+tensorflow实时检测人脸]]></title>
    <url>%2F2018%2F12%2F29%2FfaceDetection%2F</url>
    <content type="text"><![CDATA[关于人脸检测的说明本文代码使用了opencv自带的人脸检测算法和mtcnn算法，mtcnn有明显的优势，检测成功率基本维持在100%，而且人脸各角度都可以检测成功，所以建议使用mtcnn来进行人脸检测，电脑cpu也可以流畅运行。 需要提前配置的环境：python + opencv + tensorflow 关于mtcnn的介绍，请参见压缩包中的电子书 代码结构说明 detect_face.py定义了mtcnn模型 det 1-3.npy是预训练好的模型，所以不用再对mtcnn进行训练 detect 1-3.py是三种实现方式，下面一一介绍 代码演示detect1.py使用mtcnn对一张图片进行检测，效果如下： detect2.py使用opencv自带的HAAR进行实时人脸检测，当人脸倾斜时无法检测到，效果如下： detect3.py使用MTCNN进行实时人脸检测，无论人脸各个角度，都可以检测到，效果如下： 代码地址github地址 百度云地址 注意：github地址中没有mtcnn的预训练模型，需要自己下载，百度云是完整的]]></content>
      <categories>
        <category>ML/DL</category>
      </categories>
      <tags>
        <tag>人脸检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下查看端口占用进程及杀死进程]]></title>
    <url>%2F2018%2F12%2F08%2Flinux-kill-process%2F</url>
    <content type="text"><![CDATA[直接查看进程1ps 通过端口查看进程1lsof –i:端口号 杀死进程1kill -9 pid号]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>查看linux进程并杀死</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下关于screen命令的使用]]></title>
    <url>%2F2018%2F12%2F08%2Flinux-screen%2F</url>
    <content type="text"><![CDATA[因为进入服务器只有一个窗口，当我们用这个窗口跑代码时，就没有办法同时用命令编辑一些文件。为了解决这个问题，我们可以使用screen开启多个进程，用一个进程跑代码，然后将这个窗口折叠到后台，创建新的进程来编辑代码。 当我们想要断开服务器连接仍然让一些程序运行的时候，可以使用screen让程序在后台一直运行。 安装screen (ubuntu系统)1sudo apt-get install screen 创建进程1screen -S 进程名 之后，会进入一个干净的窗口，可以执行相应操作，连续按Ctrl+A、Ctrl+D回到主线程，之前执行的操作会一直在后台运行，直到杀死该进程。 这条命令可以多次使用，创建多个进程。 查看当前screen进程1screen -ls 进入某一进程123#两条命令选其一screen -r 进程名screen -r 进程pid号 终止进程12345#方法一screen -X -S 进程名 quit#方法二先进入要杀死的进程，然后输入exit]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux下screen的使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux添加用户并赋予sudo权限]]></title>
    <url>%2F2018%2F11%2F29%2FaddLinuxUser%2F</url>
    <content type="text"><![CDATA[创建用户123# 在root用户下不用写sudosudo adduser fanfan # 在/home 下会自动创建同名文件夹passwd fanfan # 设置密码，上个命令有时会直接让输入密码，就不需要执行这一步了 删除用户1sudo userdel fanfan 添加sudo权限 su -切换到root vim /etc/sudoers ，在root ALL=(ALL) ALL的下一行添加： 12345# sudo时需要输入密码fanfan ALL=(ALL) ALL# sudo时不需要输入密码fanfan ALL=(ALL) NOPASSWD: ALL 按Esc，再输入:wq!保存文件，要加!，不然保存会出问题]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux添加用户</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地访问服务器端jupyter notebook]]></title>
    <url>%2F2018%2F11%2F29%2FremoteJupyter%2F</url>
    <content type="text"><![CDATA[1 登陆远程服务器2 生成配置文件1$ jupyter notebook --generate-config 3 生成密码打开ipython，创建一个密文的密码12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password: Verify password: Out[2]: 'sha1:ce23d945972f:34769685a7ccd3d08c84a18c63968a41f1140274' 把生成的密文‘sha:ce…’复制下来 4 修改默认配置文件1$ vim ~/.jupyter/jupyter_notebook_config.py 进行如下修改：1234c.NotebookApp.ip='*'c.NotebookApp.password = u'sha:ce...刚才复制的那个密文'c.NotebookApp.open_browser = Falsec.NotebookApp.port =8888 #随便指定一个端口 5 启动jupyter notebook1$ jupyter notebook 6 远程访问此时应该可以直接从本地浏览器直接访问http://address_of_remote:8888就可以看到jupyter的登陆界面，输入第三步中设置的密码。 7 建立SSH通道如果登陆失败，则有可能是服务器防火墙设置的问题，此时最简单的方法是在本地建立一个ssh通道：在本地终端中输入：12ssh fanfan@222.92.146.251 -L127.0.0.1:1234:127.0.0.1:6666ssh fanfan@47.106.208.254 -L127.0.0.1:1234:127.0.0.1:8888 便可以在localhost:1234直接访问远程的jupyter了。]]></content>
      <categories>
        <category>环境配置与安装</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>jupyter notebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器端安装Anaconda]]></title>
    <url>%2F2018%2F11%2F29%2FinstallAnaconda%2F</url>
    <content type="text"><![CDATA[步骤打开网址：Anaconda清华镜像，复制要下载的文件地址，执行以下命令：12345678910wget 复制的网址（会下载一个sh文件）sh sh文件名 #执行后，会显示使用条款，按enter继续阅读，会让回答几个问题，全部yesrm -rf sh文件名source ~/.bashrc （使conda生效）#设置清华conda镜像conda config --prepend channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ 注意事项 Anaconda3-5.2.0.Linux-x86_64.sh ==&gt; python3.6 Anaconda3-5.3.1.Linux-x86_64.sh ==&gt; python3.7 若wget显示网络不可达，执行以下操作： 123456#centossudo yum -y install wget#ubuntusudo apt-get updatesudo apt-get install wget 若不能运行jupyter notebook，进行如下配置：jupyter notebook配置]]></content>
      <categories>
        <category>环境配置与安装</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Anaconda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux终端bash美化教程]]></title>
    <url>%2F2018%2F11%2F29%2FbeautifyBash%2F</url>
    <content type="text"><![CDATA[美化步骤12345vim .bashrc添加下行export PS1="Time:\[\033[1;35m\]\T \[\033[0m\]User:\[\033[1;33m\]\u \[\033[0m\]Dir:\[\033[1;32m\]\w\[\033[0m\]\n\$"退出vimsource .bashrc 美化效果 PS1中参数的具体含义参考链接]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo写博客步骤]]></title>
    <url>%2F2018%2F11%2F29%2FwriteArtical%2F</url>
    <content type="text"><![CDATA[博客编写步骤1 进入D:\Blog文件夹下，打开终端 2 输入：hexo new &quot;文件名&quot;，在D:\Blog\source\\_posts目录下创建了文件名.md文件 3 打开文件名.md，编写博客 4 终端输入：hexo d -g提交博客 md文件编写注意事项1234567---title: 博客名categories: 分类名tags: - 标签1 - 标签2--- 更新博客分类与标签页面12hexo cleanhexo d -g]]></content>
      <tags>
        <tag>Hexo发送文章</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简易安卓聊天软件之思路架构及源码]]></title>
    <url>%2F2018%2F11%2F04%2FweChat%2F</url>
    <content type="text"><![CDATA[安卓聊天软件完成的功能罗列1 登陆2 动态显示好友列表3 服务端程序4 客户端程序5 安全退出6 与多好友聊天，屏幕切换，可以保存原信息，每次新登陆，可以读取历史记录7 缓存消息，及离线完成 软件架构图 本地Sqlite数据库设计只有一张表，存储聊天消息，表中有三个属性，分别为：发送者 接收者 消息内容 客户端与服务端传输消息协议约定： 客户端新上线的时候，向服务端发送用户名，服务端向客户端发送好友列表与离线消息 客户端 ==&gt; 服务端：发送者：接收者：消息 服务端 ==&gt; 客户端：发送者：接收者：消息 服务端向客户端发送的是消息还是好友列表，以开头是否是”&amp;”符号区分 客户端目录结构（Android Studio） 客户端的基本思路Service负责与服务器进行网络连接与IO读写，无论是发送消息还是接受消息，Service都先把消息存到本地数据库，FriendListActivity与ChatActivity中ListView的显示，都是直接从数据库读取数据。Service与Activity的通信主要使用Intent和广播来进行。 服务端程序服务端基本思路（具体代码见文末源码地址）： 使用一个List存储所有好友 使用一个Map存储在线好友及对应Socket 使用一个Map存储离线消息 软件开发经验总结这次软件开发是以小组形式进行的，最后算是完成了聊天软件的基本功能，这次开发做的好的地方在于一开始小组就先把真个架构图设计好了，包括数据库，后面写代码基本很顺畅，得到的经验就是开发一个软件，做一个项目，写代码真的是很靠后的事情了，前期一定是先通过写用例，梳理好逻辑，画好架构图，后期按照梳理好的逻辑来写代码。后期还需要努力的地方在于UML类图，希望下次开发前期能把UML类图画出来，这样前期工作会更完善，加油，希望可以成为一个专业的程序员。 源码地址源码：github地址 注意：源码中的ImServeFinal.java文件时服务端程序，应该拿出来用java的IDE运行，记得更改ip与端口]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>java</tag>
      </tags>
  </entry>
</search>
